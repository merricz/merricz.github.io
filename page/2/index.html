<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.18.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":false,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="Myoboku">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="Myoboku">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="merric">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/page/2/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"page/2/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Myoboku</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Myoboku</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">merric</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">20</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">22</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/06/23/%E7%A0%94%E5%8F%91%E5%B7%A5%E5%85%B7/Git%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="merric">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Myoboku">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Myoboku">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/06/23/%E7%A0%94%E5%8F%91%E5%B7%A5%E5%85%B7/Git%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/" class="post-title-link" itemprop="url">Git学习总结</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-06-23 22:30:00" itemprop="dateCreated datePublished" datetime="2020-06-23T22:30:00+00:00">2020-06-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%A0%94%E5%8F%91%E5%B7%A5%E5%85%B7/" itemprop="url" rel="index"><span itemprop="name">研发工具</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="什么是git"><a href="#什么是git" class="headerlink" title="什么是git"></a>什么是git</h1><p>Git是免费、开源的 <strong>分布式版本控制</strong> 系统，可以有效、高速地处理从很小到非常大的项目版本管理。</p>
<h2 id="版本控制"><a href="#版本控制" class="headerlink" title="版本控制"></a>版本控制</h2><p>版本控制是指对软件开发过程中各种程序代码、配置文件及说明文档等文件变更的管理，是软件配置管理的核心思想之一。那些年，我们的毕业论文,其实就是版本变更的真实写照…脑洞一下，版本控制就是这些论文变更的管理</p>
<p><img src="/images/%E8%AE%BA%E6%96%87%E7%89%88%E6%9C%AC.png" alt="论文版本"></p>
<h3 id="集中化的版本控制系统"><a href="#集中化的版本控制系统" class="headerlink" title="集中化的版本控制系统"></a>集中化的版本控制系统</h3><p>那么，集中化的版本控制系统又是什么呢，说白了，就是有一个集中管理的中央服务器，保存着所有文件的修改历史版本，而协同开发者通过客户端连接到这台服务器，从服务器上同步更新或上传自己的修改。</p>
<p><img src="/images/%E9%9B%86%E4%B8%AD%E5%8C%96%E7%9A%84%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6.png" alt="集中化的版本控制"></p>
<h3 id="分布式的版本控制系统"><a href="#分布式的版本控制系统" class="headerlink" title="分布式的版本控制系统"></a>分布式的版本控制系统</h3><p>分布式版本控制系统，就是远程仓库同步所有版本信息到本地的每个用户。这里分三点阐述：</p>
<ul>
<li>用户在本地就可以查看所有的历史版本信息，但是偶尔要从远程更新一下，因为可能别的用户有文件修改提交到远程。</li>
<li>用户即使离线也可以本地提交，push推送到远程服务器才需要联网。</li>
<li>每个用户都保存了历史版本，所以只要有一个用户设备没问题，就可以恢复数据了</li>
</ul>
<p><img src="/images/%E5%88%86%E5%B8%83%E5%BC%8F%E7%9A%84%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6.png" alt="分布式的版本控制"></p>
<h1 id="Git的相关理论基础"><a href="#Git的相关理论基础" class="headerlink" title="Git的相关理论基础"></a><strong>Git的相关理论基础</strong></h1><h2 id="Git的四大工作区域"><a href="#Git的四大工作区域" class="headerlink" title="Git的四大工作区域"></a>Git的四大工作区域</h2><p>先复习Git的几个工作区域：</p>
<p><img src="/images/git%E7%9A%84%E5%9B%9B%E5%A4%A7%E5%B7%A5%E4%BD%9C%E5%8C%BA%E5%9F%9F.png" alt="git的四大工作区域"></p>
<ul>
<li><strong>Workspace</strong> ：你电脑本地看到的文件和目录，在Git的版本控制下，构成了工作区。</li>
<li><strong>Index&#x2F;Stage</strong> ：暂存区，一般存放在 .git目录下，即.git&#x2F;index,它又叫待提交更新区，用于临时存放你未提交的改动。比如，你执行git add，这些改动就添加到这个区域啦。</li>
<li><strong>Repository</strong> ：本地仓库，你执行git clone 地址，就是把远程仓库克隆到本地仓库。它是一个存放在本地的版本库，其中 <strong>HEAD指向最新放入仓库的版本</strong> 。当你执行git commit，文件改动就到本地仓库来了~</li>
<li><strong>Remote</strong> ：远程仓库，就是类似github，码云等网站所提供的仓库，可以理解为远程数据交换的仓库</li>
</ul>
<h2 id="Git的工作流程"><a href="#Git的工作流程" class="headerlink" title="Git的工作流程"></a>Git的工作流程</h2><p>上一小节介绍完Git的四大工作区域，把git的操作命令和几个工作区域结合起来，个人觉得更容易理解一些，看图：</p>
<p><img src="/images/git%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png" alt="git的工作流程"></p>
<p>git 的正向工作流程一般就这样：</p>
<ul>
<li>从远程仓库拉取文件代码回来；</li>
<li>在工作目录，增删改查文件；</li>
<li>把改动的文件放入暂存区；</li>
<li>将暂存区的文件提交本地仓库；</li>
<li>将本地仓库的文件推送到远程仓库；</li>
</ul>
<h2 id="Git文件的四种状态"><a href="#Git文件的四种状态" class="headerlink" title="Git文件的四种状态"></a>Git文件的四种状态</h2><p>根据一个文件是否已加入版本控制，可以把文件状态分为：Tracked(已跟踪)和Untracked(未跟踪)，而tracked(已跟踪)又包括三种工作状态：Unmodified，Modified，Staged</p>
<p><img src="/images/git%E6%96%87%E4%BB%B6%E7%9A%84%E5%9B%9B%E7%A7%8D%E7%8A%B6%E6%80%81.png" alt="git文件的四种状态"></p>
<ul>
<li><strong>Untracked</strong> : 文件还没有加入到git库，还没参与版本控制，即未跟踪状态。这时候的文件，通过git add 状态，可以变为Staged状态</li>
<li><strong>Unmodified</strong> ：文件已经加入git库, 但是呢，还没修改, 就是说版本库中的文件快照内容与文件夹中还完全一致。Unmodified的文件如果被修改, 就会变为Modified. 如果使用git remove移出版本库, 则成为Untracked文件。</li>
<li><strong>Modified</strong> ：文件被修改了，就进入modified状态啦，文件这个状态通过stage命令可以进入staged状态</li>
<li><strong>staged</strong> ：暂存状态. 执行git commit则将修改同步到库中, 这时库中的文件和本地文件又变为一致, 文件为Unmodified状态.</li>
</ul>
<h1 id="git的常用命令"><a href="#git的常用命令" class="headerlink" title="git的常用命令"></a>git的常用命令</h1><h2 id="日常开发中，Git的基本常用命令"><a href="#日常开发中，Git的基本常用命令" class="headerlink" title="日常开发中，Git的基本常用命令"></a><strong>日常开发中，Git的基本常用命令</strong></h2><ul>
<li>git clone</li>
<li>git checkout -b dev</li>
<li>git add</li>
<li>git commit</li>
<li>git log</li>
<li>git diff</li>
<li>git status</li>
<li>git pull&#x2F;git fetch</li>
<li>git push</li>
</ul>
<p>这个图只是模拟一下git基本命令使用的大概流程</p>
<p><img src="/images/git%E7%9A%84%E5%A4%A7%E6%A6%82%E6%B5%81%E7%A8%8B.png" alt="git的大概流程"></p>
<h3 id="git-clone"><a href="#git-clone" class="headerlink" title="git clone"></a>git clone</h3><p>当我们要进行开发，第一步就是克隆远程版本库到本地</p>
<pre><code>git clone url  克隆远程版本库  
  
</code></pre>
<h3 id="git-checkout-b-dev"><a href="#git-checkout-b-dev" class="headerlink" title="git checkout -b dev"></a>git checkout -b dev</h3><p>克隆完之后呢，开发新需求的话，我们需要新建一个开发分支，比如新建开发分支dev</p>
<p>创建分支：</p>
<pre><code>git checkout -b dev   创建开发分支dev，并切换到该分支下  
</code></pre>
<h3 id="git-add"><a href="#git-add" class="headerlink" title="git add"></a>git add</h3><p>git add的使用格式：</p>
<pre><code>git add .	添加当前目录的所有文件到暂存区  
git add [dir]	添加指定目录到暂存区，包括子目录  
git add [file1]	添加指定文件到暂存区  
</code></pre>
<p>有了开发分支dev之后，我们就可以开始开发啦，假设我们开发完HelloWorld.java，可以把它加到暂存区，命令如下</p>
<pre><code>git add Hello.java  把HelloWorld.java文件添加到暂存区去  
</code></pre>
<h3 id="git-commit"><a href="#git-commit" class="headerlink" title="git commit"></a>git commit</h3><p>git commit的使用格式：</p>
<pre><code>git commit -m [message] 提交暂存区到仓库区,message为说明信息  
git commit [file1] -m [message] 提交暂存区的指定文件到本地仓库  
git commit --amend -m [message] 使用一次新的commit，替代上一次提交  
  
</code></pre>
<p>把HelloWorld.java文件加到暂存区后，我们接着可以提交到本地仓库</p>
<pre><code>git commit -m &#39;helloworld开发&#39;  
  
</code></pre>
<h3 id="git-status"><a href="#git-status" class="headerlink" title="git status"></a>git status</h3><p>git status,表示查看工作区状态，使用命令格式：</p>
<pre><code>git status  查看当前工作区暂存区变动  
git status -s  查看当前工作区暂存区变动，概要信息  
git status  --show-stash 查询工作区中是否有stash（暂存的文件）  
</code></pre>
<p>当你忘记是否已把代码文件添加到暂存区或者是否提交到本地仓库，都可以用git status看看</p>
<h3 id="git-log"><a href="#git-log" class="headerlink" title="git log"></a>git log</h3><p>git log，这个命令用得应该比较多，表示查看提交历史&#x2F;提交日志，要回滚代码就经常用它看看提交历史。</p>
<pre><code>git log  查看提交历史  
git log --oneline 以精简模式显示查看提交历史  
git log -p &lt;file&gt; 查看指定文件的提交历史  
git blame &lt;file&gt; 一列表方式查看指定文件的提交历史  
</code></pre>
<h3 id="git-diff"><a href="#git-diff" class="headerlink" title="git diff"></a>git diff</h3><pre><code>git diff 显示暂存区和工作区的差异  
git diff filepath   filepath路径文件中，工作区与暂存区的比较差异  
git diff HEAD filepath 工作区与HEAD ( 当前工作分支)的比较差异  
git diff branchName filepath 当前分支的文件与branchName分支的文件的比较差异  
git diff commitId filepath 与某一次提交的比较差异  
</code></pre>
<p>如果你想对比一下你改了哪些内容，可以用git diff对比一下文件修改差异</p>
<h3 id="git-pull-git-fetch"><a href="#git-pull-git-fetch" class="headerlink" title="git pull&#x2F;git fetch"></a>git pull&#x2F;git fetch</h3><pre><code>git pull  拉取远程仓库所有分支更新并合并到本地分支。  
git pull origin master 将远程master分支合并到当前本地分支  
git pull origin master:master 将远程master分支合并到当前本地master分支，冒号后面表示本地分支  
git fetch --all  拉取所有远端的最新代码  
git fetch origin master 拉取远程最新master分支代码  
</code></pre>
<p>我们一般都会用git pull拉取最新代码看看的，解决一下冲突，再推送代码到远程仓库的。</p>
<blockquote>
<p>有些伙伴可能对使用git pull还是git fetch有点疑惑，其实 git pull &#x3D; git fetch+ git<br>merge。pull的话，拉取远程分支并与本地分支合并，fetch只是拉远程分支，怎么合并，可以自己再做选择。</p>
</blockquote>
<h3 id="git-push"><a href="#git-push" class="headerlink" title="git push"></a>git push</h3><p>git push 可以推送本地分支、标签到远程仓库，也可以删除远程分支。</p>
<pre><code>git push origin master 将本地分支的更新全部推送到远程仓库master分支。  
git push origin -d &lt;branchname&gt;   删除远程branchname分支  
git push --tags 推送所有标签  
</code></pre>
<p>如果我们在dev开发完，或者就想把文件推送到远程仓库，给别的伙伴看看，就可以使用git push origin dev</p>
<h3 id="git-branch"><a href="#git-branch" class="headerlink" title="git branch"></a>git branch</h3><p>git branch用处多多呢，比如新建分支、查看分支、删除分支等等</p>
<p><strong>新建分支：</strong></p>
<pre><code>git checkout -b dev2  新建一个分支，并且切换到新的分支dev2  
git branch dev2 新建一个分支，但是仍停留在原来分支  
</code></pre>
<p><strong>查看分支：</strong></p>
<pre><code>git branch    查看本地所有的分支  
git branch -r  查看所有远程的分支  
git branch -a  查看所有远程分支和本地分支  
</code></pre>
<p><strong>删除分支：</strong></p>
<pre><code>git branch -D &lt;branchname&gt;  删除本地branchname分支  
</code></pre>
<h3 id="git-checkout"><a href="#git-checkout" class="headerlink" title="git checkout"></a>git checkout</h3><p> <strong>切换分支：</strong></p>
<pre><code>git checkout master 切换到master分支  
</code></pre>
<h3 id="git-merge"><a href="#git-merge" class="headerlink" title="git merge"></a>git merge</h3><p>我们在开发分支dev开发、测试完成在发布之前，我们一般需要把开发分支dev代码合并到master，所以git merge也是程序员必备的一个命令。</p>
<pre><code>git merge master  在当前分支上合并master分支过来  
git merge --no-ff origin/dev  在当前分支上合并远程分支dev  
git merge --abort 终止本次merge，并回到merge前的状态  
</code></pre>
<p>比如，你开发完需求后，发版需要把代码合到主干master分支</p>
<h2 id="Git进阶之撤销与回退"><a href="#Git进阶之撤销与回退" class="headerlink" title="Git进阶之撤销与回退"></a><strong>Git进阶之撤销与回退</strong></h2><p>Git的撤销与回退，在日常工作中使用的比较频繁。比如我们想将某个修改后的文件撤销到上一个版本，或者想撤销某次多余的提交，都要用到git的撤销和回退操作。</p>
<p>代码在Git的每个工作区域都是用哪些命令撤销或者回退的呢，如下图所示：</p>
<p><img src="/images/git%E7%9A%84%E6%92%A4%E9%94%80%E4%B8%8E%E5%9B%9E%E9%80%80.jpg" alt="git的撤销与回退"></p>
<p>有关于Git的撤销与回退，一般就以下几个核心命令</p>
<ul>
<li>git checkout</li>
<li>git reset</li>
<li>git revert</li>
</ul>
<h3 id="git-checkout-1"><a href="#git-checkout-1" class="headerlink" title="git checkout"></a>git checkout</h3><p>如果文件还在 <strong>工作区</strong> ，还没添加到暂存区，可以使用git checkout撤销</p>
<pre><code>git checkout [file]  丢弃某个文件file  
git checkout .  丢弃所有文件  
</code></pre>
<h3 id="git-reset"><a href="#git-reset" class="headerlink" title="git reset"></a>git reset</h3><h4 id="git-reset的理解"><a href="#git-reset的理解" class="headerlink" title="git reset的理解"></a>git reset的理解</h4><blockquote>
<p>git reset的作用是修改HEAD的位置，即将HEAD指向的位置改变为之前存在的某个版本.</p>
</blockquote>
<p>为了更好地理解git reset，我们来回顾一下,Git的版本管理及HEAD的理解</p>
<blockquote>
<p>Git的所有提交，会连成一条时间轴线，这就是分支。如果当前分支是master，HEAD指针一般指向当前分支，如下：</p>
</blockquote>
<p><img src="/images/reset1.png" alt="reset1"></p>
<p>假设执行git reset，回退到版本二之后，版本三不见了,如下：</p>
<p><img src="/images/reset2.png" alt="reset2"></p>
<h4 id="git-reset的使用"><a href="#git-reset的使用" class="headerlink" title="git reset的使用"></a>git reset的使用</h4><p>Git Reset的几种使用模式</p>
<p><img src="/images/reset%E7%9A%84%E5%87%A0%E7%A7%8D%E4%BD%BF%E7%94%A8%E6%A8%A1%E5%BC%8F.png" alt="reset的几种使用模式"></p>
<pre><code>git reset HEAD --file回退暂存区里的某个文件，回退到当前版本工作区状态  
git reset –-soft 目标版本号 可以把版本库上的提交回退到暂存区，修改记录保留  
git reset –-mixed 目标版本号 可以把版本库上的提交回退到工作区，修改记录保留  
git reset –-hard  可以把版本库上的提交彻底回退，修改的记录全部revert。  
</code></pre>
<p>先看一个栗子demo吧，代码 <strong>git add到暂存区，并未commit提交</strong> ,可以酱紫回退，如下：</p>
<pre><code>git reset HEAD file 取消暂存  
git checkout file 撤销修改  
</code></pre>
<p>再看另外一个栗子吧，代码已经git commit了，但是还没有push：</p>
<pre><code>git log  获取到想要回退的commit_id  
git reset --hard commit_id  想回到过去，回到过去的commit_id  
</code></pre>
<p>如果代码已经push到远程仓库了呢，也可以使用reset回滚</p>
<pre><code>git log  
git reset --hard commit_id  
git push origin HEAD --force  
</code></pre>
<h3 id="git-revert"><a href="#git-revert" class="headerlink" title="git revert"></a>git revert</h3><blockquote>
<p>与git reset不同的是，revert复制了那个想要回退到的历史版本，将它加在当前分支的最前端。</p>
</blockquote>
<p><strong>revert之前：</strong></p>
<p><img src="/images/revert%E4%B9%8B%E5%89%8D.png" alt="revert之前"></p>
<p><strong>revert 之后：</strong></p>
<p><img src="/images/revert%E4%B9%8B%E5%90%8E.png" alt="revert之后"></p>
<p>当然，如果代码已经推送到远程的话，还可以考虑revert回滚</p>
<pre><code>git log  得到你需要回退一次提交的commit id  
git revert -n &lt;commit_id&gt;  撤销指定的版本，撤销也会作为一次提交进行保存  
</code></pre>
<h3 id="git-rebase"><a href="#git-rebase" class="headerlink" title="git rebase"></a>git rebase</h3><p>rebase又称为衍合，是合并的另外一种选择。</p>
<p>假设有两个分支master和test</p>
<pre><code>     D---E test        
    /  
A---B---C---F--- master  
  
</code></pre>
<p>执行 git merge test得到的结果</p>
<pre><code>      D--------E      
     /          \  
A---B---C---F----G---   test, master  
  
</code></pre>
<p>执行git rebase test，得到的结果</p>
<pre><code>A---B---D---E---C‘---F‘---   test, master  
  
</code></pre>
<p><strong>rebase好处是：</strong> 获得更优雅的提交树，可以线性的看到每一次提交，并且没有增加提交节点。所以很多时候，看到有些伙伴都是这个命令拉代码：git<br>pull –rebase，就是因为想更优雅，哈哈</p>
<h3 id="git-stash"><a href="#git-stash" class="headerlink" title="git stash"></a>git stash</h3><p>stash命令可用于临时保存和恢复修改</p>
<pre><code>git stash  把当前的工作隐藏起来 等以后恢复现场后继续工作  
git stash list 显示保存的工作进度列表  
git stash pop stash@&#123;num&#125; 恢复工作进度到工作区  
git stash show ：显示做了哪些改动  
git stash drop stash@&#123;num&#125; ：删除一条保存的工作进度  
git stash clear 删除所有缓存的stash。  
  
</code></pre>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/04/12/jvm/Java%E7%BA%BF%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="merric">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Myoboku">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Myoboku">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/04/12/jvm/Java%E7%BA%BF%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/" class="post-title-link" itemprop="url">Jvav线程间通信</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-04-12 22:30:00" itemprop="dateCreated datePublished" datetime="2020-04-12T22:30:00+00:00">2020-04-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h1><h2 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h2><h3 id="保证内存可见性"><a href="#保证内存可见性" class="headerlink" title="保证内存可见性"></a>保证内存可见性</h3><h4 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h4><p>可见性是指线程之间的可见性，一个线程修改的状态对另一个线程是可见的。也就是一个线程修改的结果，另一个线程马上就能看到。</p>
<h4 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h4><p>当对非volatile变量进行读写的时候，每个线程先从主内存拷贝变量到CPU缓存中，如果计算机有多个CPU，每个线程可能在不同的CPU上被处理，这意味着每个线程可以拷贝到不同的CPU<br>cache中。<br>volatile变量不会被缓存在寄存器或者对其他处理器不可见的地方，保证了每次读写变量都从主内存中读，跳过CPU<br>cache这一步。当一个线程修改了这个变量的值，新值对于其他线程是立即得知的。</p>
<p><img src="/images/volatile.png" alt="内存可见性问题"></p>
<h3 id="禁止指令重排序"><a href="#禁止指令重排序" class="headerlink" title="禁止指令重排序"></a>禁止指令重排序</h3><h4 id="基本概念-1"><a href="#基本概念-1" class="headerlink" title="基本概念"></a>基本概念</h4><p>指令重排序是JVM为了优化指令、提高程序运行效率，在不影响单线程程序执行结果的前提下，尽可能地提高并行度。指令重排序包括编译器重排序和运行时重排序。<br>在JDK1.5之后，可以使用volatile变量禁止指令重排序。针对volatile修饰的变量，在读写操作指令前后会插入内存屏障，指令重排序时不能把后面的指令重排序到内存屏</p>
<pre><code>示例说明：  
double r = 2.1; //(1)   
double pi = 3.14;//(2)   
double area = pi*r*r;//(3)1234  
</code></pre>
<p>虽然代码语句的定义顺序为1-&gt;2-&gt;3，但是计算顺序1-&gt;2-&gt;3与2-&gt;1-&gt;3对结果并无影响，所以编译时和运行时可以根据需要对1、2语句进行重排序。后面写文章分析一下JIT的问题，工作中同事提出了一个有意思的问题。。</p>
<h4 id="指令重排序带来的问题"><a href="#指令重排序带来的问题" class="headerlink" title="指令重排序带来的问题"></a>指令重排序带来的问题</h4><p>基于双重检验的单例模式(懒汉型)</p>
<pre><code>public class Singleton3 &#123;  
    private static Singleton3 instance = null;  
  
    private Singleton3() &#123;&#125;  
  
    public static Singleton3 getInstance() &#123;  
        if (instance == null) &#123;  
            synchronized(Singleton3.class) &#123;  
                if (instance == null)  
                    instance = new Singleton3();// 非原子操作  
            &#125;  
        &#125;  
  
        return instance;  
    &#125;  
&#125;12345678910111213141516  
  
</code></pre>
<p>instance&#x3D; new Singleton()并不是一个原子操作，其实际上可以抽象为下面几条JVM指令：</p>
<pre><code>memory =allocate();    //1：分配对象的内存空间   
ctorInstance(memory);  //2：初始化对象   
instance =memory;     //3：设置instance指向刚分配的内存地址123  
  
</code></pre>
<p>上面操作2依赖于操作1，但是操作3并不依赖于操作2。所以JVM是可以针对它们进行指令的优化重排序的，经过重排序后如下：</p>
<pre><code>memory =allocate();    //1：分配对象的内存空间   
instance =memory;     //3：instance指向刚分配的内存地址，此时对象还未初始化  
ctorInstance(memory);  //2：初始化对象123  
  
</code></pre>
<p>指令重排之后，instance指向分配好的内存放在了前面，而这段内存的初始化被排在了后面。在线程A执行这段赋值语句，在初始化分配对象之前就已经将其赋值给instance引用，恰好另一个线程进入方法判断instance引用不为null，然后就将其返回使用，导致出错。</p>
<p><strong>解决办法</strong><br>用volatile关键字修饰instance变量，使得instance在读、写操作前后都会插入内存屏障，避免重排序。</p>
<pre><code>public class Singleton3 &#123;  
    private static volatile Singleton3 instance = null;  
  
    private Singleton3() &#123;&#125;  
  
    public static Singleton3 getInstance() &#123;  
        if (instance == null) &#123;  
            synchronized(Singleton3.class) &#123;  
                if (instance == null)  
                    instance = new Singleton3();  
            &#125;  
        &#125;  
        return instance;  
    &#125;  
  
</code></pre>
<p>volatile关键字提供内存屏障的方式来防止指令被重排，编译器在生成字节码文件时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。</p>
<p>JVM内存屏障插入策略：</p>
<ol>
<li>每个volatile写操作的前面插入一个StoreStore屏障；</li>
<li>在每个volatile写操作的后面插入一个StoreLoad屏障；</li>
<li>在每个volatile读操作的后面插入一个LoadLoad屏障；</li>
<li>在每个volatile读操作的后面插入一个LoadStore屏障。</li>
</ol>
<h2 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h2><ul>
<li>volatile是 <strong>轻量级同步机制</strong> 。在访问volatile变量时不会执行加锁操作，因此也就不会使执行线程阻塞，是一种比synchronized关键字更轻量级的同步机制。</li>
<li>volatile <strong>无法同时保证内存可见性和原子性</strong> 。加锁机制既可以确保可见性又可以确保原子性，而volatile变量 <strong>只能确保可见性</strong> 。</li>
<li>volatile不能修饰写入操作依赖当前值的变量。声明为volatile的简单变量如果当前值与该变量以前的值相关，那么volatile关键字不起作用，也就是说如下的表达式都不是原子操作：“count++”、“count &#x3D; count+1”。</li>
<li>当要访问的变量已在synchronized代码块中，或者为常量时，没必要使用volatile；</li>
<li>volatile屏蔽掉了JVM中必要的代码优化，所以在效率上比较低，因此一定在必要时才使用此关键字。</li>
</ul>
<p>虽然volatile只能保证可见性不能保证原子性，但用volatile修饰long和double可以保证其操作原子性。</p>
<p>所以从Oracle Java Spec里面可以看到：</p>
<ul>
<li>对于64位的long和double，如果没有被volatile修饰，那么对其操作可以不是原子的。在操作的时候，可以分成两步，每次对32位操作。</li>
<li>如果使用volatile修饰long和double，那么其读写都是原子操作</li>
<li>对于64位的引用地址的读写，都是原子操作</li>
<li>在实现JVM时，可以自由选择是否把读写long和double作为原子操作</li>
<li>推荐JVM实现为原子操作</li>
</ul>
<h1 id="synchronized"><a href="#synchronized" class="headerlink" title="synchronized"></a>synchronized</h1><p>众所周知 <code>synchronized</code> 关键字是解决并发问题常用解决方案，有以下三种使用方式:</p>
<ul>
<li>同步普通方法，锁的是当前对象。</li>
<li>同步静态方法，锁的是当前 <code>Class</code> 对象。</li>
<li>同步块，锁的是 <code>()</code> 中的对象。</li>
</ul>
<h2 id="实现原理-1"><a href="#实现原理-1" class="headerlink" title="实现原理"></a>实现原理</h2><p><code>JVM</code> 是通过进入、退出对象监视器( <code>Monitor</code> )来实现对方法、同步块的同步的。</p>
<p>具体实现是在编译之后在同步方法调用前加入一个 <code>monitor.enter</code> 指令，在退出方法和异常处插入 <code>monitor.exit</code> 的指令。</p>
<p>其本质就是对一个对象监视器( <code>Monitor</code> )进行获取，而这个获取过程具有排他性从而达到了同一时刻只能一个线程访问的目的。</p>
<p>而对于没有获取到锁的线程将会阻塞到方法入口处，直到获取锁的线程 <code>monitor.exit</code> 之后才能尝试继续获取锁。</p>
<h2 id="锁优化"><a href="#锁优化" class="headerlink" title="锁优化"></a>锁优化</h2><p><code>synchronized</code> 很多都称之为重量锁，<code>JDK1.6</code> 中对 <code>synchronized</code><br>进行了各种优化，为了能减少获取和释放锁带来的消耗引入了<code>偏向锁</code>和<code>轻量锁</code>。</p>
<p>Java SE 1.6中，锁一共有4种状态，级别从低到高依次是： <strong>无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态</strong><br>，这几个状态会随着竞争情况逐渐升级。 <strong>锁可以升级但不能降级</strong><br>，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。对象的MarkWord变化为下图：</p>
<p><img src="/images/Java%E5%AF%B9%E8%B1%A1%E5%A4%B4MarkWord.png" alt="Java对象头MarkWord"></p>
<h3 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h3><p>HotSpot的作者经过研究发现，大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。</p>
<h4 id="获取锁"><a href="#获取锁" class="headerlink" title="获取锁"></a>获取锁</h4><p>当一个线程访问同步块并获取锁时，会在 <strong>对象头</strong> 和 <strong>栈帧中的锁记录</strong><br>里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark<br>Word里是否存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁。如果测试失败，则需要再测试一下Mark<br>Word中偏向锁的标识是否设置成1（表示当前是偏向锁）：如果没有设置，则使用CAS竞争锁；如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程</p>
<h4 id="释放锁"><a href="#释放锁" class="headerlink" title="释放锁"></a>释放锁</h4><p>偏向锁使用了一种 <strong>等到竞争出现才释放锁</strong> 的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。</p>
<p><img src="/images/%E5%81%8F%E5%90%91%E9%94%81%E7%9A%84%E6%92%A4%E9%94%80.png" alt="偏向锁的撤销"></p>
<p>如图，偏向锁的撤销，需要等待 <strong>全局安全点</strong><br>（在这个时间点上没有正在执行的字节码）。它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态；如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark<br>Word <strong>要么</strong> 重新偏向于其他线程， <strong>要么</strong> 恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。</p>
<p>如果配置中关闭偏向锁，则直接进入轻量级锁</p>
<h3 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h3><p>当偏向锁出现锁竞争时，就会升级为轻量级锁。</p>
<h4 id="加锁"><a href="#加锁" class="headerlink" title="加锁"></a>加锁</h4><p>线程在执行同步块之前，JVM会先在当前线程的栈桢中 <strong>创建用于存储锁记录的空间</strong> ，并将对象头中的Mark Word复制到锁记录中，官方称为<br><strong>Displaced Mark Word</strong> 。然后线程尝试使用CAS <strong>将对象头中的Mark Word替换为指向锁记录的指针</strong><br>。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。</p>
<h4 id="解锁"><a href="#解锁" class="headerlink" title="解锁"></a>解锁</h4><p>轻量级解锁时，会使用原子的CAS操作将Displaced Mark<br>Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。</p>
<p>因为自旋会消耗CPU，为了避免无用的自旋（比如获得锁的线程被阻塞住了），一旦锁升级成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时，都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮的夺锁之争。</p>
<h3 id="其他优化"><a href="#其他优化" class="headerlink" title="其他优化"></a>其他优化</h3><h4 id="适应性自旋"><a href="#适应性自旋" class="headerlink" title="适应性自旋"></a>适应性自旋</h4><p>在使用 <code>CAS</code> 时，如果操作失败，<code>CAS</code> 会自旋再次尝试。由于自旋是需要消耗 <code>CPU</code> 资源的，所以如果长期自旋就白白浪费了<br><code>CPU</code>。<code>JDK1.6</code>加入了适应性自旋:</p>
<blockquote>
<p>如果某个锁自旋很少成功获得，那么下一次就会减少自旋。</p>
</blockquote>
<p>这里还需要提一下，重量级锁是可以降级的，在GC中STW时，<br><strong>重量级锁的降级发生于STW阶段，降级对象就是那些仅仅能被VMThread访问而没有其他JavaThread访问的对象。</strong></p>
<h1 id="AQS"><a href="#AQS" class="headerlink" title="AQS"></a>AQS</h1><p><img src="/images/AQS%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="AQS架构图"></p>
<h2 id="原理概述"><a href="#原理概述" class="headerlink" title="原理概述"></a>原理概述</h2><p>AQS核心思想是，如果被请求的共享资源空闲，那么就将当前请求资源的线程设置为有效的工作线程，将共享资源设置为锁定状态；如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要用的是CLH队列的变体实现的，将暂时获取不到锁的线程加入到队列中。</p>
<p>CLH：Craig、Landin and<br>Hagersten队列，是单向链表，AQS中的队列是CLH变体的虚拟双向队列（FIFO），AQS是通过将每条请求共享资源的线程封装成一个节点来实现锁的分配。</p>
<p><img src="/images/CLH%E9%98%9F%E5%88%97.png" alt="CLH队列"></p>
<h3 id="AQS数据结构"><a href="#AQS数据结构" class="headerlink" title="AQS数据结构"></a>AQS数据结构</h3><pre><code>// 队列的数据结构如下  
// 结点的数据结构  
static final class Node &#123;  
    // 表示该节点等待模式为共享式，通常记录于nextWaiter，  
    // 通过判断nextWaiter的值可以判断当前结点是否处于共享模式  
    static final Node SHARED = new Node();  
    // 表示节点处于独占式模式，与SHARED相对  
    static final Node EXCLUSIVE = null;  
    // waitStatus的不同状态，具体内容见下文的表格  
    static final int CANCELLED =  1;  
    static final int SIGNAL    = -1;  
    static final int CONDITION = -2;  
    static final int PROPAGATE = -3;  
    volatile int waitStatus;  
    // 记录前置结点  
    volatile Node prev;  
    // 记录后置结点  
    volatile Node next;  
    // 记录当前的线程  
    volatile Thread thread;  
    // 用于记录共享模式(SHARED), 也可以用来记录CONDITION队列(见扩展分析)  
    Node nextWaiter;  
    // 通过nextWaiter的记录值判断当前结点的模式是否为共享模式  
    final boolean isShared() &#123;	return nextWaiter == SHARED;&#125;  
    // 获取当前结点的前置结点  
    final Node predecessor() throws NullPointerException &#123; ... &#125;  
    // 用于初始化时创建head结点或者创建SHARED结点  
    Node() &#123;&#125;  
    // 在addWaiter方法中使用，用于创建一个新的结点  
    Node(Thread thread, Node mode) &#123;       
        this.nextWaiter = mode;  
        this.thread = thread;  
    &#125;  
    // 在CONDITION队列中使用该构造函数新建结点  
    Node(Thread thread, int waitStatus) &#123;   
        this.waitStatus = waitStatus;  
        this.thread = thread;  
    &#125;  
&#125;  
// 记录头结点  
private transient volatile Node head;  
// 记录尾结点  
private transient volatile Node tail;  
  
</code></pre>
<p>Node状态表(waitStatus，初始化时默认为0)</p>
<table>
<thead>
<tr>
<th>状态名称</th>
<th>状态值</th>
<th>状态描述</th>
</tr>
</thead>
<tbody><tr>
<td>CANCELLED</td>
<td>1</td>
<td>说明当前结点(即相应的线程)是因为超时或者中断取消的，进入该状态后将无法恢复</td>
</tr>
<tr>
<td>SIGNAL</td>
<td>-1</td>
<td></td>
</tr>
<tr>
<td>说明当前结点的后继结点是(或者将要)由park导致阻塞的，当结点被释放或者取消时，需要通过unpark唤醒后继结点(表现为unparkSuccessor()方法)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>CONDITION</td>
<td>-2</td>
<td></td>
</tr>
<tr>
<td>该状态是用于condition队列结点的，表明结点在等待队列中，结点线程等待在Condition上，当其他线程对Condition调用了signal()方法时，会将其加入到同步队列中去</td>
<td></td>
<td></td>
</tr>
<tr>
<td>PROPAGATE</td>
<td>-3</td>
<td>说明下一次共享式同步状态的获取将会无条件地向后继结点传播</td>
</tr>
</tbody></table>
<h3 id="AQS的重要方法"><a href="#AQS的重要方法" class="headerlink" title="AQS的重要方法"></a>AQS的重要方法</h3><p>从架构图中可以得知，AQS提供了大量用于自定义同步器实现的Protected方法。自定义同步器实现的相关方法也只是为了通过修改State字段来实现多线程的独占模式或者共享模式。自定义同步器需要实现以下方法（并不是全部）：</p>
<table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>protected boolean isHeldExclusively()</td>
<td>该线程是否正在独占资源。只有用到Condition才需要去实现它。</td>
</tr>
<tr>
<td>protected boolean tryAcquire(int arg)</td>
<td></td>
</tr>
<tr>
<td>独占方式。arg为获取锁的次数，尝试获取资源，成功则返回True，失败则返回False。</td>
<td></td>
</tr>
<tr>
<td>protected boolean tryRelease(int arg)</td>
<td></td>
</tr>
<tr>
<td>独占方式。arg为释放锁的次数，尝试释放资源，成功则返回True，失败则返回False。</td>
<td></td>
</tr>
<tr>
<td>protected int tryAcquireShared(int arg)</td>
<td></td>
</tr>
<tr>
<td>共享方式。arg为获取锁的次数，尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。</td>
<td></td>
</tr>
<tr>
<td>protected boolean tryReleaseShared(int arg)</td>
<td></td>
</tr>
<tr>
<td>共享方式。arg为释放锁的次数，尝试释放资源，如果释放后允许唤醒后续等待结点返回True，否则返回False。</td>
<td></td>
</tr>
</tbody></table>
<p>一般来说，自定义同步器要么是独占方式，要么是共享方式，它们也只需实现tryAcquire-tryRelease、tryAcquireShared-<br>tryReleaseShared中的一种即可。AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。ReentrantLock是独占锁，所以实现了tryAcquire-<br>tryRelease。</p>
<p>以非公平锁为例，这里主要阐述一下非公平锁与AQS之间方法的关联之处，具体每一处核心方法的作用会在文章后面详细进行阐述。</p>
<p><img src="/images/%E5%85%AC%E5%B9%B3%E9%94%81%E5%92%8C%E9%9D%9E%E5%85%AC%E5%B9%B3%E9%94%81%E6%B5%81%E7%A8%8B.png" alt="公平锁和非公平锁加锁流程"></p>
<p>以非公平锁ReentrantLock为例，加锁和解锁的流程如下：</p>
<p><img src="/images/ReentrantLock%E5%8A%A0%E9%94%81%E5%92%8C%E8%A7%A3%E9%94%81%E6%B5%81%E7%A8%8B.png" alt="ReentrantLock加锁和解锁流程"></p>
<p>加锁：</p>
<ul>
<li>通过ReentrantLock的加锁方法Lock进行加锁操作。</li>
<li>会调用到内部类Sync的Lock方法，由于Sync#lock是抽象方法，根据ReentrantLock初始化选择的公平锁和非公平锁，执行相关内部类的Lock方法，本质上都会执行AQS的Acquire方法。</li>
<li>AQS的Acquire方法会执行tryAcquire方法，但是由于tryAcquire需要自定义同步器实现，因此执行了ReentrantLock中的tryAcquire方法，由于ReentrantLock是通过公平锁和非公平锁内部类实现的tryAcquire方法，因此会根据锁类型不同，执行不同的tryAcquire。</li>
<li>tryAcquire是获取锁逻辑，获取失败后，会执行框架AQS的后续逻辑，跟ReentrantLock自定义同步器无关。</li>
</ul>
<p>解锁：</p>
<ul>
<li>通过ReentrantLock的解锁方法Unlock进行解锁。</li>
<li>Unlock会调用内部类Sync的Release方法，该方法继承于AQS。</li>
<li>Release中会调用tryRelease方法，tryRelease需要自定义同步器实现，tryRelease只在ReentrantLock中的Sync实现，因此可以看出，释放锁的过程，并不区分是否为公平锁。</li>
<li>释放成功后，所有处理由AQS框架完成，与自定义同步器无关。</li>
</ul>
<h4 id="acquire方法"><a href="#acquire方法" class="headerlink" title="acquire方法"></a>acquire方法</h4><pre><code>// 这里不去看tryAcquire、tryRelease方法的具体实现，只知道它们的作用分别为尝试获取同步状态、尝试释放同步状态  
  
public final void acquire(int arg) &#123;  
    // 如果线程直接获取成功，或者再尝试获取成功后都是直接工作，  
    // 如果是从阻塞状态中唤醒开始工作的线程，将当前的线程中断  
    if (!tryAcquire(arg) &amp;&amp;  
        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))  
        selfInterrupt();  
&#125;  
// 包装线程，新建结点并加入到同步队列中  
private Node addWaiter(Node mode) &#123;  
    Node node = new Node(Thread.currentThread(), mode);  
    Node pred = tail;  
    // 尝试入队， 成功返回  
    if (pred != null) &#123;  
        node.prev = pred;  
        // CAS操作设置队尾  
        if (compareAndSetTail(pred, node)) &#123;  
            pred.next = node;  
            return node;  
        &#125;  
    &#125;  
    // 通过CAS操作自旋完成node入队操作  
    enq(node);  
    return node;  
&#125;  
&#125;  
  
</code></pre>
<p>addWaiter主要的流程如下：</p>
<ul>
<li><p>通过当前的线程和锁模式新建一个节点。</p>
</li>
<li><p>Pred指针指向尾节点Tail。</p>
</li>
<li><p>将New中Node的Prev指针指向Pred。</p>
</li>
<li><p>通过compareAndSetTail方法，完成尾节点的设置。这个方法主要是对tailOffset和Expect进行比较，如果tailOffset的Node和Expect的Node地址是相同的，那么设置Tail的值为Update的值。</p>
<p>static {<br>try {<br>    stateOffset &#x3D; unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField(“state”));<br>    headOffset &#x3D; unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField(“head”));<br>    tailOffset &#x3D; unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField(“tail”));<br>    waitStatusOffset &#x3D; unsafe.objectFieldOffset(Node.class.getDeclaredField(“waitStatus”));<br>    nextOffset &#x3D; unsafe.objectFieldOffset(Node.class.getDeclaredField(“next”));<br>} catch (Exception ex) {<br>throw new Error(ex);<br>  }<br>}</p>
</li>
</ul>
<p>从AQS的静态代码块可以看出，都是获取一个对象的属性相对于该对象在内存当中的偏移量，这样我们就可以根据这个偏移量在对象内存当中找到这个属性。tailOffset指的是tail对应的偏移量，所以这个时候会将new出来的Node置为当前队列的尾节点。同时，由于是双向链表，也需要将前一个节点指向尾节点。</p>
<ul>
<li><p>如果Pred指针是Null（说明等待队列中没有元素），或者当前Pred指针和Tail指向的位置不同（说明被别的线程已经修改），就需要看一下Enq的方法。</p>
<p>&#x2F;&#x2F; java.util.concurrent.locks.AbstractQueuedSynchronizer  </p>
<p>private Node enq(final Node node) {<br>for (;;) {<br>    Node t &#x3D; tail;<br>    if (t &#x3D;&#x3D; null) { &#x2F;&#x2F; Must initialize<br>        if (compareAndSetHead(new Node()))<br>            tail &#x3D; head;<br>    } else {<br>        node.prev &#x3D; t;<br>        if (compareAndSetTail(t, node)) {<br>            t.next &#x3D; node;<br>            return t;<br>        }<br>    }<br>}<br>}</p>
</li>
</ul>
<p>如果没有被初始化，需要进行初始化一个头结点出来。但请注意，初始化的头结点并不是当前线程节点，而是调用了无参构造函数的节点。如果经历了初始化或者并发导致队列中有元素，则与之前的方法相同。其实，addWaiter就是一个在双端链表添加尾节点的操作，需要注意的是，双端链表的头结点是一个无参构造函数的头结点。</p>
<pre><code>// 在同步队列中等待获取同步状态  
final boolean acquireQueued(final Node node, int arg) &#123;  
    boolean failed = true;  
    try &#123;  
        boolean interrupted = false;  
        // 自旋  
        for (;;) &#123;  
            final Node p = node.predecessor();  
            // 检查是否符合开始工作的条件  
            if (p == head &amp;&amp; tryAcquire(arg)) &#123;  
                setHead(node);  
                p.next = null;  
                failed = false;  
                return interrupted;  
            &#125;  
            // 获取不到同步状态，将前置结点标为SIGNAL状态并且通过park操作将node包装的线程阻塞  
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;  
                parkAndCheckInterrupt())  
                interrupted = true;  
        &#125;  
    &#125; finally &#123;  
        // 如果获取失败，将node标记为CANCELLED  
        if (failed)  
            cancelAcquire(node);  
    &#125;  

//setHead方法是把当前节点置为虚节点，但并没有修改waitStatus，因为它是一直需要用的数据。  
private void setHead(Node node) &#123;  
    head = node;  
    node.thread = null;  
    node.prev = null;  
&#125;  
  
// java.util.concurrent.locks.AbstractQueuedSynchronizer  
  
// 靠前驱节点判断当前线程是否应该被阻塞  
private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123;  
    // 获取头结点的节点状态  
    int ws = pred.waitStatus;  
    // 说明头结点处于唤醒状态  
    if (ws == Node.SIGNAL)  
        return true;   
    // 通过枚举值我们知道waitStatus&gt;0是取消状态  
    if (ws &gt; 0) &#123;  
        do &#123;  
            // 循环向前查找取消节点，把取消节点从队列中剔除  
            node.prev = pred = pred.prev;  
        &#125; while (pred.waitStatus &gt; 0);  
        pred.next = node;  
    &#125; else &#123;  
        // 设置前任节点等待状态为SIGNAL  
        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);  
    &#125;  
    return false;  
&#125;  
  
</code></pre>
<p>parkAndCheckInterrupt主要用于挂起当前线程，阻塞调用栈，返回当前线程的中断状态。</p>
<pre><code>// java.util.concurrent.locks.AbstractQueuedSynchronizer  
  
private final boolean parkAndCheckInterrupt() &#123;  
    LockSupport.park(this);  
    return Thread.interrupted();  
&#125;  
</code></pre>
<h4 id="cancelAcquire方法"><a href="#cancelAcquire方法" class="headerlink" title="cancelAcquire方法"></a>cancelAcquire方法</h4><pre><code>private void cancelAcquire(Node node) &#123;  
  // 将无效节点过滤  
    if (node == null)  
        return;  
  // 设置该节点不关联任何线程，也就是虚节点  
    node.thread = null;  
    Node pred = node.prev;  
  // 通过前驱节点，跳过取消状态的node  
    while (pred.waitStatus &gt; 0)  
        node.prev = pred = pred.prev;  
  // 获取过滤后的前驱节点的后继节点  
    Node predNext = pred.next;  
  // 把当前node的状态设置为CANCELLED  
    node.waitStatus = Node.CANCELLED;  
  // 如果当前节点是尾节点，将从后往前的第一个非取消状态的节点设置为尾节点  
  // 更新失败的话，则进入else，如果更新成功，将tail的后继节点设置为null  
    if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123;  
        compareAndSetNext(pred, predNext, null);  
    &#125; else &#123;  
        int ws;  
    // 如果当前节点不是head的后继节点，1:判断当前节点前驱节点的是否为SIGNAL，2:如果不是，则把前驱节点设置为SINGAL看是否成功  
    // 如果1和2中有一个为true，再判断当前节点的线程是否为null  
    // 如果上述条件都满足，把当前节点的前驱节点的后继指针指向当前节点的后继节点  
        if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) &#123;  
            Node next = node.next;  
            if (next != null &amp;&amp; next.waitStatus &lt;= 0)  
                compareAndSetNext(pred, predNext, next);  
        &#125; else &#123;  
      // 如果当前节点是head的后继节点，或者上述条件不满足，那就唤醒当前节点的后继节点  
            unparkSuccessor(node);  
        &#125;  
        node.next = node; // help GC  
    &#125;  
&#125;  
  
</code></pre>
<p>当前的流程：</p>
<ul>
<li>获取当前节点的前驱节点，如果前驱节点的状态是CANCELLED，那就一直往前遍历，找到第一个waitStatus &lt;&#x3D; 0的节点，将找到的Pred节点和当前Node关联，将当前Node设置为CANCELLED。</li>
<li>根据当前节点的位置，考虑以下三种情况：</li>
</ul>
<p>(1) 当前节点是尾节点。</p>
<p>(2) 当前节点是Head的后继节点。</p>
<p>(3) 当前节点不是Head的后继节点，也不是尾节点。</p>
<p><strong>执行cancelAcquire的时候，当前节点的前置节点可能已经从队列中出去了（已经执行过Try代码块中的shouldParkAfterFailedAcquire方法了），如果此时修改Prev指针，有可能会导致Prev指向另一个已经移除队列的Node，因此这块变化Prev指针不安全。<br>shouldParkAfterFailedAcquire方法中，会执行下面的代码，其实就是在处理Prev指针。shouldParkAfterFailedAcquire是获取锁失败的情况下才会执行，进入该方法后，说明共享资源已被获取，当前节点之前的节点都不会出现变化，因此这个时候变更Prev指针比较安全。</strong></p>
<pre><code>do &#123;  
    node.prev = pred = pred.prev;  
&#125; while (pred.waitStatus &gt; 0);  
  
</code></pre>
<h4 id="unlock方法"><a href="#unlock方法" class="headerlink" title="unlock方法"></a><strong>unlock方法</strong></h4><pre><code>public void unlock() &#123;  
    sync.release(1);  
&#125;  
  
</code></pre>
<p>可以看到，本质释放锁的地方，是通过框架来完成的。</p>
<pre><code>// java.util.concurrent.locks.AbstractQueuedSynchronizer  
  
public final boolean release(int arg) &#123;  
    if (tryRelease(arg)) &#123;  
        Node h = head;  
        if (h != null &amp;&amp; h.waitStatus != 0)  
            unparkSuccessor(h);  
        return true;  
    &#125;  
    return false;  
&#125;  
  
</code></pre>
<p>在ReentrantLock里面的公平锁和非公平锁的父类Sync定义了可重入锁的释放锁机制。</p>
<pre><code>// java.util.concurrent.locks.ReentrantLock.Sync  
  
// 方法返回当前锁是不是没有被线程持有  
protected final boolean tryRelease(int releases) &#123;  
    // 减少可重入次数  
    int c = getState() - releases;  
    // 当前线程不是持有锁的线程，抛出异常  
    if (Thread.currentThread() != getExclusiveOwnerThread())  
        throw new IllegalMonitorStateException();  
    boolean free = false;  
    // 如果持有线程全部释放，将当前独占锁所有线程设置为null，并更新state  
    if (c == 0) &#123;  
        free = true;  
        setExclusiveOwnerThread(null);  
    &#125;  
    setState(c);  
    return free;  
&#125;  
  
</code></pre>
<p>我们来解释下述源码：</p>
<pre><code>// java.util.concurrent.locks.AbstractQueuedSynchronizer  
  
public final boolean release(int arg) &#123;  
    // 上边自定义的tryRelease如果返回true，说明该锁没有被任何线程持有  
    if (tryRelease(arg)) &#123;  
        // 获取头结点  
        Node h = head;  
        // 头结点不为空并且头结点的waitStatus不是初始化节点情况，解除线程挂起状态  
        if (h != null &amp;&amp; h.waitStatus != 0)  
            unparkSuccessor(h);  
        return true;  
    &#125;  
    return false;  
&#125;  
  
</code></pre>
<p>这里的判断条件为什么是h !&#x3D; null &amp;&amp; h.waitStatus !&#x3D; 0？</p>
<blockquote>
<p>h &#x3D;&#x3D; null Head还没初始化。初始情况下，head &#x3D;&#x3D;<br>null，第一个节点入队，Head会被初始化一个虚拟节点。所以说，这里如果还没来得及入队，就会出现head &#x3D;&#x3D; null 的情况。</p>
<p>h !&#x3D; null &amp;&amp; waitStatus &#x3D;&#x3D; 0 表明后继节点对应的线程仍在运行中，不需要唤醒。</p>
<p>h !&#x3D; null &amp;&amp; waitStatus &lt; 0 表明后继节点可能被阻塞了，需要唤醒。</p>
</blockquote>
<p>再看一下unparkSuccessor方法：</p>
<pre><code>// java.util.concurrent.locks.AbstractQueuedSynchronizer  
  
private void unparkSuccessor(Node node) &#123;  
    // 获取头结点waitStatus  
    int ws = node.waitStatus;  
    if (ws &lt; 0)  
        compareAndSetWaitStatus(node, ws, 0);  
    // 获取当前节点的下一个节点  
    Node s = node.next;  
    // 如果下个节点是null或者下个节点被cancelled，就找到队列最开始的非cancelled的节点  
    if (s == null || s.waitStatus &gt; 0) &#123;  
        s = null;  
        // 就从尾部节点开始找，到队首，找到队列第一个waitStatus&lt;0的节点。  
        for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev)  
            if (t.waitStatus &lt;= 0)  
                s = t;  
    &#125;  
    // 如果当前节点的下个节点不为空，而且状态&lt;=0，就把当前节点unpark  
    if (s != null)  
        LockSupport.unpark(s.thread);  
&#125;  
  
</code></pre>
<p>为什么要从后往前找第一个非Cancelled的节点呢？原因如下。</p>
<p>之前的addWaiter方法：</p>
<pre><code>// java.util.concurrent.locks.AbstractQueuedSynchronizer  
  
private Node addWaiter(Node mode) &#123;  
    Node node = new Node(Thread.currentThread(), mode);  
    // Try the fast path of enq; backup to full enq on failure  
    Node pred = tail;  
    if (pred != null) &#123;  
        node.prev = pred;  
        if (compareAndSetTail(pred, node)) &#123;  
            pred.next = node;  
            return node;  
        &#125;  
    &#125;  
    enq(node);  
    return node;  
&#125;  
  
</code></pre>
<p>我们从这里可以看到，节点入队并不是原子操作，也就是说，node.prev &#x3D; pred; compareAndSetTail(pred, node)<br>这两个地方可以看作Tail入队的原子操作，但是此时pred.next &#x3D;<br>node;还没执行，如果这个时候执行了unparkSuccessor方法，就没办法从前往后找了，所以需要从后往前找。还有一点原因，在产生CANCELLED状态节点的时候，先断开的是Next指针，Prev指针并未断开，因此也是必须要从后往前遍历才能够遍历完全部的Node。</p>
<p>综上所述，如果是从前往后找，由于极端情况下入队的非原子操作和CANCELLED节点产生过程中断开Next指针的操作，可能会导致无法遍历所有的节点。所以，唤醒对应的线程后，对应的线程就会继续往下执行。继续执行acquireQueued方法以后，中断如何处理？</p>
<h3 id="中断恢复后的执行流程"><a href="#中断恢复后的执行流程" class="headerlink" title="中断恢复后的执行流程"></a>中断恢复后的执行流程</h3><p>唤醒后，会执行return Thread.interrupted();，这个函数返回的是当前执行线程的中断状态，并清除。</p>
<pre><code>// java.util.concurrent.locks.AbstractQueuedSynchronizer  
  
private final boolean parkAndCheckInterrupt() &#123;  
    LockSupport.park(this);  
    return Thread.interrupted();  
&#125;  
</code></pre>
<p>再回到acquireQueued代码，当parkAndCheckInterrupt返回True或者False的时候，interrupted的值不同，但都会执行下次循环。如果这个时候获取锁成功，就会把当前interrupted返回。</p>
<pre><code>// java.util.concurrent.locks.AbstractQueuedSynchronizer  
  
final boolean acquireQueued(final Node node, int arg) &#123;  
    boolean failed = true;  
    try &#123;  
        boolean interrupted = false;  
        for (;;) &#123;  
            final Node p = node.predecessor();  
            if (p == head &amp;&amp; tryAcquire(arg)) &#123;  
                setHead(node);  
                p.next = null; // help GC  
                failed = false;  
                return interrupted;  
            &#125;  
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt())  
                interrupted = true;  
            &#125;  
    &#125; finally &#123;  
        if (failed)  
            cancelAcquire(node);  
    &#125;  
&#125;  
  
</code></pre>
<p>如果acquireQueued为True，就会执行selfInterrupt方法。</p>
<pre><code>// java.util.concurrent.locks.AbstractQueuedSynchronizer  
  
static void selfInterrupt() &#123;  
    Thread.currentThread().interrupt();  
&#125;  
  
</code></pre>
<p>该方法其实是为了中断线程。但为什么获取了锁以后还要中断线程呢？这部分属于Java提供的协作式中断知识内容，感兴趣同学可以查阅一下。这里简单介绍一下：</p>
<ol>
<li>当中断线程被唤醒时，并不知道被唤醒的原因，可能是当前线程在等待中被中断，也可能是释放了锁以后被唤醒。因此我们通过Thread.interrupted()方法检查中断标记（该方法返回了当前线程的中断状态，并将当前线程的中断标识设置为False），并记录下来，如果发现该线程被中断过，就再中断一次。</li>
<li>线程在等待资源的过程中被唤醒，唤醒后还是会不断地去尝试获取锁，直到抢到锁为止。也就是说，在整个流程中，并不响应中断，只是记录中断记录。最后抢到锁返回了，那么如果被中断过的话，就需要补充一次中断。</li>
</ol>
<h1 id="原子类"><a href="#原子类" class="headerlink" title="原子类"></a>原子类</h1><p>原子操作是指一个不受其他操作影响的操作任务单元。原子操作是在多线程环境下避免数据不一致必须的手段。</p>
<p>int++并不是一个原子操作，所以当一个线程读取它的值并加 1 时，另外一个线程有可能会读到之前的值，这就会引发错误。</p>
<p>为了解决这个问题，必须保证增加操作是原子的，在 JDK1.5 之前我们可以使用同步技术来做到这一点。到<br>JDK1.5，java.util.concurrent.atomic 包提供了 int 和long<br>类型的原子包装类，它们可以自动的保证对于他们的操作是原子的并且不需要使用同步。</p>
<p>java.util.concurrent<br>这个包里面提供了一组原子类。其基本的特性就是在多线程环境下，当有多个线程同时执行这些类的实例包含的方法时，具有排他性，即当某个线程进入方法，执行其中的指令时，不会被其他线程打断，而别的线程就像自旋锁一样，一直等到该方法执行完成，才由<br>JVM 从等待队列中选择另一个线程进入，这只是一种逻辑上的理解。</p>
<p>原子类：AtomicBoolean，AtomicInteger，AtomicLong，AtomicReference</p>
<p>原子数组：AtomicIntegerArray，AtomicLongArray，AtomicReferenceArray</p>
<p>原子属性更新器：AtomicLongFieldUpdater，AtomicIntegerFieldUpdater，AtomicReferenceFieldUpdater</p>
<p>解决 ABA 问题的原子类：AtomicMarkableReference（通过引入一个<br>boolean来反映中间有没有变过），AtomicStampedReference（通过引入一个 int 来累加来反映中间有没有变过）</p>
<h2 id="AtomicInteger举例"><a href="#AtomicInteger举例" class="headerlink" title="AtomicInteger举例"></a>AtomicInteger举例</h2><pre><code>public class AtomicInteger extends Number implements java.io.Serializable &#123;  
    
    private static final sun.misc.Unsafe U = sun.misc.Unsafe.getUnsafe();  
    private static final long VALUE;  
  
    private volatile int value;//注意该值用volatile修饰  
  
    public AtomicInteger(int initialValue) &#123;  
        value = initialValue;  
    &#125;  
    //以原子的方式将输入的值与ActomicInteger中的值进行相加，  
    //注意：返回相加前ActomicInteger中的值  
    public final int getAndAdd(int delta) &#123;  
        return U.getAndAddInt(this, VALUE, delta);  
    &#125;  
    //以原子的方式将输入的值与ActomicInteger中的值进行相加，  
    //注意：返回相加后的结果  
    public final int addAndGet(int delta) &#123;  
        return U.getAndAddInt(this, VALUE, delta) + delta;  
    &#125;  
    //以原子方式将当前ActomicInteger中的值加1,  
    //注意：返回相加前ActomicInteger中的值  
    public final int getAndIncrement() &#123;  
        return U.getAndAddInt(this, VALUE, 1);  
    &#125;  
    //以原子方式将当前ActomicInteger中的值加1,  
    //注意：返回相加后的结果  
    public final int incrementAndGet() &#123;  
        return U.getAndAddInt(this, VALUE, 1) + 1;  
    &#125;  
  
    //省略部分代码...  
  &#125;  
  
</code></pre>
<p>AtomicInteger内部会调用其中sun.misc.Unsafe方法中getAndAddInt的方法。具体代码如下：</p>
<pre><code>public final int getAndAdd(int delta) &#123;  
       return U.getAndAddInt(this, VALUE, delta);  
   &#125;  
  
</code></pre>
<p>而sun.misc.Unsafe方法中getAndAddInt方法又会调用jdk.internal.misc.Unsafe的getAndAddInt，具体代码如下：</p>
<pre><code>public final int getAndAddInt(Object o, long offset, int delta) &#123;  
       return theInternalUnsafe.getAndAddInt(o, offset, delta);  
   &#125;  
</code></pre>
<p>jdk.internal.misc.Unsafe的getAndAddInt（）方法的声明如下：</p>
<pre><code>public final int getAndAddInt(Object o, long offset, int delta) &#123;  
        int v;  
        do &#123;  
            v = getIntVolatile(o, offset);//先获取内存中存储的值  
        &#125; while (!weakCompareAndSetInt(o, offset, v, v + delta));//如果不是期望的结果值，就一直循环  
        return v;  
    &#125;  
      
//该函数返回值代表CAS操作是否成功      
public final boolean weakCompareAndSetInt(Object o, long offset,  
                                          int expected,  
                                          int x) &#123;  
     return compareAndSetInt(o, offset, expected, x);//执行CAS操作  
    &#125;  
  
</code></pre>
<p>从上述代码中我们可以得出，会先获取内存中存储的值，最终会调用compareAndSetInt（）方法来完成最终的原子操作。其中compareAndSetInt（）方法的返回值代表着该次CAS操作是否成功。如果不成功。那么会一直循环。直到成功为止（也就是循环CAS操作）。</p>
<h1 id="CountDownLatch"><a href="#CountDownLatch" class="headerlink" title="CountDownLatch"></a>CountDownLatch</h1><p>CountDownLatch顾名思义，count + down + latch ＝ 计数 ＋ 减 ＋ 门闩。<br>可以理解这个东西就是个计数器，只能减不能加，同时它还有个门闩的作用，当计数器不为0时，门闩是锁着的；当计数器减到0时，门闩就打开了。</p>
<h2 id="实现原理-2"><a href="#实现原理-2" class="headerlink" title="实现原理"></a>实现原理</h2><h3 id="构造方法"><a href="#构造方法" class="headerlink" title="构造方法"></a>构造方法</h3><p>下面是实现的源码，非常简短，主要是创建了一个Sync对象。</p>
<pre><code>public CountDownLatch(int count) &#123;  
        if (count &lt; 0) throw new IllegalArgumentException(&quot;count &lt; 0&quot;);  
        this.sync = new Sync(count);  
&#125;  
</code></pre>
<h3 id="Sync对象"><a href="#Sync对象" class="headerlink" title="Sync对象"></a>Sync对象</h3><pre><code>private static final class Sync extends AbstractQueuedSynchronizer &#123;  
        private static final long serialVersionUID = 4982264981922014374L;  
   
        Sync(int count) &#123;  
            setState(count);  
        &#125;  
   
        int getCount() &#123;  
            return getState();  
        &#125;  
   
        protected int tryAcquireShared(int acquires) &#123;  
            return (getState() == 0) ? 1 : -1;  
        &#125;  
   
        protected boolean tryReleaseShared(int releases) &#123;  
            // Decrement count; signal when transition to zero  
            for (;;) &#123;  
                int c = getState();  
                if (c == 0)  
                    return false;  
                int nextc = c-1;  
                if (compareAndSetState(c, nextc))  
                    return nextc == 0;  
            &#125;  
        &#125;  
    &#125;  
</code></pre>
<p>假设我们是这样创建的：new CountDownLatch(5)。其实也就相当于new<br>Sync(5)，相当于setState(5)。setState其实就是共享锁资源总数,我们可以暂时理解为设置一个计数器，当前计数器初始值为5。</p>
<p>tryAcquireShared方法其实就是判断一下当前计数器的值，是否为0了，如果为0的话返回1（<br><strong>返回1的时候，就表示获取锁成功,awit()方法就不再阻塞</strong> ）。</p>
<p>tryReleaseShared方法就是利用CAS的方式，对计数器进行减一的操作，而我们实际上每次调用countDownLatch.countDown()方法的时候，最终都会调到这个方法，对计数器进行减一操作，一直减到0为止。</p>
<h3 id="await"><a href="#await" class="headerlink" title="await()"></a>await()</h3><pre><code>public void await() throws InterruptedException &#123;      
    sync.acquireSharedInterruptibly(1);      
&#125;  
</code></pre>
<p>代码很简单，就一句话（注意acquireSharedInterruptibly（）方法是抽象类：AbstractQueuedSynchronizer的一个方法，我们上面提到的Sync继承了它），我们跟踪源码，继续往下看：</p>
<h3 id="acquireSharedInterruptibly-int-arg"><a href="#acquireSharedInterruptibly-int-arg" class="headerlink" title="acquireSharedInterruptibly(int arg)"></a>acquireSharedInterruptibly(int arg)</h3><pre><code>public final void acquireSharedInterruptibly(int arg)  
           throws InterruptedException &#123;  
       if (Thread.interrupted())  
           throw new InterruptedException();  
       if (tryAcquireShared(arg) &lt; 0)  
           doAcquireSharedInterruptibly(arg);  
   &#125;  
  
</code></pre>
<p>源码也是非常简单的，首先判断了一下，当前线程是否有被中断，如果没有的话，就调用tryAcquireShared(int<br>acquires)方法，判断一下当前线程是否还需要“阻塞”。其实这里调用的tryAcquireShared方法，就是我们上面提到的java.util.concurrent.CountDownLatch.Sync.tryAcquireShared(int)这个方法。<br>当然，在一开始我们没有调用过countDownLatch.countDown()方法时，这里tryAcquireShared方法肯定是会返回-1的，因为会进入到doAcquireSharedInterruptibly方法。</p>
<pre><code>private void doAcquireSharedInterruptibly(int arg)  
    throws InterruptedException &#123;  
    final Node node = addWaiter(Node.SHARED);  
    boolean failed = true;  
    try &#123;  
        for (;;) &#123;  
            final Node p = node.predecessor();  
            if (p == head) &#123;  
                int r = tryAcquireShared(arg);  
                if (r &gt;= 0) &#123;  
                    setHeadAndPropagate(node, r);  
                    p.next = null; // help GC  
                    failed = false;  
                    return;  
                &#125;  
            &#125;  
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;  
                parkAndCheckInterrupt())  
                throw new InterruptedException();  
        &#125;  
    &#125; finally &#123;  
        if (failed)  
            cancelAcquire(node);  
    &#125;  
&#125;  
  
</code></pre>
<h3 id="countDown-方法"><a href="#countDown-方法" class="headerlink" title="countDown()方法"></a>countDown()方法</h3><pre><code>// 计数器减1  
public void countDown() &#123;  
    sync.releaseShared(1);   
&#125;  
  
//调用AQS的releaseShared方法  
public final boolean releaseShared(int arg) &#123;  
    if (tryReleaseShared(arg)) &#123;//计数器减一  
        doReleaseShared();//唤醒后继结点,这个时候队列中可能只有调用过await()的线程节点,也可能队列为空,一般为主线程  
        return true;  
    &#125;  
    return false;  
&#125;  
  
//自定义同步器实现的方法  
protected boolean tryReleaseShared(int releases) &#123;  
    // Decrement count; signal when transition to zero  
    for (;;) &#123;  
        int c = getState();  
        if (c == 0)  
            return false;  //重复调用的时候返回false结束上层方法  
        int nextc = c-1;  
        if (compareAndSetState(c, nextc))  
            return nextc == 0;  //调用countDown的线程不把资源释放到0,改方法一直返回 false   
    &#125;  
&#125;  
  
</code></pre>
<p>这个时候，我们应该对于countDownLatch.await()方法是怎么“阻塞”当前线程的，已经非常明白了。其实说白了，就是当你调用了countDownLatch.await()方法后，你当前线程就会进入了一个死循环当中，在这个死循环里面，会不断的进行判断，通过调用tryAcquireShared方法，不断判断我们上面说的那个计数器，看看它的值是否为0了（为0的时候，其实就是我们调用了足够多<br>countDownLatch.countDown()方法的时候），如果是为0的话，tryAcquireShared就会返回1，代码也会进入到if (r &gt;&#x3D;<br>0)部分，然后跳出了循环，也就不再“阻塞”当前线程了。需要注意的是，说是在不停的循环，其实也并非在不停的执行for循环里面的内容，因为在后面调用parkAndCheckInterrupt（）方法时，在这个方法里面是会调用<br>LockSupport.park(this);来挂起当前线程。</p>
<h3 id="CountDownLatch-使用的注意点："><a href="#CountDownLatch-使用的注意点：" class="headerlink" title="CountDownLatch 使用的注意点："></a>CountDownLatch 使用的注意点：</h3><ol>
<li>只有当count为0时， <strong>await之后的程序才够执行</strong> 。</li>
<li><strong>countDown必须写在finally中，防止发生异程常时，导致程序死锁。</strong></li>
</ol>
<h3 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h3><pre><code>public class Test &#123;  
    public static void main(String[] args) &#123;  
        final CountDownLatch latch = new CountDownLatch(2);  
        new Thread() &#123;  
            public void run() &#123;  
                try &#123;  
                    System.out.println(&quot;子线程&quot; + Thread.currentThread().getName() + &quot;正在执行&quot;);  
                    Thread.sleep(3000);  
                    System.out.println(&quot;子线程&quot; + Thread.currentThread().getName() + &quot;执行完毕&quot;);  
                &#125; catch (InterruptedException e) &#123;  
                    e.printStackTrace();  
                &#125; finally &#123;  
                    latch.countDown();  
                &#125;  
            &#125;;  
        &#125;.start();  
  
        new Thread() &#123;  
            public void run() &#123;  
                try &#123;  
                    System.out.println(&quot;子线程&quot; + Thread.currentThread().getName() + &quot;正在执行&quot;);  
                    Thread.sleep(3000);  
                    System.out.println(&quot;子线程&quot; + Thread.currentThread().getName() + &quot;执行完毕&quot;);  
                    latch.countDown();  
                &#125; catch (InterruptedException e) &#123;  
                    e.printStackTrace();  
                &#125; finally &#123;  
                    latch.countDown();  
                &#125;  
            &#125;;  
        &#125;.start();  
        try &#123;  
            System.out.println(&quot;等待2个子线程执行完毕...&quot;);  
            latch.await();  
            System.out.println(&quot;2个子线程已经执行完毕&quot;);  
            System.out.println(&quot;继续执行主线程&quot;);  
        &#125; catch (InterruptedException e) &#123;              
            e.printStackTrace();          
            &#125;     
    &#125;  
&#125;  
  
</code></pre>
<h1 id="CyclicBarrier"><a href="#CyclicBarrier" class="headerlink" title="CyclicBarrier"></a>CyclicBarrier</h1><p>CyclicBarrier是一个同步辅助类，允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)。因为该<br>barrier 在释放等待线程后可以重用，所以称它为循环 的 barrier。</p>
<p>注意比较CountDownLatch和CyclicBarrier：</p>
<ol>
<li><p>CountDownLatch的作用是允许1或N个线程等待其他线程完成执行；而CyclicBarrier则是允许N个线程相互等待。</p>
</li>
<li><p>CountDownLatch的计数器无法被重置；CyclicBarrier的计数器可以被重置后使用，因此它被称为是循环的barrier。</p>
</li>
</ol>
<h2 id="CyclicBarrier函数列表"><a href="#CyclicBarrier函数列表" class="headerlink" title="CyclicBarrier函数列表"></a><strong>CyclicBarrier函数列表</strong></h2><pre><code>CyclicBarrier(int parties)  
创建一个新的 CyclicBarrier，它将在给定数量的参与者（线程）处于等待状态时启动，但它不会在启动 barrier 时执行预定义的操作。  
CyclicBarrier(int parties, Runnable barrierAction)  
创建一个新的 CyclicBarrier，它将在给定数量的参与者（线程）处于等待状态时启动，并在启动 barrier 时执行给定的屏障操作，该操作由最后一个进入 barrier 的线程执行。  
  
int await()  
在所有参与者都已经在此 barrier 上调用 await 方法之前，将一直等待。  
int await(long timeout, TimeUnit unit)  
在所有参与者都已经在此屏障上调用 await 方法之前将一直等待,或者超出了指定的等待时间。  
int getNumberWaiting()  
返回当前在屏障处等待参与者数目。  
int getParties()  
返回要求启动此 barrier 的参与者数目。  
boolean isBroken()  
查询此屏障是否处于损坏状态。  
void reset()  
将屏障重置为其初始状态。  
</code></pre>
<h2 id="CyclicBarrier数据结构"><a href="#CyclicBarrier数据结构" class="headerlink" title="CyclicBarrier数据结构"></a>CyclicBarrier数据结构</h2><p>CyclicBarrier的UML类图如下：</p>
<p><img src="/images/CyclicBarrier%E7%9A%84UML%E7%B1%BB%E5%9B%BE.jpg" alt="CyclicBarrier的UML类图"></p>
<p>CyclicBarrier是包含了”<a target="_blank" rel="noopener" href="http://www.cnblogs.com/skywang12345/p/3496147.html">ReentrantLock</a>对象lock”和”<a target="_blank" rel="noopener" href="http://www.cnblogs.com/skywang12345/p/3496716.html">Condition</a>对象trip”，它是通过独占锁实现的。下面通过源码去分析到底是如何实现的。</p>
<h2 id="CyclicBarrier源码分析"><a href="#CyclicBarrier源码分析" class="headerlink" title="CyclicBarrier源码分析"></a>CyclicBarrier源码分析</h2><h3 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h3><p>CyclicBarrier的构造函数共2个：CyclicBarrier 和 CyclicBarrier(int parties, Runnable<br>barrierAction)。第1个构造函数是调用第2个构造函数来实现的，下面第2个构造函数的源码。</p>
<pre><code>public CyclicBarrier(int parties, Runnable barrierAction) &#123;  
    if (parties &lt;= 0) throw new IllegalArgumentException();  
    // parties表示“必须同时到达barrier的线程个数”。  
    this.parties = parties;  
    // count表示“处在等待状态的线程个数”。  
    this.count = parties;  
    // barrierCommand表示“parties个线程到达barrier时，会执行的动作”。  
    this.barrierCommand = barrierAction;  
&#125;  
  
</code></pre>
<h3 id="await-1"><a href="#await-1" class="headerlink" title="await()"></a>await()</h3><pre><code>public int await() throws InterruptedException, BrokenBarrierException &#123;  
    try &#123;  
        return dowait(false, 0L);  
    &#125; catch (TimeoutException toe) &#123;  
        throw new Error(toe); // cannot happen;  
    &#125;  
&#125;  
</code></pre>
<p><strong>说明</strong> ：await()是通过dowait()实现的。</p>
<pre><code>private int dowait(boolean timed, long nanos)  
    throws InterruptedException, BrokenBarrierException,  
           TimeoutException &#123;  
    final ReentrantLock lock = this.lock;  
    // 获取“独占锁(lock)”  
    lock.lock();  
    try &#123;  
        // 保存“当前的generation”  
        final Generation g = generation;  
  
        // 若“当前generation已损坏”，则抛出异常。  
        if (g.broken)  
            throw new BrokenBarrierException();  
  
        // 如果当前线程被中断，则通过breakBarrier()终止CyclicBarrier，唤醒CyclicBarrier中所有等待线程。  
        if (Thread.interrupted()) &#123;  
            breakBarrier();  
            throw new InterruptedException();  
        &#125;  
  
       // 将“count计数器”-1  
       int index = --count;  
       // 如果index=0，则意味着“有parties个线程到达barrier”。  
       if (index == 0) &#123;  // tripped  
           boolean ranAction = false;  
           try &#123;  
               // 如果barrierCommand不为null，则执行该动作。  
               final Runnable command = barrierCommand;  
               if (command != null)  
                   command.run();  
               ranAction = true;  
               // 唤醒所有等待线程，并更新generation。  
               nextGeneration();  
               return 0;    //这里等价于return index;  
           &#125; finally &#123;  
               if (!ranAction)  
                   breakBarrier();  
           &#125;  
       &#125;  
  
        // 当前线程一直阻塞，直到“有parties个线程到达barrier” 或 “当前线程被中断” 或 “超时”这3者之一发生，  
        // 当前线程才继续执行。  
        for (;;) &#123;  
            try &#123;  
                // 如果不是“超时等待”，则调用awati()进行等待；否则，调用awaitNanos()进行等待。  
                if (!timed)  
                    trip.await();  
                else if (nanos &gt; 0L)  
                    nanos = trip.awaitNanos(nanos);  
            &#125; catch (InterruptedException ie) &#123;  
                // 如果等待过程中，线程被中断，则执行下面的函数。  
                if (g == generation &amp;&amp; ! g.broken) &#123;  
                    breakBarrier();  
                    throw ie;  
                &#125; else &#123;  
                    Thread.currentThread().interrupt();  
                &#125;  
            &#125;  
  
            // 如果“当前generation已经损坏”，则抛出异常。  
            if (g.broken)  
                throw new BrokenBarrierException();  
  
            // 如果“generation已经换代”，则返回index。  
            if (g != generation)  
                return index;  
  
            // 如果是“超时等待”，并且时间已到，则通过breakBarrier()终止CyclicBarrier，唤醒CyclicBarrier中所有等待线程。  
            if (timed &amp;&amp; nanos &lt;= 0L) &#123;  
                breakBarrier();  
                throw new TimeoutException();  
            &#125;  
        &#125;  
    &#125; finally &#123;  
        // 释放“独占锁(lock)”  
        lock.unlock();  
    &#125;  
&#125;  
</code></pre>
<p><strong>说明</strong> ：dowait()的作用就是让当前线程阻塞，直到“有parties个线程到达barrier” 或 “当前线程被中断” 或<br>“超时”这3者之一发生，当前线程才继续执行。<br>(01) generation是CyclicBarrier的一个成员变量，它的定义如下：</p>
<pre><code>private Generation generation = new Generation();  
  
private static class Generation &#123;  
    boolean broken = false;  
&#125;  
</code></pre>
<p>在CyclicBarrier中，同一批的线程属于同一代，即同一个Generation；CyclicBarrier中通过generation对象，记录属于哪一代。<br>当有parties个线程到达barrier，generation就会被更新换代。</p>
<p>(02)<br>如果当前线程被中断，即Thread.interrupted()为true；则通过breakBarrier()终止CyclicBarrier。breakBarrier()的源码如下：</p>
<pre><code>private void breakBarrier() &#123;  
    generation.broken = true;  
    count = parties;  
    trip.signalAll();  
&#125;  
  
</code></pre>
<p>breakBarrier()会设置当前中断标记broken为true，意味着“将该Generation中断”；同时，设置count&#x3D;parties，即重新初始化count；最后，通过signalAll()唤醒CyclicBarrier上所有的等待线程。</p>
<p>(03) 将“count计数器”-1，即–count；然后判断是不是“有parties个线程到达barrier”，即index是不是为0。<br>当index&#x3D;0时，如果barrierCommand不为null，则执行该barrierCommand，barrierCommand就是我们创建CyclicBarrier时，传入的Runnable对象。然后，调用nextGeneration()进行换代工作，nextGeneration()的源码如下：</p>
<pre><code>private void nextGeneration() &#123;  
    trip.signalAll();  
    count = parties;  
    generation = new Generation();  
&#125;  
</code></pre>
<p>首先，它会调用signalAll()唤醒CyclicBarrier上所有的等待线程；接着，重新初始化count；最后，更新generation的值。</p>
<p>(04)<br>在for(;;)循环中。timed是用来表示当前是不是“超时等待”线程。如果不是，则通过trip.await()进行等待；否则，调用awaitNanos()进行超时等待。</p>
<h3 id="举个栗子-1"><a href="#举个栗子-1" class="headerlink" title="举个栗子"></a>举个栗子</h3><pre><code>import java.util.concurrent.CyclicBarrier;  
import java.util.concurrent.BrokenBarrierException;  
  
public class CyclicBarrierTest1 &#123;  
  
    private static int SIZE = 5;  
    private static CyclicBarrier cb;  
    public static void main(String[] args) &#123;  
  
        cb = new CyclicBarrier(SIZE);  
  
        // 新建5个任务  
        for(int i=0; i&lt;SIZE; i++)  
            new InnerThread().start();  
    &#125;  
  
    static class InnerThread extends Thread&#123;  
        public void run() &#123;  
            try &#123;  
                System.out.println(Thread.currentThread().getName() + &quot; wait for CyclicBarrier.&quot;);  
  
                // 将cb的参与者数量加1  
                cb.await();  
  
                // cb的参与者数量等于5时，才继续往后执行  
                System.out.println(Thread.currentThread().getName() + &quot; continued.&quot;);  
            &#125; catch (BrokenBarrierException e) &#123;  
                e.printStackTrace();  
            &#125; catch (InterruptedException e) &#123;  
                e.printStackTrace();  
            &#125;  
        &#125;  
    &#125;  
&#125;  
运行结果：  
Thread-1 wait for CyclicBarrier.  
Thread-2 wait for CyclicBarrier.  
Thread-3 wait for CyclicBarrier.  
Thread-4 wait for CyclicBarrier.  
Thread-0 wait for CyclicBarrier.  
Thread-0 continued.  
Thread-4 continued.  
Thread-2 continued.  
Thread-3 continued.  
Thread-1 continued.  
  

import java.util.concurrent.CyclicBarrier;  
import java.util.concurrent.BrokenBarrierException;  
  
public class CyclicBarrierTest2 &#123;  
  
    private static int SIZE = 5;  
    private static CyclicBarrier cb;  
    public static void main(String[] args) &#123;  
  
        cb = new CyclicBarrier(SIZE, new Runnable () &#123;  
            public void run() &#123;  
                System.out.println(&quot;CyclicBarrier&#39;s parties is: &quot;+ cb.getParties());  
            &#125;  
        &#125;);  
  
        // 新建5个任务  
        for(int i=0; i&lt;SIZE; i++)  
            new InnerThread().start();  
    &#125;  
  
    static class InnerThread extends Thread&#123;  
        public void run() &#123;  
            try &#123;  
                System.out.println(Thread.currentThread().getName() + &quot; wait for CyclicBarrier.&quot;);  
  
                // 将cb的参与者数量加1  
                cb.await();  
  
                // cb的参与者数量等于5时，才继续往后执行  
                System.out.println(Thread.currentThread().getName() + &quot; continued.&quot;);  
            &#125; catch (BrokenBarrierException e) &#123;  
                e.printStackTrace();  
            &#125; catch (InterruptedException e) &#123;  
                e.printStackTrace();  
            &#125;  
        &#125;  
    &#125;  
&#125;  
运行结果：  
  
Thread-1 wait for CyclicBarrier.  
Thread-2 wait for CyclicBarrier.  
Thread-3 wait for CyclicBarrier.  
Thread-4 wait for CyclicBarrier.  
Thread-0 wait for CyclicBarrier.  
CyclicBarrier&#39;s parties is: 5  
Thread-0 continued.  
Thread-4 continued.  
Thread-2 continued.  
Thread-3 continued.  
Thread-1 continued.  
</code></pre>
<h1 id="Semaphore"><a href="#Semaphore" class="headerlink" title="Semaphore"></a>Semaphore</h1><p>我们以一个停车场运作为例来说明信号量的作用。假设停车场只有三个车位，一开始三个车位都是空的。这时如果同时来了三辆车，看门人允许其中它们进入，然后放下车拦。以后来的车必须在入口等待，直到停车场中有车辆离开。这时，如果有一辆车离开停车场，看门人得知后，打开车拦，放入一辆，如果又离开一辆，则又可以放入一辆，如此往复。</p>
<p>在这个停车场系统中，车位是公共资源，每辆车好比一个线程，看门人起的就是信号量的作用。信号量是一个非负整数，表示了当前公共资源的可用数目（在上面的例子中可以用空闲的停车位类比信号量），当一个线程要使用公共资源时（在上面的例子中可以用车辆类比线程），首先要查看信号量，如果信号量的值大于1，则将其减1，然后去占有公共资源。如果信号量的值为0，则线程会将自己阻塞，直到有其它线程释放公共资源</p>
<p>在信号量上我们定义两种操作： acquire（获取） 和<br>release（释放）。当一个线程调用acquire操作时，它要么通过成功获取信号量（信号量减1），要么一直等下去，直到有线程释放信号量，或超时。release（释放）实际上会将信号量的值加1，然后唤醒等待的线程。</p>
<p>信号量主要用于两个目的，一个是用于多个共享资源的互斥使用，另一个用于并发线程数的控制。</p>
<h2 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h2><p>在Java的并发包中，Semaphore类表示信号量。Semaphore内部主要通过AQS（AbstractQueuedSynchronizer）实现线程的管理。Semaphore有两个构造函数，<br><strong>参数permits表示许可数</strong> ，它最后传递给了AQS的state值。线程在运行时首先获取许可， <strong>如果成功，许可数就减1</strong><br>，线程运行，当线程运行结束就释放许可， <strong>许可数就加1</strong><br>。如果许可数为0，则获取失败，线程位于AQS的等待队列中，它会被其它释放许可的线程唤醒。在创建Semaphore对象的时候还可以指定它的公平性。一般常用非公平的信号量，非公平信号量是指在获取许可时先尝试获取许可，而不必关心是否已有需要获取许可的线程位于等待队列中，如果获取失败，才会入列。而公平的信号量在获取许可时首先要查看等待队列中是否已有线程，如果有则入列。</p>
<h3 id="构造函数-1"><a href="#构造函数-1" class="headerlink" title="构造函数"></a>构造函数</h3><pre><code>//非公平的构造函数  
public Semaphore(int permits) &#123;  
    sync = new NonfairSync(permits);  
&#125;  
  
//通过fair参数决定公平性  
public Semaphore(int permits, boolean fair) &#123;  
    sync = fair ? new FairSync(permits) : new NonfairSync(permits);  
&#125;   
  
</code></pre>
<h3 id="acquire"><a href="#acquire" class="headerlink" title="acquire()"></a>acquire()</h3><pre><code>public void acquire() throws InterruptedException &#123;  
    sync.acquireSharedInterruptibly(1);  
&#125;  
  
public final void acquireSharedInterruptibly(int arg)  
        throws InterruptedException &#123;  
    if (Thread.interrupted())  
        throw new InterruptedException();  
    if (tryAcquireShared(arg) &lt; 0)  
        doAcquireSharedInterruptibly(arg);  
&#125;  
</code></pre>
<ul>
<li>调用tryAcquireShared()方法尝试获取信号。</li>
<li>如果没有可用信号，将当前线程加入等待队列并挂起</li>
</ul>
<p>tryAcquireShared<br>会调用对应公平或者非公平同步器的方法,xxTAcquireShared下面是非公平的,公平的方法就多了一个hasQueuedPredecessors方法的逻辑</p>
<h3 id="NonfairSync-tryAcquireShared"><a href="#NonfairSync-tryAcquireShared" class="headerlink" title="NonfairSync.tryAcquireShared()"></a>NonfairSync.tryAcquireShared()</h3><pre><code>final int nonfairTryAcquireShared(int acquires) &#123;  
    for (;;) &#123;  
        int available = getState();  
        int remaining = available - acquires; //剩余许可数  
        if (remaining &lt; 0 ||  
            compareAndSetState(available, remaining))   
            return remaining;  
    &#125;  
&#125;  
</code></pre>
<p>可以看出，如果remaining &lt;0<br>即获取许可后，许可数小于0，则获取失败，在doAcquireSharedInterruptibly方法中线程会将自身阻塞，然后入列。可以看到，非公平锁对于信号的获取是直接使用CAS进行尝试的。</p>
<h3 id="FairSync-tryAcquireShared"><a href="#FairSync-tryAcquireShared" class="headerlink" title="FairSync.tryAcquireShared()"></a>FairSync.tryAcquireShared()</h3><pre><code>protected int tryAcquireShared(int acquires) &#123;  
            for (;;) &#123;  
                if (hasQueuedPredecessors())  
                    return -1;  
                int available = getState();  
                int remaining = available - acquires;  
                if (remaining &lt; 0 ||  
                    compareAndSetState(available, remaining))  
                    return remaining;  
            &#125;  
        &#125;  
  
</code></pre>
<ul>
<li><p>先调用hasQueuedPredecessors()方法，判断队列中是否有等待线程。如果有，直接返回-1，表示没有可用信号</p>
</li>
<li><p>队列中没有等待线程，再使用CAS尝试更新state，获取信号</p>
</li>
</ul>
<h3 id="doAcquireSharedInterruptibly"><a href="#doAcquireSharedInterruptibly" class="headerlink" title="doAcquireSharedInterruptibly()"></a>doAcquireSharedInterruptibly()</h3><pre><code>private void doAcquireSharedInterruptibly(int arg)  
        throws InterruptedException &#123;  
        final Node node = addWaiter(Node.SHARED);   // 1  
        boolean failed = true;  
        try &#123;  
            for (;;) &#123;  
                final Node p = node.predecessor();     
                if (p == head) &#123;      // 2  
                    int r = tryAcquireShared(arg);  
                    if (r &gt;= 0) &#123;  
                        setHeadAndPropagate(node, r);  
                        p.next = null; // help GC  
                        failed = false;  
                        return;  
                    &#125;  
                &#125;  
                if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;     // 3  
                    parkAndCheckInterrupt())  
                    throw new InterruptedException();  
            &#125;  
        &#125; finally &#123;  
            if (failed)  
                cancelAcquire(node);     
        &#125;  
    &#125;  
  
</code></pre>
<ol>
<li>封装一个Node节点，加入队列尾部</li>
<li>在无限循环中，如果当前节点是头节点，就尝试获取信号</li>
<li>不是头节点，在经过节点状态判断后，挂起当前线程</li>
</ol>
<h3 id="release-释放信号"><a href="#release-释放信号" class="headerlink" title="release()释放信号"></a><strong>release()释放信号</strong></h3><pre><code>public final boolean releaseShared(int arg) &#123;  
        if (tryReleaseShared(arg)) &#123;    // 1  
            doReleaseShared();  // 2  
            return true;  
        &#125;  
        return false;  
    &#125;  
</code></pre>
<ol>
<li>cas更新state加一</li>
<li>唤醒等待队列头节点线程</li>
</ol>
<h2 id="举个栗子-2"><a href="#举个栗子-2" class="headerlink" title="举个栗子"></a>举个栗子</h2><pre><code>public static void main(String[] args) &#123;  
        ThreadPoolExecutor threadPool = new ThreadPoolExecutor(10, 10,  
                0L, TimeUnit.MILLISECONDS,  
                new LinkedBlockingQueue&lt;Runnable&gt;(10));  
        //信号总数为5  
        Semaphore semaphore = new Semaphore(5);  
        //运行10个线程  
        for (int i = 0; i &lt; 10; i++) &#123;  
            threadPool.execute(new Runnable() &#123;  
                  
                @Override  
                public void run() &#123;  
                    try &#123;  
                        //获取信号  
                        semaphore.acquire();     
                        System.out.println(Thread.currentThread().getName() + &quot;获得了信号量,时间为&quot; + System.currentTimeMillis());  
                        //阻塞2秒，测试效果  
                        Thread.sleep(2000);  
                        System.out.println(Thread.currentThread().getName() + &quot;释放了信号量,时间为&quot; + System.currentTimeMillis());  
                    &#125; catch (InterruptedException e) &#123;  
                        e.printStackTrace();  
                    &#125; finally &#123;  
                        //释放信号  
                        semaphore.release();  
                    &#125;  
                  
                &#125;  
            &#125;);  
        &#125;  
        threadPool.shutdown();  
    &#125;  
  
pool-1-thread-2获得了信号量,时间为1550584196125  
pool-1-thread-1获得了信号量,时间为1550584196125  
pool-1-thread-3获得了信号量,时间为1550584196125  
pool-1-thread-4获得了信号量,时间为1550584196126  
pool-1-thread-5获得了信号量,时间为1550584196127  
pool-1-thread-2释放了信号量,时间为1550584198126  
pool-1-thread-3释放了信号量,时间为1550584198126  
pool-1-thread-4释放了信号量,时间为1550584198126  
pool-1-thread-6获得了信号量,时间为1550584198126  
pool-1-thread-9获得了信号量,时间为1550584198126  
pool-1-thread-8获得了信号量,时间为1550584198126  
pool-1-thread-1释放了信号量,时间为1550584198126  
pool-1-thread-10获得了信号量,时间为1550584198126  
pool-1-thread-5释放了信号量,时间为1550584198127  
pool-1-thread-7获得了信号量,时间为1550584198127  
pool-1-thread-6释放了信号量,时间为1550584200126  
pool-1-thread-8释放了信号量,时间为1550584200126  
pool-1-thread-10释放了信号量,时间为1550584200126  
pool-1-thread-9释放了信号量,时间为1550584200126  
pool-1-thread-7释放了信号量,时间为1550584200127  
</code></pre>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/03/21/jvm/%E5%A4%9A%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="merric">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Myoboku">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Myoboku">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/03/21/jvm/%E5%A4%9A%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B/" class="post-title-link" itemprop="url">多线程与多进程</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-03-21 22:30:00" itemprop="dateCreated datePublished" datetime="2020-03-21T22:30:00+00:00">2020-03-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="线程和进程"><a href="#线程和进程" class="headerlink" title="线程和进程"></a>线程和进程</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动,进程是系统进行资源分配和调度的一个独立单位.</p>
<p>线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源.</p>
<p>一个线程可以创建和撤销另一个线程;同一个进程中的多个线程之间可以并发执行.</p>
<p>相对进程而言，线程是一个更加接近于执行体的概念，它可以与同进程中的其他线程共享数据，但拥有自己的栈空间，拥有独立的执行序列。</p>
<p>在串行程序基础上引入线程和进程是为了提高程序的并发度，从而提高程序运行效率和响应时间。</p>
<h2 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h2><p>进程和线程的主要差别在于它们是不同的操作系统资源管理方式。进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。<br><strong>但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。</strong></p>
<ol>
<li><strong>简而言之,一个程序至少有一个进程,一个进程至少有一个线程.</strong></li>
<li>线程的划分尺度小于进程，使得多线程程序的并发性高。</li>
<li>另外，进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率。</li>
<li>线程在执行过程中与进程还是有区别的。每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口。 <strong>但是线程不能够独立执行，</strong> 必须依存在应用程序中，由应用程序提供多个线程执行控制。</li>
<li>从逻辑角度来看，多线程的意义在于一个应用程序中，有多个执行部分可以同时执行。但操作系统并没有将多个线程看做多个独立的应用，来实现进程的调度和管理以及资源分配。 <strong>这就是进程和线程的重要区别。</strong></li>
</ol>
<h1 id="多线程和多进程"><a href="#多线程和多进程" class="headerlink" title="多线程和多进程"></a>多线程和多进程</h1><table>
<thead>
<tr>
<th><strong>对比维度</strong></th>
<th><strong>多进程</strong></th>
<th><strong>多线程</strong></th>
<th><strong>总结</strong></th>
</tr>
</thead>
<tbody><tr>
<td>数据共享、同步</td>
<td>数据共享复杂，需要用IPC；数据是分开的，同步简单</td>
<td>因为共享进程数据，数据共享简单，但也是因为这个原因导致同步复杂</td>
<td>各有优势</td>
</tr>
<tr>
<td>内存、CPU</td>
<td>占用内存多，切换复杂，CPU利用率低</td>
<td>占用内存少，切换简单，CPU利用率高</td>
<td>线程占优</td>
</tr>
<tr>
<td>创建销毁、切换</td>
<td>创建销毁、切换复杂，速度慢</td>
<td>创建销毁、切换简单，速度很快</td>
<td>线程占优</td>
</tr>
<tr>
<td>编程、调试</td>
<td>编程简单，调试简单</td>
<td>编程复杂，调试复杂</td>
<td>进程占优</td>
</tr>
<tr>
<td>可靠性</td>
<td>进程间不会互相影响</td>
<td>一个线程挂掉将导致整个进程挂掉</td>
<td>进程占优</td>
</tr>
<tr>
<td>分布式</td>
<td>适应于多核、多机分布式；如果一台机器不够，扩展到多台机器比较简单</td>
<td>适应于多核分布式</td>
<td>进程占优</td>
</tr>
</tbody></table>
<p>使用进程和线程一般根据以上的不同情况进行不同的选择，一般以业务逻辑划分进程，内部再细分线程</p>
<h1 id="进程间通信"><a href="#进程间通信" class="headerlink" title="进程间通信"></a>进程间通信</h1><h2 id="进程间通信的目的"><a href="#进程间通信的目的" class="headerlink" title="进程间通信的目的"></a>进程间通信的目的</h2><ul>
<li><p><strong>数据传输</strong><br>一个进程需要将它的数据发送给另一个进程，发送的数据量在一个字节到几M字节之间</p>
</li>
<li><p><strong>共享数据</strong><br>多个进程想要操作共享数据，一个进程对共享数据</p>
</li>
<li><p><strong>通知事</strong><br>一个进程需要向另一个或一组进程发送消息，通知它（它们）发生了某种事件（如进程终止时要通知父进程）。</p>
</li>
<li><p><strong>资源共享</strong><br>多个进程之间共享同样的资源。为了作到这一点，需要内核提供锁和同步机制。</p>
</li>
<li><p><strong>进程控制</strong><br>有些进程希望完全控制另一个进程的执行（如Debug进程），此时控制进程希望能够拦截另一个进程的所有陷入和异常，并能够及时知道它的状态改变。</p>
</li>
</ul>
<h2 id="linux进程间通信的方式"><a href="#linux进程间通信的方式" class="headerlink" title="linux进程间通信的方式"></a>linux进程间通信的方式</h2><h3 id="管道（pipe）"><a href="#管道（pipe）" class="headerlink" title="管道（pipe）"></a>管道（pipe）</h3><ul>
<li>管道是半双工的，数据只能向一个方向流动；需要双方通信时，需要建立起两个管道。</li>
<li>只能用于父子进程或者兄弟进程之间(具有亲缘关系的进程);</li>
<li>单独构成一种独立的文件系统：管道对于管道两端的进程而言，就是一个文件，但它不是普通的文件，它不属于某种文件系统，而是自立门户，单独构成一种文件系统，并且只存在与内存中。</li>
<li>数据的读出和写入：一个进程向管道中写的内容被管道另一端的进程读出。写入的内容每次都添加在管道缓冲区的末尾，并且每次都是从缓冲区的头部读出数据。</li>
</ul>
<p><img src="/images/%E7%AE%A1%E9%81%93.png" alt="管道"></p>
<p>常见的Linux命令 “|” 其实就是匿名管道，表示把一个进程的输出传输到另外一个进程，如：</p>
<pre><code>echo &quot;Happyjava&quot; | awk -F &#39;j&#39; &#39;&#123;print $2&#125;&#39;  
# 输出 ava  
  
</code></pre>
<p>—|—  </p>
<p><strong>管道的实质：</strong></p>
<ul>
<li>管道的实质是一个内核缓冲区，进程以先进先出的方式从缓冲区存取数据，管道一端的进程顺序的将数据写入缓冲区，另一端的进程则顺序的读出数据。</li>
<li>该缓冲区可以看做是一个循环队列，读和写的位置都是自动增长的，不能随意改变，一个数据只能被读一次，读出来以后在缓冲区就不复存在了。</li>
<li>当缓冲区读空或者写满时，有一定的规则控制相应的读进程或者写进程进入等待队列，当空的缓冲区有新数据写入或者满的缓冲区有数据读出来时，就唤醒等待队列中的进程继续读写。</li>
</ul>
<p><strong>管道的局限：</strong><br>管道的主要局限性正体现在它的特点上：</p>
<ul>
<li>只支持单向数据流；</li>
<li>只能用于具有亲缘关系的进程之间；</li>
<li>没有名字；</li>
<li>管道的缓冲区是有限的（管道制存在于内存中，在管道创建时，为缓冲区分配一个页面大小）；</li>
<li>管道所传送的是无格式字节流，这就要求管道的读出方和写入方必须事先约定好数据的格式，比如多少字节算作一个消息（或命令、或记录）等等；</li>
</ul>
<h3 id="有名管道（FIFO）"><a href="#有名管道（FIFO）" class="headerlink" title="有名管道（FIFO）"></a>有名管道（FIFO）</h3><p>匿名管道，由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道(FIFO)。<br>有名管道不同于匿名管道之处在于它提供了一个路径名与之关联， <strong>以有名管道的文件形式存在于文件系统中</strong> ，这样，<br><strong>即使与有名管道的创建进程不存在亲缘关系的进程，只要可以访问该路径，就能够彼此通过有名管道相互通信</strong><br>，因此，通过有名管道不相关的进程也能交换数据。值的注意的是，有名管道严格遵循 <strong>先进先出(first in first out)</strong><br>,对匿名管道及有名管道的读总是从开始处返回数据，对它们的写则把数据添加到末尾。它们不支持诸如lseek()等文件定位操作。<br><strong>有名管道的名字存在于文件系统中，内容存放在内存中。</strong></p>
<p><strong>匿名管道和有名管道总结：</strong><br>（1）管道是特殊类型的文件，在满足先入先出的原则条件下可以进行读写，但不能进行定位读写。<br>（2）匿名管道是单向的，只能在有亲缘关系的进程间通信；有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。<br>（3） <strong>无名管道阻塞问题：</strong><br>无名管道无需显示打开，创建时直接返回文件描述符，在读写时需要确定对方的存在，否则将退出。如果当前进程向无名管道的一端写数据，必须确定另一端有某一进程。如果写入无名管道的数据超过其最大值，写操作将阻塞，如果管道中没有数据，读操作将阻塞，如果管道发现另一端断开，将自动退出。<br>（4） <strong>有名管道阻塞问题：</strong><br>有名管道在打开时需要确实对方的存在，否则将阻塞。即以读方式打开某管道，在此之前必须一个进程以写方式打开管道，否则阻塞。此外，可以以读写（O_RDWR）模式打开有名管道，即当前进程读，当前进程写，不会阻塞。</p>
<h3 id="信号（-Signal-）"><a href="#信号（-Signal-）" class="headerlink" title="信号（ Signal ）"></a>信号（ <strong>Signal</strong> ）</h3><ul>
<li>信号是Linux系统中用于进程间互相通信或者操作的一种机制，信号可以在任何时候发给某一进程，而无需知道该进程的状态。</li>
<li>如果该进程当前并未处于执行状态，则该信号就有内核保存起来，直到该进程回复执行并传递给它为止。</li>
<li>如果一个信号被进程设置为阻塞，则该信号的传递被延迟，直到其阻塞被取消是才被传递给进程。</li>
</ul>
<p><strong>信号来源</strong></p>
<p>信号是软件层次上对中断机制的一种模拟，是一种异步通信方式，，信号可以在用户空间进程和内核之间直接交互，内核可以利用信号来通知用户空间的进程发生了哪些系统事件，信号事件主要有两个来源：</p>
<ul>
<li>硬件来源：用户按键输入<code>Ctrl+C</code>退出、硬件异常如无效的存储访问等。</li>
<li>软件终止：终止进程信号、其他进程调用kill函数、软件异常产生信号。</li>
</ul>
<p><strong>信号生命周期和处理流程</strong></p>
<ol>
<li><p>信号被某个进程产生，并设置此信号传递的对象（一般为对应进程的pid），然后传递给操作系统；</p>
</li>
<li><p>操作系统根据接收进程的设置（是否阻塞）而选择性的发送给接收者，如果接收者阻塞该信号（且该信号是可以阻塞的），操作系统将暂时保留该信号，而不传递，直到该进程解除了对此信号的阻塞（如果对应进程已经退出，则丢弃此信号），如果对应进程没有阻塞，操作系统将传递此信号。</p>
</li>
<li><p>目的进程接收到此信号后，将根据当前进程对此信号设置的预处理方式，暂时终止当前代码的执行，保护上下文（主要包括临时寄存器数据，当前程序位置以及当前CPU的状态）、转而执行中断服务程序，执行完成后在回复到中断的位置。当然，对于抢占式内核，在中断返回时还将引发新的调度。</p>
</li>
</ol>
<h3 id="消息队列（-Message-）"><a href="#消息队列（-Message-）" class="headerlink" title="消息队列（ Message ）"></a>消息队列（ <strong>Message</strong> ）</h3><p>注意，此消息队列不是我们常用的MQ，如kafka，rabbitmq，rocketmq等。</p>
<ul>
<li>消息队列是存放在内存中的消息链表，每个消息队列由消息队列标识符表示。</li>
<li>与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显示地删除一个消息队列时，该消息队列才会被真正的删除。</li>
<li>另外与管道不同的是，消息队列在某个进程往一个队列写入消息之前，并不需要另外某个进程在该队列上等待消息的到达</li>
</ul>
<p><strong>消息队列特点总结：</strong></p>
<ol>
<li>消息队列是消息的链表,具有特定的格式,存放在内存中并由消息队列标识符标识.</li>
<li>消息队列允许一个或多个进程向它写入与读取消息.</li>
<li>管道和消息队列的通信数据都是先进先出的原则。</li>
<li>消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比FIFO更有优势。</li>
<li>消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺。</li>
<li>目前主要有两种类型的消息队列：POSIX消息队列以及System V消息队列，系统V消息队列目前被大量使用。系统V消息队列是随内核持续的，只有在内核重起或者人工删除时，该消息队列才会被删除。</li>
</ol>
<h3 id="共享内存-（share-memory）"><a href="#共享内存-（share-memory）" class="headerlink" title="共享内存 （share memory）"></a>共享内存 <strong>（share memory）</strong></h3><ul>
<li>使得多个进程可以直接读写同一块内存空间，是最快的可用IPC形式。是针对其他通信机制运行效率较低而设计的。</li>
<li>为了在多个进程间交换信息，内核专门留出了一块内存区，可以由需要访问的进程将其映射到自己的私有地址空间。进程就可以直接读写这一块内存而不需要进行数据的拷贝，从而大大提高效率。</li>
<li>由于多个进程共享一段内存，因此需要依靠某种同步机制（如信号量）来达到进程间的同步及互斥。</li>
</ul>
<p><img src="/images/%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98.png" alt="共享内存"></p>
<h3 id="信号量（-semaphore-）"><a href="#信号量（-semaphore-）" class="headerlink" title="信号量（ semaphore ）"></a>信号量（ <strong>semaphore</strong> ）</h3><p>信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。<br>为了获得共享资源，进程需要执行下列操作：<br>（1） <strong>创建一个信号量</strong> ：这要求调用者指定初始值，对于二值信号量来说，它通常是1，也可是0。<br>（2） <strong>等待一个信号量</strong> ：该操作会测试这个信号量的值，如果小于0，就阻塞。也称为P操作。<br>（3） <strong>挂出一个信号量</strong> ：该操作将信号量的值加1，也称为V操作。</p>
<p>为了正确地实现信号量，信号量值的测试及减1操作应当是原子操作。为此，信号量通常是在内核中实现的。Linux环境中，有三种类型：<br><strong>Posix（<a target="_blank" rel="noopener" href="https://link.jianshu.com/?t=http://baike.baidu.com/link?url=hYEo6ngm9MlqsQHT3h28baIDxEooeSPX6wr_FdGF-F8mf7wDp2xJWIDtQWGEDxthtPNiJtlsw460g1_N0txJYa">可移植性操作系统接口</a>）有名信号量（使用Posix<br>IPC名字标识）</strong>、 <strong>Posix基于内存的信号量（存放在共享内存区中）</strong> 、 <strong>System V信号量（在内核中维护）</strong><br>。这三种信号量都可用于进程间或线程间的同步。</p>
<p><img src="/images/%E4%B8%A4%E4%B8%AA%E8%BF%9B%E7%A8%8B%E4%BD%BF%E7%94%A8%E4%B8%80%E4%B8%AA%E4%BA%8C%E5%80%BC%E4%BF%A1%E5%8F%B7%E9%87%8F.png" alt="两个进程使用一个二值信号量"></p>
<p><img src="/images/%E4%B8%A4%E4%B8%AA%E8%BF%9B%E7%A8%8B%E6%89%80%E4%BB%A5%E7%94%A8%E4%B8%80%E4%B8%AAPosix%E6%9C%89%E5%90%8D%E4%BA%8C%E5%80%BC%E4%BF%A1%E5%8F%B7%E9%87%8F.png" alt="两个进程所以用一个Posix有名二值信号量"></p>
<p><img src="/images/%E4%B8%80%E4%B8%AA%E8%BF%9B%E7%A8%8B%E4%B8%A4%E4%B8%AA%E7%BA%BF%E7%A8%8B%E5%85%B1%E4%BA%AB%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AD%98%E7%9A%84%E4%BF%A1%E5%8F%B7%E9%87%8F.png" alt="一个进程两个线程共享基于内存的信号量"></p>
<p><strong>信号量与普通整型变量的区别：</strong></p>
<ol>
<li>信号量是非负整型变量，除了初始化之外，它只能通过两个标准原子操作：wait(semap) , signal(semap) ; 来进行访问；</li>
<li>操作也被成为PV原语（P来源于荷兰语proberen”测试”，V来源于荷兰语verhogen”增加”，P表示通过的意思，V表示释放的意思），而普通整型变量则可以在任何语句块中被访问；</li>
</ol>
<p><strong>信号量与互斥量之间的区别：</strong></p>
<ol>
<li>互斥量用于线程的互斥，信号量用于线程的同步。这是互斥量和信号量的根本区别，也就是互斥和同步之间的区别。</li>
</ol>
<p><strong>互斥：</strong> 是指某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，即访问是无序的。<br><strong>同步：</strong> 是指在互斥的基础上（大多数情况），通过其它机制实现访问者对资源的有序访问。<br>在大多数情况下，同步已经实现了互斥，特别是所有写入资源的情况必定是互斥的。少数情况是指可以允许多个访问者同时访问资源</p>
<ol start="2">
<li><p>互斥量值只能为0&#x2F;1，信号量值可以为非负整数。<br>也就是说，一个互斥量只能用于一个资源的互斥访问，它不能实现多个资源的多线程互斥问题。信号量可以实现多个同类资源的多线程互斥和同步。当信号量为单值信号量是，也可以完成一个资源的互斥访问。</p>
</li>
<li><p>互斥量的加锁和解锁必须由同一线程分别对应使用，信号量可以由一个线程释放，另一个线程得到。</p>
</li>
</ol>
<h3 id="套接字（-socket-）"><a href="#套接字（-socket-）" class="headerlink" title="套接字（ socket ）"></a>套接字（ <strong>socket</strong> ）</h3><p>套接字是一种通信机制，凭借这种机制，客户&#x2F;服务器（即要进行通信的进程）系统的开发工作既可以在本地单机上进行，也可以跨网络进行。也就是说它可以让不在同一台计算机但通过网络连接计算机上的进程进行通信。</p>
<p>套接字是支持TCP&#x2F;IP的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。</p>
<p><strong>套接字特性</strong><br>套接字的特性由3个属性确定，它们分别是：域、端口号、协议类型。</p>
<ol>
<li><p>套接字的域**<br>它指定套接字通信中使用的网络介质，最常见的套接字域有两种：<br><strong>一是AF_INET，它指的是Internet网络。</strong><br>当客户使用套接字进行跨网络的连接时，它就需要用到服务器计算机的IP地址和端口来指定一台联网机器上的某个特定服务，所以在使用socket作为通信的终点，服务器应用程序必须在开始通信之前绑定一个端口，服务器在指定的端口等待客户的连接。<br><strong>另一个域AF_UNIX，表示UNIX文件系统，</strong> 它就是文件输入&#x2F;输出，而它的地址就是文件名。</p>
</li>
<li><p>套接字的端口号<br>每一个基于TCP&#x2F;IP网络通讯的程序(进程)都被赋予了唯一的端口和端口号，端口是一个信息缓冲区，用于保留Socket中的输入&#x2F;输出信息，端口号是一个16位无符号整数，范围是0-65535，以区别主机上的每一个程序（端口号就像房屋中的房间号），低于256的端口号保留给标准应用程序，比如pop3的端口号就是110，每一个套接字都组合进了IP地址、端口，这样形成的整体就可以区别每一个套接字。</p>
</li>
<li><p>套接字协议类型<br>因特网提供三种通信机制，<br><strong>一是流套接字，</strong><br>流套接字在域中通过TCP&#x2F;IP连接实现，同时也是AF_UNIX中常用的套接字类型。流套接字提供的是一个有序、可靠、双向字节流的连接，因此发送的数据可以确保不会丢失、重复或乱序到达，而且它还有一定的出错后重新发送的机制。<br><strong>二个是数据报套接字，</strong><br>它不需要建立连接和维持一个连接，它们在域中通常是通过UDP&#x2F;IP协议实现的。它对可以发送的数据的长度有限制，数据报作为一个单独的网络消息被传输,它可能会丢失、复制或错乱到达，UDP不是一个可靠的协议，但是它的速度比较高，因为它并一需要总是要建立和维持一个连接。<br><strong>三是原始套接字，</strong> 原始套接字允许对较低层次的协议直接访问，比如IP、<br>ICMP协议，它常用于检验新的协议实现，或者访问现有服务中配置的新设备，因为RAW<br>SOCKET可以自如地控制Windows下的多种协议，能够对网络底层的传输机制进行控制，所以可以应用原始套接字来操纵网络层和传输层应用。比如，我们可以通过RAW<br>SOCKET来接收发向本机的ICMP、IGMP协议包，或者接收TCP&#x2F;IP栈不能够处理的IP包，也可以用来发送一些自定包头或自定协议的IP包。网络监听技术很大程度上依赖于SOCKET_RAW。</p>
</li>
</ol>
<blockquote>
<p><strong>原始套接字与标准套接字的区别在于：</strong>  </p>
<p>原始套接字可以读写内核没有处理的IP数据包，而流套接字只能读取TCP协议的数据，数据报套接字只能读取UDP协议的数据。因此，如果要访问其他协议发送数据必须使用原始套接字。</p>
</blockquote>
<p><strong>服务器端</strong></p>
<ol>
<li><p>首先服务器应用程序用系统调用socket来创建一个套接字，它是系统分配给该服务器进程的类似文件描述符的资源，它不能与其他的进程共享。</p>
</li>
<li><p>然后，服务器进程会给套接字起个名字，我们使用系统调用bind来给套接字命名。然后服务器进程就开始等待客户连接到这个套接字。</p>
</li>
<li><p>接下来，系统调用listen来创建一个队列并将其用于存放来自客户的进入连接。</p>
</li>
<li><p>最后，服务器通过系统调用accept来接受客户的连接。它会创建一个与原有的命名套接不同的新套接字，这个套接字只用于与这个特定客户端进行通信，而命名套接字（即原先的套接字）则被保留下来继续处理来自其他客户的连接（建立客户端和服务端的用于通信的流，进行通信）。</p>
</li>
</ol>
<p><strong>客户端</strong></p>
<ol>
<li>客户应用程序首先调用socket来创建一个未命名的套接字，然后将服务器的命名套接字作为一个地址来调用connect与服务器建立连接。</li>
<li>一旦连接建立，我们就可以像使用底层的文件描述符那样用套接字来实现双向数据的通信（通过流进行数据传输）。</li>
</ol>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>各种通信方式的比较和优缺点</p>
<ol>
<li>管道：速度慢，容量有限，只有父子进程能通讯</li>
<li>FIFO：任何进程间都能通讯，但速度慢</li>
<li>消息队列：容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题</li>
<li>信号量：不能传递复杂消息，只能用来同步</li>
<li>共享内存区：能够很容易控制容量，速度快，但要保持同步，比如一个进程在写的时候，另一个进程要注意读写的问题，相当于线程中的线程安全，当然，共享内存区同样可以用作线程间通讯，不过没这个必要，线程间本来就已经共享了同一进程内的一块内存</li>
</ol>
<h1 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h1><p>所谓死锁，是指多个进程循环等待它方占有的资源而无限期地僵持下去的局面。</p>
<h2 id="死锁的产生"><a href="#死锁的产生" class="headerlink" title="死锁的产生"></a>死锁的产生</h2><p>如果在计算机系统中同时具备下面四个必要条件时，那麽会发生死锁。换句话说，只要下面四个条件有一个不具备，系统就不会出现死锁。</p>
<ol>
<li><p>互斥条件。即某个资源在一段时间内只能由一个进程占有，不能同时被两个或两个以上的进程占有。这种独占资源如CD-ROM驱动器，打印机等等，必须在占有该资源的进程主动释放它之后，其它进程才能占有该资源。这是由资源本身的属性所决定的。如独木桥就是一种独占资源，两方的人不能同时过桥。</p>
</li>
<li><p>不可抢占条件。进程所获得的资源在未使用完毕之前，资源申请者不能强行地从资源占有者手中夺取资源，而只能由该资源的占有者进程自行释放。如过独木桥的人不能强迫对方后退，也不能非法地将对方推下桥，必须是桥上的人自己过桥后空出桥面（即主动释放占有资源），对方的人才能过桥。</p>
</li>
<li><p>占有且申请条件。进程至少已经占有一个资源，但又申请新的资源；由于该资源已被另外进程占有，此时该进程阻塞；但是，它在等待新资源之时，仍继续占用已占有的资源。还以过独木桥为例，甲乙两人在桥上相遇。甲走过一段桥面（即占有了一些资源），还需要走其余的桥面（申请新的资源），但那部分桥面被乙占有（乙走过一段桥面）。甲过不去，前进不能，又不后退；乙也处于同样的状况。</p>
</li>
<li><p>循环等待条件。存在一个进程等待序列{P1，P2，…，Pn}，其中P1等待P2所占有的某一资源，P2等待P3所占有的某一源，……，而Pn等待P1所占有的的某一资源，形成一个进程循环等待环。就像前面的过独木桥问题，甲等待乙占有的桥面，而乙又等待甲占有的桥面，从而彼此循环等待。</p>
</li>
</ol>
<p>上面我们提到的这四个条件在死锁时会同时发生。也就是说，只要有一个必要条件不满足，则死锁就可以排除。</p>
<h2 id="死锁的预防"><a href="#死锁的预防" class="headerlink" title="死锁的预防"></a>死锁的预防</h2><p>前面介绍了死锁发生时的四个必要条件，只要破坏这四个必要条件中的任意一个条件，死锁就不会发生。这就为我们解决死锁问题提供了可能。一般地，解决死锁的方法分为死锁的预防，避免，检测与恢复三种（注意：死锁的检测与恢复是一个方法）。我们将在下面分别加以介绍。</p>
<p>死锁的预防是保证系统不进入死锁状态的一种策略。它的基本思想是要求进程申请资源时遵循某种协议，从而打破产生死锁的四个必要条件中的一个或几个，保证系统不会进入死锁状态。</p>
<ol>
<li>打破互斥条件。即允许进程同时访问某些资源。但是，有的资源是不允许被同时访问的，像打印机等等，这是由资源本身的属性所决定的。所以，这种办法并无实用价值。</li>
<li>打破不可抢占条件。即允许进程强行从占有者那里夺取某些资源。就是说，当一个进程已占有了某些资源，它又申请新的资源，但不能立即被满足时，它必须释放所占有的全部资源，以后再重新申请。它所释放的资源可以分配给其它进程。这就相当于该进程占有的资源被隐蔽地强占了。这种预防死锁的方法实现起来困难，会降低系统性能。 </li>
<li>打破占有且申请条件。可以实行资源预先分配策略。即进程在运行前一次性地向系统申请它所需要的全部资源。如果某个进程所需的全部资源得不到满足，则不分配任何资源，此进程暂不运行。只有当系统能够满足当前进程的全部资源需求时，才一次性地将所申请的资源全部分配给该进程。由于运行的进程已占有了它所需的全部资源，所以不会发生占有资源又申请资源的现象，因此不会发生死锁。但是，这种策略也有如下缺点：</li>
</ol>
<ul>
<li>在许多情况下，一个进程在执行之前不可能知道它所需要的全部资源。这是由于进程在执行时是动态的，不可预测的；</li>
<li>资源利用率低。无论所分资源何时用到，一个进程只有在占有所需的全部资源后才能执行。即使有些资源最后才被该进程用到一次，但该进程在生存期间却一直占有它们，造成长期占着不用的状况。这显然是一种极大的资源浪费；</li>
<li>降低了进程的并发性。因为资源有限，又加上存在浪费，能分配到所需全部资源的进程个数就必然少了。</li>
</ul>
<ol start="4">
<li>打破循环等待条件，实行资源有序分配策略。采用这种策略，即把资源事先分类编号，按号分配，使进程在申请，占用资源时不会形成环路。所有进程对资源的请求必须严格按资源序号递增的顺序提出。进程占用了小号资源，才能申请大号资源，就不会产生环路，从而预防了死锁。这种策略与前面的策略相比，资源的利用率和系统吞吐量都有很大提高，但是也存在以下缺点：</li>
</ol>
<ul>
<li>限制了进程对资源的请求，同时给系统中所有资源合理编号也是件困难事，并增加了系统开销；</li>
<li>为了遵循按编号申请的次序，暂不使用的资源也需要提前申请，从而增加了进程对资源的占用时间。</li>
</ul>
<h2 id="死锁的避免"><a href="#死锁的避免" class="headerlink" title="死锁的避免"></a>死锁的避免</h2><p>上面我们讲到的死锁预防是排除死锁的静态策略，它使产生死锁的四个必要条件不能同时具备，从而对进程申请资源的活动加以限制，以保证死锁不会发生。下面我们介绍排除死锁的动态策略–死锁的避免，它不限制进程有关申请资源的命令，而是对进程所发出的每一个申请资源命令加以动态地检查，并根据检查结果决定是否进行资源分配。就是说，在资源分配过程中若预测有发生死锁的可能性，则加以避免。这种方法的关键是确定资源分配的安全性。</p>
<ol>
<li>安全序列</li>
</ol>
<p>我们首先引入安全序列的定义：所谓系统是安全的，是指系统中的所有进程能够按照某一种次序分配资源，并且依次地运行完毕，这种进程序列{P1，P2，…，Pn}就是安全序列。如果存在这样一个安全序列，则系统是安全的；如果系统不存在这样一个安全序列，则系统是不安全的。</p>
<p>安全序列{P1，P2，…，Pn}是这样组成的：若对于每一个进程Pi，它需要的附加资源可以被系统中当前可用资源加上所有进程Pj当前占有资源之和所满足，则{P1，P2，…，Pn}为一个安全序列，这时系统处于安全状态，不会进入死锁状态。</p>
<p>虽然存在安全序列时一定不会有死锁发生，但是系统进入不安全状态（四个死锁的必要条件同时发生）也未必会产生死锁。当然，产生死锁后，系统一定处于不安全状态。</p>
<ol start="2">
<li>银行家算法</li>
</ol>
<p>这是一个著名的避免死锁的算法，是由Dijstra首先提出来并加以解决的。</p>
<p>当一个进程申请使用资源的时候，银行家算法通过先 <strong>试探</strong><br>分配给该进程资源，然后通过安全性算法判断分配后的系统是否处于安全状态，若不安全则试探分配作废，让该进程继续等待。</p>
<p><img src="/images/%E9%93%B6%E8%A1%8C%E5%AE%B6%E7%AE%97%E6%B3%95.jpeg" alt="银行家算法"></p>
<h2 id="死锁的检查与恢复"><a href="#死锁的检查与恢复" class="headerlink" title="死锁的检查与恢复"></a>死锁的检查与恢复</h2><h3 id="死锁的检查"><a href="#死锁的检查" class="headerlink" title="死锁的检查"></a>死锁的检查</h3><p>检查死锁的办法就是检查系统中由进程和资源构成的有向图是否构成一个或多个环路，若是，则存在死锁，否则不存在。<br>由于死锁是系统中的恶性小概率事件，死锁检测程序的多次执行往往都不会调用一次死锁解除程序，而这却增加了系统开销，因此在设计操作系统时需要权衡检测精度与时间开销。</p>
<h3 id="死锁的恢复"><a href="#死锁的恢复" class="headerlink" title="死锁的恢复"></a>死锁的恢复</h3><p>一旦在死锁检测时发现了死锁，就要消除死锁，使系统从死锁状态中恢复过来。</p>
<ol>
<li>最简单，最常用的方法就是进行系统的重新启动，不过这种方法代价很大，它意味着在这之前所有的进程已经完成的计算工作都将付之东流，包括参与死锁的那些进程，以及未参与死锁的进程。</li>
<li>撤消进程，剥夺资源。终止参与死锁的进程，收回它们占有的资源，从而解除死锁。这时又分两种情况：一次性撤消参与死锁的全部进程，剥夺全部资源；或者逐步撤消参与死锁的进程，逐步收回死锁进程占有的资源。一般来说，选择逐步撤消的进程时要按照一定的原则进行，目的是撤消那些代价最小的进程，比如按进程的优先级确定进程的代价；考虑进程运行时的代价和与此进程相关的外部作业的代价等因素。</li>
</ol>
<p>此外，还有进程回退策略，即让参与死锁的进程回退到没有发生死锁前某一点处，并由此点处继续执行，以求再次执行时不再发生死锁。虽然这是个较理想的办法，但是操作起来系统开销极大，要有堆栈这样的机构记录进程的每一步变化，以便今后的回退，有时这是无法做到的。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/02/17/jvm/JVM%E7%9A%84%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="merric">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Myoboku">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Myoboku">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/02/17/jvm/JVM%E7%9A%84%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/" class="post-title-link" itemprop="url">JVM内存结构</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-02-17 22:30:00" itemprop="dateCreated datePublished" datetime="2020-02-17T22:30:00+00:00">2020-02-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="JVM内存结构"><a href="#JVM内存结构" class="headerlink" title="JVM内存结构"></a>JVM内存结构</h1><p>首先，放张jvm架构图</p>
<p><img src="/images/JVM%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84.jpg" alt="JVM架构图"></p>
<p>JVM内存结构主要有三大块： <strong>堆内存</strong> 、 <strong>方法区</strong> 和 <strong>栈</strong><br>。堆内存是JVM中最大的一块由年轻代和老年代组成，而年轻代内存又被分成三部分， <strong>Eden空间</strong> 、 <strong>From Survivor空间</strong> 、<br><strong>To Survivor空间</strong> ,默认情况下年轻代按照 <strong>8:1:1</strong> 的比例来分配；</p>
<p>方法区存储类信息、常量、静态变量等数据，是线程共享的区域，为与Java堆区分，方法区还有一个别名Non-<br>Heap(非堆)；栈又分为java虚拟机栈和本地方法栈主要用于方法的执行。</p>
<p>Java<br>虚拟机定义了若干种程序运行期间会使用到的运行时数据区，其中有一些会随着虚拟机启动而创建，随着虚拟机退出而销毁。另外一些则是与线程一一对应的，这些与线程一一对应的数据区域会随着线程开始和结束而创建和销毁。</p>
<ul>
<li><strong>线程私有</strong> ：程序计数器、虚拟机栈、本地方法区</li>
<li><strong>线程共享</strong> ：堆、方法区, 堆外内存（Java7的永久代或JDK8的元空间、代码缓存）</li>
</ul>
<h2 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h2><p>程序计数寄存器（ <strong>Program Counter Register</strong> ），Register 的命名源于 CPU<br>的寄存器，寄存器存储指令相关的线程信息，CPU 只有把数据装载到寄存器才能够运行。</p>
<p>这里，并非是广义上所指的物理寄存器，叫程序计数器（或PC计数器或指令计数器）会更加贴切，并且也不容易引起一些不必要的误会。 <strong>JVM 中的 PC<br>寄存器是对物理 PC 寄存器的一种抽象模拟</strong> 。</p>
<p>程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的 <strong>行号指示器</strong> 。</p>
<h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><p>PC 寄存器用来存储指向下一条指令的地址，即将要执行的指令代码。由执行引擎读取下一条指令。</p>
<p><img src="/images/PC%E5%AF%84%E5%AD%98%E5%99%A8.jpg" alt="PC寄存器"></p>
<p>（分析：进入class文件所在目录，执行 <code>javap -v xx.class</code> 反解析（或者通过 IDEA 插件 <code>Jclasslib</code><br>直接查看，上图），可以看到当前类对应的Code区（汇编指令）、本地变量表、异常表和代码行偏移量映射表、常量池等信息。）</p>
<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><blockquote>
<p>通过下面两个问题，理解下PC计数器</p>
</blockquote>
<ul>
<li><strong>使用PC寄存器存储字节码指令地址有什么用呢？为什么使用PC寄存器记录当前线程的执行地址呢？</strong></li>
</ul>
<p>因为CPU需要不停的切换各个线程，这时候切换回来以后，就得知道接着从哪开始继续执行。JVM的字节码解释器就需要通过改变PC寄存器的值来明确下一条应该执行什么样的字节码指令。</p>
<ul>
<li><strong>PC寄存器为什么会被设定为线程私有的？</strong></li>
</ul>
<p>多线程在一个特定的时间段内只会执行其中某一个线程方法，CPU会不停的做任务切换，这样必然会导致经常中断或恢复。为了能够准确的记录各个线程正在执行的当前字节码指令地址，所以为每个线程都分配了一个PC寄存器，每个线程都独立计算，不会互相影响。</p>
<blockquote>
<p>相关总结如下：</p>
</blockquote>
<ul>
<li>它是一块很小的内存空间，几乎可以忽略不计。也是运行速度最快的存储区域</li>
<li>在 JVM 规范中，每个线程都有它自己的程序计数器，是线程私有的，生命周期与线程的生命周期一致</li>
<li>任何时间一个线程都只有一个方法在执行，也就是所谓的 <strong>当前方法</strong> 。如果当前线程正在执行的是 Java 方法，程序计数器记录的是 JVM 字节码指令地址，如果是执行 native 方法，则是未指定值（undefined）</li>
<li>它是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成</li>
<li>字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令</li>
<li><strong>它是唯一一个在 JVM 规范中没有规定任何<code>OutOfMemoryError</code> 情况的区域</strong></li>
</ul>
<h2 id="虚拟机栈"><a href="#虚拟机栈" class="headerlink" title="虚拟机栈"></a>虚拟机栈</h2><h3 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h3><blockquote>
<p>Java 虚拟机栈(Java Virtual Machine Stacks)，早期也叫 Java<br>栈。每个线程在创建的时候都会创建一个虚拟机栈，其内部保存一个个的栈帧(Stack Frame），对应着一次次 Java<br>方法调用，是线程私有的，生命周期和线程一致。</p>
</blockquote>
<p><strong>作用</strong> ：主管 Java 程序的运行，它保存方法的局部变量、部分结果，并参与方法的调用和返回。</p>
<p><strong>特点</strong> ：</p>
<ul>
<li>栈是一种快速有效的分配存储方式，访问速度仅次于程序计数器</li>
<li>JVM 直接对虚拟机栈的操作只有两个：每个方法执行，伴随着 <strong>入栈</strong> （进栈&#x2F;压栈），方法执行结束 <strong>出栈</strong></li>
<li><strong>栈不存在垃圾回收问题</strong></li>
</ul>
<p><strong>栈中可能出现的异常</strong> ：</p>
<p>Java 虚拟机规范允许 <strong>Java虚拟机栈的大小是动态的或者是固定不变的</strong></p>
<ul>
<li>如果采用固定大小的 Java 虚拟机栈，那每个线程的 Java 虚拟机栈容量可以在线程创建的时候独立选定。如果线程请求分配的栈容量超过 Java 虚拟机栈允许的最大容量，Java 虚拟机将会抛出一个 <strong>StackOverflowError</strong> 异常</li>
<li>如果 Java 虚拟机栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的虚拟机栈，那 Java 虚拟机将会抛出一个 <strong>OutOfMemoryError</strong> 异常</li>
</ul>
<p>可以通过参数<code>-Xss</code>来设置线程的最大栈空间，栈的大小直接决定了函数调用的最大可达深度。</p>
<p>官方提供的参考工具，可查一些参数和操作：<a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/8/docs/technotes/tools/windows/java.html#BGBCIEFC">https://docs.oracle.com/javase/8/docs/technotes/tools/windows/java.html#BGBCIEFC</a></p>
<h3 id="栈的存储单位"><a href="#栈的存储单位" class="headerlink" title="栈的存储单位"></a>栈的存储单位</h3><p>栈中存储什么？</p>
<ul>
<li>每个线程都有自己的栈，栈中的数据都是以 <strong>栈帧（Stack Frame）的格式存在</strong></li>
<li>在这个线程上正在执行的每个方法都各自有对应的一个栈帧</li>
<li>栈帧是一个内存区块，是一个数据集，维系着方法执行过程中的各种数据信息</li>
</ul>
<h3 id="栈运行原理"><a href="#栈运行原理" class="headerlink" title="栈运行原理"></a>栈运行原理</h3><ul>
<li>JVM 直接对 Java 栈的操作只有两个，对栈帧的 <strong>压栈</strong> 和 <strong>出栈</strong> ，遵循“先进后出&#x2F;后进先出”原则</li>
<li>在一条活动线程中，一个时间点上，只会有一个活动的栈帧。即只有当前正在执行的方法的栈帧（ <strong>栈顶栈帧</strong> ）是有效的，这个栈帧被称为 <strong>当前栈帧</strong> （Current Frame），与当前栈帧对应的方法就是 <strong>当前方法</strong> （Current Method），定义这个方法的类就是 <strong>当前类</strong> （Current Class）</li>
<li>执行引擎运行的所有字节码指令只针对当前栈帧进行操作</li>
<li>如果在该方法中调用了其他方法，对应的新的栈帧会被创建出来，放在栈的顶端，称为新的当前栈帧</li>
<li>不同线程中所包含的栈帧是不允许存在相互引用的，即不可能在一个栈帧中引用另外一个线程的栈帧</li>
<li>如果当前方法调用了其他方法，方法返回之际，当前栈帧会传回此方法的执行结果给前一个栈帧，接着，虚拟机会丢弃当前栈帧，使得前一个栈帧重新成为当前栈帧</li>
<li>Java 方法有两种返回函数的方式， <strong>一种是正常的函数返回，使用 return 指令，另一种是抛出异常，不管用哪种方式，都会导致栈帧被弹出</strong></li>
</ul>
<p>IDEA 在 debug 时候，可以在 debug 窗口看到 Frames 中各种方法的压栈和出栈情况</p>
<p><img src="/images/%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%E6%A0%88.jpg" alt="方法调用栈"></p>
<h3 id="栈帧的内部结构"><a href="#栈帧的内部结构" class="headerlink" title="栈帧的内部结构"></a>栈帧的内部结构</h3><p>每个 <strong>栈帧</strong> （Stack Frame）中存储着：</p>
<ul>
<li>局部变量表（Local Variables）</li>
<li>操作数栈（Operand Stack）(或称为表达式栈)</li>
<li>动态链接（Dynamic Linking）：指向运行时常量池的方法引用</li>
<li>方法返回地址（Return Address）：方法正常退出或异常退出的地址</li>
<li>一些附加信息</li>
</ul>
<p><img src="/images/%E6%A0%88%E8%A7%A3%E6%9E%90.jpg" alt="栈解析"></p>
<h4 id="局部变量表"><a href="#局部变量表" class="headerlink" title="局部变量表"></a>局部变量表</h4><ul>
<li>局部变量表也被称为局部变量数组或者本地变量表</li>
<li>是一组变量值存储空间， <strong>主要用于存储方法参数和定义在方法体内的局部变量</strong> ，包括编译器可知的各种 Java 虚拟机 <strong>基本数据类型</strong> （boolean、byte、char、short、int、float、long、double）、 <strong>对象引用</strong> （reference类型，它并不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此相关的位置）和 <strong>returnAddress</strong> 类型（指向了一条字节码指令的地址，已被异常表取代）</li>
<li>由于局部变量表是建立在线程的栈上，是线程的私有数据，因此 <strong>不存在数据安全问题</strong></li>
<li><strong>局部变量表所需要的容量大小是编译期确定下来的</strong> ，并保存在方法的 Code 属性的 <code>maximum local variables</code> 数据项中。在方法运行期间是不会改变局部变量表的大小的</li>
<li>方法嵌套调用的次数由栈的大小决定。一般来说， <strong>栈越大，方法嵌套调用次数越多</strong> 。对一个函数而言，它的参数和局部变量越多，使得局部变量表膨胀，它的栈帧就越大，以满足方法调用所需传递的信息增大的需求。进而函数调用就会占用更多的栈空间，导致其嵌套调用次数就会减少。</li>
<li><strong>局部变量表中的变量只在当前方法调用中有效</strong> 。在方法执行时，虚拟机通过使用局部变量表完成参数值到参数变量列表的传递过程。当方法调用结束后，随着方法栈帧的销毁，局部变量表也会随之销毁。</li>
<li>参数值的存放总是在局部变量数组的 index0 开始，到数组长度 -1 的索引结束</li>
</ul>
<h5 id="槽-Slot"><a href="#槽-Slot" class="headerlink" title="槽 Slot"></a>槽 Slot</h5><ul>
<li>局部变量表最基本的存储单元是 Slot（变量槽）</li>
<li>在局部变量表中，32 位以内的类型只占用一个 Slot(包括returnAddress类型)，64 位的类型（long和double）占用两个连续的 Slot<ul>
<li>byte、short、char 在存储前被转换为int，boolean也被转换为int，0 表示 false，非 0 表示 true</li>
<li>long 和 double 则占据两个 Slot</li>
</ul>
</li>
<li>JVM 会为局部变量表中的每一个 Slot 都分配一个访问索引，通过这个索引即可成功访问到局部变量表中指定的局部变量值，索引值的范围从 0 开始到局部变量表最大的 Slot 数量</li>
<li>当一个实例方法被调用的时候，它的方法参数和方法体内部定义的局部变量将会 <strong>按照顺序被复制</strong> 到局部变量表中的每一个 Slot 上</li>
<li><strong>如果需要访问局部变量表中一个 64bit 的局部变量值时，只需要使用前一个索引即可</strong> 。（比如：访问 long 或 double 类型变量，不允许采用任何方式单独访问其中的某一个 Slot）</li>
<li>如果当前帧是由构造方法或实例方法创建的，那么该对象引用 this 将会存放在 index 为 0 的 Slot 处，其余的参数按照参数表顺序继续排列（这里就引出一个问题：静态方法中为什么不可以引用 this，就是因为this 变量不存在于当前方法的局部变量表中）</li>
<li><strong>栈帧中的局部变量表中的槽位是可以重用的</strong> ，如果一个局部变量过了其作用域，那么在其作用域之后申明的新的局部变量就很有可能会复用过期局部变量的槽位，从而 <strong>达到节省资源的目的</strong> 。（下图中，this、a、b、c 理论上应该有 4 个变量，c 复用了 b 的槽）</li>
</ul>
<p><img src="/images/%E6%A7%BD.jpg" alt="槽"></p>
<ul>
<li>在栈帧中，与性能调优关系最为密切的就是局部变量表。在方法执行时，虚拟机使用局部变量表完成方法的传递</li>
<li><strong>局部变量表中的变量也是重要的垃圾回收根节点，只要被局部变量表中直接或间接引用的对象都不会被回收</strong></li>
</ul>
<h4 id="操作数栈"><a href="#操作数栈" class="headerlink" title="操作数栈"></a>操作数栈</h4><ul>
<li>每个独立的栈帧中除了包含局部变量表之外，还包含一个 <strong>后进先出</strong> （Last-In-First-Out）的操作数栈，也可以称为 <strong>表达式栈</strong> （Expression Stack）</li>
<li><strong>操作数栈，在方法执行过程中，根据字节码指令，往操作数栈中写入数据或提取数据，即入栈（push）、出栈（pop）</strong></li>
<li>某些字节码指令将值压入操作数栈，其余的字节码指令将操作数取出栈。使用它们后再把结果压入栈。比如，执行复制、交换、求和等操作</li>
</ul>
<h5 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h5><ul>
<li>操作数栈， <strong>主要用于保存计算过程的中间结果，同时作为计算过程中变量临时的存储空间</strong></li>
<li>操作数栈就是 JVM 执行引擎的一个工作区，当一个方法刚开始执行的时候，一个新的栈帧也会随之被创建出来， <strong>此时这个方法的操作数栈是空的</strong></li>
<li>每一个操作数栈都会拥有一个明确的栈深度用于存储数值，其所需的最大深度在编译期就定义好了，保存在方法的 Code 属性的 <code>max_stack</code> 数据项中</li>
<li>栈中的任何一个元素都可以是任意的 Java 数据类型 <ul>
<li>32bit 的类型占用一个栈单位深度</li>
<li>64bit 的类型占用两个栈单位深度</li>
</ul>
</li>
<li>操作数栈并非采用访问索引的方式来进行数据访问的，而是只能通过标准的入栈和出栈操作来完成一次数据访问</li>
<li><strong>如果被调用的方法带有返回值的话，其返回值将会被压入当前栈帧的操作数栈中</strong> ，并更新 PC 寄存器中下一条需要执行的字节码指令</li>
<li>操作数栈中元素的数据类型必须与字节码指令的序列严格匹配，这由编译器在编译期间进行验证，同时在类加载过程中的类检验阶段的数据流分析阶段要再次验证</li>
<li>另外，我们说 <strong>Java虚拟机的解释引擎是基于栈的执行引擎</strong> ，其中的栈指的就是操作数栈</li>
</ul>
<h5 id="栈顶缓存（Top-of-stack-Cashing）"><a href="#栈顶缓存（Top-of-stack-Cashing）" class="headerlink" title="栈顶缓存（Top-of-stack-Cashing）"></a>栈顶缓存（Top-of-stack-Cashing）</h5><p>HotSpot 的执行引擎采用的并非是基于寄存器的架构，但这并不代表 HotSpot VM 的实现并没有间接利用到寄存器资源。寄存器是物理 CPU<br>中的组成部分之一，它同时也是 CPU<br>中非常重要的高速存储资源。一般来说，寄存器的读&#x2F;写速度非常迅速，甚至可以比内存的读&#x2F;写速度快上几十倍不止，不过寄存器资源却非常有限，不同平台下的CPU<br>寄存器数量是不同和不规律的。寄存器主要用于缓存本地机器指令、数值和下一条需要被执行的指令地址等数据。</p>
<p>基于栈式架构的虚拟机所使用的零地址指令更加紧凑，但完成一项操作的时候必然需要使用更多的入栈和出栈指令，这同时也就意味着将需要更多的指令分派（instruction<br>dispatch）次数和内存读&#x2F;写次数。由于操作数是存储在内存中的，因此频繁的执行内存读&#x2F;写操作必然会影响执行速度。为了解决这个问题，HotSpot JVM<br>设计者们提出了栈顶缓存技术， <strong>将栈顶元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读&#x2F;写次数，提升执行引擎的执行效率</strong></p>
<h4 id="动态链接（指向运行时常量池的方法引用）"><a href="#动态链接（指向运行时常量池的方法引用）" class="headerlink" title="动态链接（指向运行时常量池的方法引用）"></a>动态链接（指向运行时常量池的方法引用）</h4><ul>
<li><strong>每一个栈帧内部都包含一个指向运行时常量池中该栈帧所属方法的引用</strong> 。包含这个引用的目的就是为了支持当前方法的代码能够实现动态链接(Dynamic Linking)。</li>
<li>在 Java 源文件被编译到字节码文件中时，所有的变量和方法引用都作为 <strong>符号引用</strong> （Symbolic Reference）保存在 Class 文件的常量池中。比如：描述一个方法调用了另外的其他方法时，就是通过常量池中指向方法的符号引用来表示的，那么 <strong>动态链接的作用就是为了将这些符号引用转换为调用方法的直接引用</strong></li>
</ul>
<p><img src="/images/%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5%E4%BD%9C%E7%94%A8.jpg" alt="动态链接作用"></p>
<h5 id="JVM-是如何执行方法调用的"><a href="#JVM-是如何执行方法调用的" class="headerlink" title="JVM 是如何执行方法调用的"></a>JVM 是如何执行方法调用的</h5><p>方法调用不同于方法执行，方法调用阶段的唯一任务就是确定被调用方法的版本（即调用哪一个方法），暂时还不涉及方法内部的具体运行过程。Class<br>文件的编译过程中不包括传统编译器中的连接步骤，一切方法调用在 Class文件里面存储的都是 <strong>符号引用</strong> ，而不是方法在实际运行时内存布局中的入口地址（<br><strong>直接引用</strong> ）。也就是需要在类加载阶段，甚至到运行期才能确定目标方法的直接引用。</p>
<blockquote>
<p>【这一块内容，除了方法调用，还包括解析、分派（静态分派、动态分派、单分派与多分派），这里先不介绍，后续再挖】</p>
</blockquote>
<p>在 JVM 中，将符号引用转换为调用方法的直接引用与方法的绑定机制有关</p>
<ul>
<li><strong>静态链接</strong> ：当一个字节码文件被装载进 JVM 内部时，如果被调用的 <strong>目标方法在编译期可知</strong> ，且运行期保持不变时。这种情况下将调用方法的符号引用转换为直接引用的过程称之为静态链接</li>
<li><strong>动态链接</strong> ：如果被调用的方法在编译期无法被确定下来，也就是说，只能在程序运行期将调用方法的符号引用转换为直接引用，由于这种引用转换过程具备动态性，因此也就被称之为动态链接</li>
</ul>
<p>对应的方法的绑定机制为：早期绑定（Early Binding）和晚期绑定（Late Binding）。<br><strong>绑定是一个字段、方法或者类在符号引用被替换为直接引用的过程，这仅仅发生一次</strong> 。</p>
<ul>
<li>早期绑定： <strong>早期绑定就是指被调用的目标方法如果在编译期可知，且运行期保持不变时</strong> ，即可将这个方法与所属的类型进行绑定，这样一来，由于明确了被调用的目标方法究竟是哪一个，因此也就可以使用静态链接的方式将符号引用转换为直接引用。</li>
<li>晚期绑定：如果被调用的方法在编译器无法被确定下来，只能够在程序运行期根据实际的类型绑定相关的方法，这种绑定方式就被称为晚期绑定。</li>
</ul>
<h5 id="虚方法和非虚方法"><a href="#虚方法和非虚方法" class="headerlink" title="虚方法和非虚方法"></a>虚方法和非虚方法</h5><ul>
<li>如果方法在编译器就确定了具体的调用版本，这个版本在运行时是不可变的。这样的方法称为非虚方法，比如静态方法、私有方法、final 方法、实例构造器、父类方法都是非虚方法</li>
<li>其他方法称为虚方法</li>
</ul>
<h5 id="虚方法表"><a href="#虚方法表" class="headerlink" title="虚方法表"></a>虚方法表</h5><p>在面向对象编程中，会频繁的使用到动态分派，如果每次动态分派都要重新在类的方法元数据中搜索合适的目标有可能会影响到执行效率。为了提高性能，JVM<br>采用在类的方法区建立一个虚方法表（virtual method table），使用索引表来代替查找。非虚方法不会出现在表中。</p>
<p>每个类中都有一个虚方法表，表中存放着各个方法的实际入口。</p>
<p>虚方法表会在类加载的连接阶段被创建并开始初始化，类的变量初始值准备完成之后，JVM 会把该类的方法表也初始化完毕。</p>
<h4 id="方法返回地址（return-address）"><a href="#方法返回地址（return-address）" class="headerlink" title="方法返回地址（return address）"></a>方法返回地址（return address）</h4><p>用来存放调用该方法的 PC 寄存器的值。</p>
<p>一个方法的结束，有两种方式</p>
<ul>
<li>正常执行完成</li>
<li>出现未处理的异常，非正常退出</li>
</ul>
<p>无论通过哪种方式退出，在方法退出后都返回到该方法被调用的位置。方法正常退出时，调用者的 PC<br>计数器的值作为返回地址，即调用该方法的指令的下一条指令的地址。而通过异常退出的，返回地址是要通过异常表来确定的，栈帧中一般不会保存这部分信息。</p>
<p>当一个方法开始执行后，只有两种方式可以退出这个方法：</p>
<ol>
<li>执行引擎遇到任意一个方法返回的字节码指令，会有返回值传递给上层的方法调用者，简称 <strong>正常完成出口</strong></li>
</ol>
<p>一个方法的正常调用完成之后究竟需要使用哪一个返回指令还需要根据方法返回值的实际数据类型而定</p>
<p>在字节码指令中，返回指令包含 ireturn(当返回值是 boolean、byte、char、short 和 int<br>类型时使用)、lreturn、freturn、dreturn 以及 areturn，另外还有一个 return 指令供声明为 void<br>的方法、实例初始化方法、类和接口的初始化方法使用。</p>
<ol start="2">
<li>在方法执行的过程中遇到了异常，并且这个异常没有在方法内进行处理，也就是只要在本方法的异常表中没有搜索到匹配的异常处理器，就会导致方法退出。简称 <strong>异常完成出口</strong></li>
</ol>
<p>方法执行过程中抛出异常时的异常处理，存储在一个异常处理表，方便在发生异常的时候找到处理异常的代码。</p>
<p>本质上， <strong>方法的退出就是当前栈帧出栈的过程</strong><br>。此时，需要恢复上层方法的局部变量表、操作数栈、将返回值压入调用者栈帧的操作数栈、设置PC寄存器值等，让调用者方法继续执行下去。</p>
<p>正常完成出口和异常完成出口的区别在于： <strong>通过异常完成出口退出的不会给他的上层调用者产生任何的返回值</strong></p>
<h4 id="附加信息"><a href="#附加信息" class="headerlink" title="附加信息"></a>附加信息</h4><p>栈帧中还允许携带与 Java 虚拟机实现相关的一些附加信息。例如，对程序调试提供支持的信息，但这些信息取决于具体的虚拟机实现。</p>
<h2 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h2><h3 id="本地方法接口"><a href="#本地方法接口" class="headerlink" title="本地方法接口"></a>本地方法接口</h3><p>简单的讲，一个 Native Method 就是一个 Java 调用非 Java 代码的接口。我们知道的 Unsafe 类就有很多本地方法。</p>
<blockquote>
<p>为什么要使用本地方法（Native Method）?</p>
</blockquote>
<p>Java 使用起来非常方便，然而有些层次的任务用 Java 实现起来也不容易，或者我们对程序的效率很在意时，问题就来了</p>
<ul>
<li>与 Java 环境外交互：有时 Java 应用需要与 Java 外面的环境交互，这就是本地方法存在的原因。</li>
<li>与操作系统交互：JVM 支持 Java 语言本身和运行时库，但是有时仍需要依赖一些底层系统的支持。通过本地方法，我们可以实现用 Java 与实现了 jre 的底层系统交互， JVM 的一些部分就是 C 语言写的。</li>
<li>Sun’s Java：Sun的解释器就是C实现的，这使得它能像一些普通的C一样与外部交互。jre大部分都是用 Java 实现的，它也通过一些本地方法与外界交互。比如，类 <code>java.lang.Thread</code> 的 <code>setPriority()</code> 的方法是用Java 实现的，但它实现调用的是该类的本地方法 <code>setPrioruty()</code>，该方法是C实现的，并被植入 JVM 内部。</li>
</ul>
<h3 id="本地方法栈（Native-Method-Stack）"><a href="#本地方法栈（Native-Method-Stack）" class="headerlink" title="本地方法栈（Native Method Stack）"></a>本地方法栈（Native Method Stack）</h3><ul>
<li>Java 虚拟机栈用于管理 Java 方法的调用，而本地方法栈用于管理本地方法的调用</li>
<li>本地方法栈也是线程私有的</li>
<li>允许线程固定或者可动态扩展的内存大小<ul>
<li>如果线程请求分配的栈容量超过本地方法栈允许的最大容量，Java 虚拟机将会抛出一个 <code>StackOverflowError</code> 异常</li>
<li>如果本地方法栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的本地方法栈，那么 Java虚拟机将会抛出一个<code>OutofMemoryError</code>异常</li>
</ul>
</li>
<li>本地方法是使用 C 语言实现的</li>
<li>它的具体做法是 <code>Native Method Stack</code> 中登记 native 方法，在 <code>Execution Engine</code> 执行时加载本地方法库当某个线程调用一个本地方法时，它就进入了一个全新的并且不再受虚拟机限制的世界。它和虚拟机拥有同样的权限。</li>
<li>本地方法可以通过本地方法接口来访问虚拟机内部的运行时数据区，它甚至可以直接使用本地处理器中的寄存器，直接从本地内存的堆中分配任意数量的内存</li>
<li>并不是所有 JVM 都支持本地方法。因为 Java 虚拟机规范并没有明确要求本地方法栈的使用语言、具体实现方式、数据结构等。如果 JVM 产品不打算支持 native 方法，也可以无需实现本地方法栈</li>
<li>在 Hotspot JVM 中，直接将本地方法栈和虚拟机栈合二为一</li>
</ul>
<blockquote>
<p><strong>栈是运行时的单位，而堆是存储的单位</strong> 。</p>
<p>栈解决程序的运行问题，即程序如何执行，或者说如何处理数据。堆解决的是数据存储的问题，即数据怎么放、放在哪。</p>
</blockquote>
<h2 id="堆内存"><a href="#堆内存" class="headerlink" title="堆内存"></a>堆内存</h2><h3 id="内存划分"><a href="#内存划分" class="headerlink" title="内存划分"></a>内存划分</h3><p>对于大多数应用，Java 堆是 Java<br>虚拟机管理的内存中最大的一块，被所有线程共享。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数据都在这里分配内存。</p>
<p>为了进行高效的垃圾回收，虚拟机把堆内存 <strong>逻辑上</strong> 划分成三块区域（分代的唯一理由就是优化 GC 性能）：</p>
<ul>
<li>新生带（年轻代）：新对象和没达到一定年龄的对象都在新生代</li>
<li>老年代（养老区）：被长时间使用的对象，老年代的内存空间应该要比年轻代更大</li>
<li>元空间（JDK1.8 之前叫永久代）：像一些方法中的操作临时对象等，JDK1.8 之前是占用 JVM 内存，JDK1.8 之后直接使用物理内存</li>
</ul>
<p><img src="/images/JVM%E5%A0%86%E5%86%85%E5%AD%98%E5%88%92%E5%88%86.jpg" alt="JVM堆内存划分"></p>
<p>Java 虚拟机规范规定，Java<br>堆可以是处于物理上不连续的内存空间中，只要逻辑上是连续的即可，像磁盘空间一样。实现时，既可以是固定大小，也可以是可扩展的，主流虚拟机都是可扩展的（通过<br><code>-Xmx</code> 和 <code>-Xms</code> 控制），如果堆中没有完成实例分配，并且堆无法再扩展时，就会抛出 <code>OutOfMemoryError</code> 异常。</p>
<h4 id="年轻代-Young-Generation"><a href="#年轻代-Young-Generation" class="headerlink" title="年轻代 (Young Generation)"></a>年轻代 (Young Generation)</h4><p>年轻代是所有新对象创建的地方。当填充年轻代时，执行垃圾收集。这种垃圾收集称为 <strong>Minor GC</strong> 。年轻一代被分为三个部分——伊甸园（ <strong>Eden<br>Memory</strong> ）和两个幸存区（ <strong>Survivor Memory</strong> ，被称为from&#x2F;to或s0&#x2F;s1），默认比例是<code>8:1:1</code></p>
<ul>
<li>大多数新创建的对象都位于 Eden 内存空间中</li>
<li>当 Eden 空间被对象填充时，执行 <strong>Minor GC</strong> ，并将所有幸存者对象移动到一个幸存者空间中</li>
<li>Minor GC 检查幸存者对象，并将它们移动到另一个幸存者空间。所以每次，一个幸存者空间总是空的</li>
<li>经过多次 GC 循环后存活下来的对象被移动到老年代。通常，这是通过设置年轻一代对象的年龄阈值来实现的，然后他们才有资格提升到老一代</li>
</ul>
<h4 id="老年代-Old-Generation"><a href="#老年代-Old-Generation" class="headerlink" title="老年代(Old Generation)"></a>老年代(Old Generation)</h4><p>旧的一代内存包含那些经过许多轮小型 GC 后仍然存活的对象。通常，垃圾收集是在老年代内存满时执行的。老年代垃圾收集称为 主GC（Major<br>GC），通常需要更长的时间。</p>
<p>大对象直接进入老年代（大对象是指需要大量连续内存空间的对象）。这样做的目的是避免在 Eden 区和两个Survivor 区之间发生大量的内存拷贝</p>
<p><img src="/images/Java8%E5%89%8D%E5%90%8E%E5%A0%86%E5%86%85%E5%AD%98%E5%AF%B9%E6%AF%94.jpg" alt="Java8前后堆内存对比"></p>
<h4 id="元空间"><a href="#元空间" class="headerlink" title="元空间"></a>元空间</h4><p>不管是 JDK8 之前的永久代，还是 JDK8 及以后的元空间，都可以看作是 Java 虚拟机规范中方法区的实现。</p>
<p>虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫 Non-Heap（非堆），目的应该是与 Java 堆区分开。</p>
<p>所以元空间放在后边的方法区再说。</p>
<h3 id="设置堆内存大小和-OOM"><a href="#设置堆内存大小和-OOM" class="headerlink" title="设置堆内存大小和 OOM"></a>设置堆内存大小和 OOM</h3><p>Java 堆用于存储 Java 对象实例，那么堆的大小在 JVM 启动的时候就确定了，我们可以通过 <code>-Xmx</code> 和 <code>-Xms</code> 来设定</p>
<ul>
<li><code>-Xms</code> 用来表示堆的起始内存，等价于 <code>-XX:InitialHeapSize</code></li>
<li><code>-Xmx</code> 用来表示堆的最大内存，等价于 <code>-XX:MaxHeapSize</code></li>
</ul>
<p>如果堆的内存大小超过 <code>-Xmx</code> 设定的最大内存， 就会抛出 <code>OutOfMemoryError</code> 异常。</p>
<p>我们通常会将 <code>-Xmx</code> 和 <code>-Xms</code> 两个参数配置为相同的值，其目的是为了能够在垃圾回收机制清理完堆区后不再需要重新分隔计算堆的大小，从而提高性能</p>
<ul>
<li>默认情况下，初始堆内存大小为：电脑内存大小&#x2F;64</li>
<li>默认情况下，最大堆内存大小为：电脑内存大小&#x2F;4</li>
</ul>
<p>可以通过代码获取到我们的设置值，当然也可以模拟 OOM：</p>
<pre><code>public static void main(String[] args) &#123;  
  
  //返回 JVM 堆大小  
  long initalMemory = Runtime.getRuntime().totalMemory() / 1024 /1024;  
  //返回 JVM 堆的最大内存  
  long maxMemory = Runtime.getRuntime().maxMemory() / 1024 /1024;  
  
  System.out.println(&quot;-Xms : &quot;+initalMemory + &quot;M&quot;);  
  System.out.println(&quot;-Xmx : &quot;+maxMemory + &quot;M&quot;);  
  
  System.out.println(&quot;系统内存大小：&quot; + initalMemory * 64 / 1024 + &quot;G&quot;);  
  System.out.println(&quot;系统内存大小：&quot; + maxMemory * 4 / 1024 + &quot;G&quot;);  
&#125;  
</code></pre>
<h4 id="查看-JVM-堆内存分配"><a href="#查看-JVM-堆内存分配" class="headerlink" title="查看 JVM 堆内存分配"></a>查看 JVM 堆内存分配</h4><ol>
<li><p>在默认不配置 JVM 堆内存大小的情况下，JVM 根据默认值来配置当前内存大小</p>
</li>
<li><p>默认情况下新生代和老年代的比例是 1:2，可以通过 <code>–XX:NewRatio</code> 来配置</p>
</li>
</ol>
<pre><code>* 新生代中的 **Eden** : **From Survivor** : **To Survivor** 的比例是 **8:1:1** ，可以通过 `-XX:SurvivorRatio` 来配置
</code></pre>
<ol start="3">
<li>若在 JDK 7 中开启了 <code>-XX:+UseAdaptiveSizePolicy</code>，JVM 会动态调整 JVM 堆中各个区域的大小以及进入老年代的年龄</li>
</ol>
<p>此时 <code>–XX:NewRatio</code> 和 <code>-XX:SurvivorRatio</code> 将会失效，而 JDK 8<br>是默认开启<code>-XX:+UseAdaptiveSizePolicy</code></p>
<p>在 JDK 8中， <strong>不要随意关闭</strong><code>-XX:+UseAdaptiveSizePolicy</code>，除非对堆内存的划分有明确的规划</p>
<p>每次 GC 后都会重新计算 Eden、From Survivor、To Survivor 的大小</p>
<p>计算依据是 <strong>GC过程</strong> 中统计的 <strong>GC时间</strong> 、 <strong>吞吐量</strong> 、 <strong>内存占用量</strong></p>
<pre><code>java -XX:+PrintFlagsFinal -version | grep HeapSize  
    uintx ErgoHeapSizeLimit                         = 0                                   &#123;product&#125;  
    uintx HeapSizePerGCThread                       = 87241520                            &#123;product&#125;  
    uintx InitialHeapSize                          := 134217728                           &#123;product&#125;  
    uintx LargePageHeapSizeThreshold                = 134217728                           &#123;product&#125;  
    uintx MaxHeapSize                              := 2147483648                          &#123;product&#125;  
java version &quot;1.8.0_211&quot;  
Java(TM) SE Runtime Environment (build 1.8.0_211-b12)  
Java HotSpot(TM) 64-Bit Server VM (build 25.211-b12, mixed mode)  
$ jmap -heap 进程号  
</code></pre>
<h3 id="对象在堆中的生命周期"><a href="#对象在堆中的生命周期" class="headerlink" title="对象在堆中的生命周期"></a>对象在堆中的生命周期</h3><ol>
<li>在 JVM 内存模型的堆中，堆被划分为新生代和老年代<br>* 新生代又被进一步划分为 <strong>Eden区</strong> 和 <strong>Survivor区</strong> ，Survivor 区由 <strong>From Survivor</strong> 和 <strong>To Survivor</strong> 组成</li>
<li>当创建一个对象时，对象会被优先分配到新生代的 Eden 区<br>* 此时 JVM 会给对象定义一个 <strong>对象年轻计数器</strong> （<code>-XX:MaxTenuringThreshold</code>）</li>
<li>当 Eden 空间不足时，JVM 将执行新生代的垃圾回收（Minor GC）<br>* JVM 会把存活的对象转移到 Survivor 中，并且对象年龄 +1<br>* 对象在 Survivor 中同样也会经历 Minor GC，每经历一次 Minor GC，对象年龄都会+1</li>
<li>如果分配的对象超过了<code>-XX:PetenureSizeThreshold</code>，对象会 <strong>直接被分配到老年代</strong></li>
</ol>
<h3 id="对象的分配过程"><a href="#对象的分配过程" class="headerlink" title="对象的分配过程"></a>对象的分配过程</h3><p>为对象分配内存是一件非常严谨和复杂的任务，JVM<br>的设计者们不仅需要考虑内存如何分配、在哪里分配等问题，并且由于内存分配算法和内存回收算法密切相关，所以还需要考虑 GC<br>执行完内存回收后是否会在内存空间中产生内存碎片。</p>
<ol>
<li>new 的对象先放在伊甸园区，此区有大小限制</li>
<li>当伊甸园的空间填满时，程序又需要创建对象，JVM 的垃圾回收器将对伊甸园区进行垃圾回收（Minor GC），将伊甸园区中的不再被其他对象所引用的对象进行销毁。再加载新的对象放到伊甸园区</li>
<li>然后将伊甸园中的剩余对象移动到幸存者 0 区</li>
<li>如果再次触发垃圾回收，此时上次幸存下来的放到幸存者 0 区，如果没有回收，就会放到幸存者 1 区</li>
<li>如果再次经历垃圾回收，此时会重新放回幸存者 0 区，接着再去幸存者 1 区</li>
<li>什么时候才会去养老区呢？ 默认是 15 次回收标记</li>
<li>在养老区，相对悠闲。当养老区内存不足时，再次触发 Major GC，进行养老区的内存清理</li>
<li>若养老区执行了 Major GC 之后发现依然无法进行对象的保存，就会产生 OOM 异常</li>
</ol>
<h3 id="GC-垃圾回收简介"><a href="#GC-垃圾回收简介" class="headerlink" title="GC 垃圾回收简介"></a>GC 垃圾回收简介</h3><h4 id="Minor-GC、Major-GC、Full-GC"><a href="#Minor-GC、Major-GC、Full-GC" class="headerlink" title="Minor GC、Major GC、Full GC"></a>Minor GC、Major GC、Full GC</h4><p>JVM 在进行 GC 时，并非每次都对堆内存（新生代、老年代；方法区）区域一起回收的，大部分时候回收的都是指新生代。</p>
<p>针对 HotSpot VM 的实现，它里面的 GC 按照回收区域又分为两大类：部分收集（Partial GC），整堆收集（Full GC）</p>
<ul>
<li>部分收集：不是完整收集整个 Java 堆的垃圾收集。其中又分为： <ul>
<li>新生代收集（Minor GC&#x2F;Young GC）：只是新生代的垃圾收集</li>
<li>老年代收集（Major GC&#x2F;Old GC）：只是老年代的垃圾收集 <ul>
<li>目前，只有 CMS GC 会有单独收集老年代的行为</li>
<li>很多时候 Major GC 会和 Full GC 混合使用，需要具体分辨是老年代回收还是整堆回收</li>
</ul>
</li>
<li>混合收集（Mixed GC）：收集整个新生代以及部分老年代的垃圾收集 <ul>
<li>目前只有 G1 GC 会有这种行为</li>
</ul>
</li>
</ul>
</li>
<li>整堆收集（Full GC）：收集整个 Java 堆和方法区的垃圾</li>
</ul>
<h3 id="TLAB"><a href="#TLAB" class="headerlink" title="TLAB"></a>TLAB</h3><h4 id="什么是-TLAB-（Thread-Local-Allocation-Buffer）"><a href="#什么是-TLAB-（Thread-Local-Allocation-Buffer）" class="headerlink" title="什么是 TLAB （Thread Local Allocation Buffer）?"></a>什么是 TLAB （Thread Local Allocation Buffer）?</h4><ul>
<li>从内存模型而不是垃圾回收的角度，对 Eden 区域继续进行划分，JVM 为每个线程分配了一个私有缓存区域，它包含在 Eden 空间内</li>
<li>多线程同时分配内存时，使用 TLAB 可以避免一系列的非线程安全问题，同时还能提升内存分配的吞吐量，因此我们可以将这种内存分配方式称为 <strong>快速分配策略</strong></li>
<li>OpenJDK 衍生出来的 JVM 大都提供了 TLAB 设计</li>
</ul>
<h4 id="为什么要有-TLAB"><a href="#为什么要有-TLAB" class="headerlink" title="为什么要有 TLAB ?"></a>为什么要有 TLAB ?</h4><ul>
<li>堆区是线程共享的，任何线程都可以访问到堆区中的共享数据</li>
<li>由于对象实例的创建在 JVM 中非常频繁，因此在并发环境下从堆区中划分内存空间是线程不安全的</li>
<li>为避免多个线程操作同一地址，需要使用加锁等机制，进而影响分配速度</li>
</ul>
<p>尽管不是所有的对象实例都能够在 TLAB 中成功分配内存，但 JVM 确实是将 TLAB 作为内存分配的首选。</p>
<p>在程序中，可以通过 <code>-XX:UseTLAB</code> 设置是否开启 TLAB 空间。</p>
<p>默认情况下，TLAB 空间的内存非常小，仅占有整个 Eden 空间的 1%，我们可以通过 <code>-XX:TLABWasteTargetPercent</code> 设置<br>TLAB 空间所占用 Eden 空间的百分比大小。</p>
<p>一旦对象在 TLAB 空间分配内存失败时，JVM 就会尝试着通过使用加锁机制确保数据操作的原子性，从而直接在 Eden 空间中分配内存。</p>
<h3 id="堆是分配对象存储的唯一选择吗"><a href="#堆是分配对象存储的唯一选择吗" class="headerlink" title="堆是分配对象存储的唯一选择吗"></a>堆是分配对象存储的唯一选择吗</h3><blockquote>
<p>随着 JIT 编译期的发展和逃逸分析技术的逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化，所有的对象都分配到堆上也渐渐变得不那么“绝对”了。<br>——《深入理解 Java 虚拟机》</p>
</blockquote>
<h4 id="逃逸分析"><a href="#逃逸分析" class="headerlink" title="逃逸分析"></a>逃逸分析</h4><p> <em><em>逃逸分析(Escape Analysis)*</em> 是目前 Java 虚拟机中比较前沿的优化技术</em>*。这是一种可以有效减少 Java<br>程序中同步负载和内存堆分配压力的跨函数全局数据流分析算法**。通过逃逸分析，Java Hotspot<br>编译器能够分析出一个新的对象的引用的使用范围从而决定是否要将这个对象分配到堆上。</p>
<p>逃逸分析的基本行为就是分析对象动态作用域：</p>
<ul>
<li>当一个对象在方法中被定义后，对象只在方法内部使用，则认为没有发生逃逸。</li>
<li>当一个对象在方法中被定义后，它被外部方法所引用，则认为发生逃逸。例如作为调用参数传递到其他地方中，称为方法逃逸。</li>
</ul>
<p>例如：</p>
<pre><code>public static StringBuffer craeteStringBuffer(String s1, String s2) &#123;  
   StringBuffer sb = new StringBuffer();  
   sb.append(s1);  
   sb.append(s2);  
   return sb;  
&#125;  
</code></pre>
<p><code>StringBuffer sb</code>是一个方法内部变量，上述代码中直接将sb返回，这样这个 StringBuffer<br>有可能被其他方法所改变，这样它的作用域就不只是在方法内部，虽然它是一个局部变量，但是其逃逸到了方法外部。甚至还有可能被外部线程访问到，譬如赋值给类变量或可以在其他线程中访问的实例变量，称为线程逃逸。</p>
<p>上述代码如果想要 <code>StringBuffer sb</code>不逃出方法，可以这样写：</p>
<pre><code>public static String createStringBuffer(String s1, String s2) &#123;  
   StringBuffer sb = new StringBuffer();  
   sb.append(s1);  
   sb.append(s2);  
   return sb.toString();  
&#125;  
</code></pre>
<p>不直接返回 StringBuffer，那么 StringBuffer 将不会逃逸出方法。</p>
<p><strong>参数设置：</strong></p>
<ul>
<li>在 JDK 6u23 版本之后，HotSpot 中默认就已经开启了逃逸分析</li>
<li>如果使用较早版本，可以通过<code>-XX&quot;+DoEscapeAnalysis</code>显式开启</li>
</ul>
<p>开发中使用局部变量，就不要在方法外定义。</p>
<p>使用逃逸分析，编译器可以对代码做优化：</p>
<ul>
<li><strong>栈上分配</strong> ：将堆分配转化为栈分配。如果一个对象在子程序中被分配，要使指向该对象的指针永远不会逃逸，对象可能是栈分配的候选，而不是堆分配</li>
<li><strong>同步省略</strong> ：如果一个对象被发现只能从一个线程被访问到，那么对于这个对象的操作可以不考虑同步</li>
<li><strong>分离对象或标量替换</strong> ：有的对象可能不需要作为一个连续的内存结构存在也可以被访问到，那么对象的部分（或全部）可以不存储在内存，而存储在 CPU 寄存器</li>
</ul>
<p>JIT<br>编译器在编译期间根据逃逸分析的结果，发现如果一个对象并没有逃逸出方法的话，就可能被优化成栈上分配。分配完成后，继续在调用栈内执行，最后线程结束，栈空间被回收，局部变量对象也被回收。这样就无需进行垃圾回收了。</p>
<p>常见栈上分配的场景：成员变量赋值、方法返回值、实例引用传递</p>
<h5 id="代码优化之同步省略（消除）"><a href="#代码优化之同步省略（消除）" class="headerlink" title="代码优化之同步省略（消除）"></a>代码优化之同步省略（消除）</h5><ul>
<li><p>线程同步的代价是相当高的，同步的后果是降低并发性和性能</p>
</li>
<li><p>在动态编译同步块的时候，JIT 编译器可以借助逃逸分析来判断同步块所使用的锁对象是否能够被一个线程访问而没有被发布到其他线程。如果没有，那么 JIT 编译器在编译这个同步块的时候就会取消对这个代码的同步。这样就能大大提高并发性和性能。这个取消同步的过程就叫做 <strong>同步省略，也叫锁消除</strong> 。</p>
<p>public void keep() {<br>  Object keeper &#x3D; new Object();<br>  synchronized(keeper) {<br>System.out.println(keeper);<br>  }<br>}</p>
</li>
</ul>
<p>如上代码，代码中对 keeper 这个对象进行加锁，但是 keeper 对象的生命周期只在 <code>keep()</code>方法中，并不会被其他线程所访问到，所以在<br>JIT编译阶段就会被优化掉。优化成：</p>
<pre><code>public void keep() &#123;  
  Object keeper = new Object();  
  System.out.println(keeper);  
&#125;  
  
</code></pre>
<h5 id="代码优化之标量替换"><a href="#代码优化之标量替换" class="headerlink" title="代码优化之标量替换"></a>代码优化之标量替换</h5><p> <strong>标量</strong> （Scalar）是指一个无法再分解成更小的数据的数据。Java 中的原始数据类型就是标量。</p>
<p>相对的，那些的还可以分解的数据叫做 <strong>聚合量</strong> （Aggregate），Java 中的对象就是聚合量，因为其还可以分解成其他聚合量和标量。</p>
<p>在 JIT 阶段，通过逃逸分析确定该对象不会被外部访问，并且对象可以被进一步分解时，JVM<br>不会创建该对象，而会将该对象成员变量分解若干个被这个方法使用的成员变量所代替。这些代替的成员变量在栈帧或寄存器上分配空间。这个过程就是 <strong>标量替换</strong> 。</p>
<p>通过 <code>-XX:+EliminateAllocations</code> 可以开启标量替换，<code>-XX:+PrintEliminateAllocations</code><br>查看标量替换情况。</p>
<pre><code>public static void main(String[] args) &#123;  
   alloc();  
&#125;  
  
private static void alloc() &#123;  
   Point point = new Point（1,2）;  
   System.out.println(&quot;point.x=&quot;+point.x+&quot;; point.y=&quot;+point.y);  
&#125;  
class Point&#123;  
    private int x;  
    private int y;  
&#125;  
</code></pre>
<p>以上代码中，point 对象并没有逃逸出 <code>alloc()</code> 方法，并且 point 对象是可以拆解成标量的。那么，JIT 就不会直接创建 Point<br>对象，而是直接使用两个标量 int x ，int y 来替代 Point 对象。</p>
<pre><code>private static void alloc() &#123;  
   int x = 1;  
   int y = 2;  
   System.out.println(&quot;point.x=&quot;+x+&quot;; point.y=&quot;+y);  
&#125;  
  
</code></pre>
<h5 id="代码优化之栈上分配"><a href="#代码优化之栈上分配" class="headerlink" title="代码优化之栈上分配"></a>代码优化之栈上分配</h5><p>我们通过 JVM 内存分配可以知道 JAVA 中的对象都是在堆上进行分配，当对象没有被引用的时候，需要依靠 GC 进行回收内存，如果对象数量较多的时候，会给<br>GC 带来较大压力，也间接影响了应用的性能。为了减少临时对象在堆内分配的数量，JVM<br>通过逃逸分析确定该对象不会被外部访问。那就通过标量替换将该对象分解在栈上分配内存，这样该对象所占用的内存空间就可以随栈帧出栈而销毁，就减轻了垃圾回收的压力。</p>
<p><strong>总结：</strong></p>
<p>关于逃逸分析的论文在1999年就已经发表了，但直到JDK 1.6才有实现，而且这项技术到如今也并不是十分成熟的。</p>
<p><strong>其根本原因就是无法保证逃逸分析的性能消耗一定能高于他的消耗。虽然经过逃逸分析可以做标量替换、栈上分配、和锁消除。但是逃逸分析自身也是需要进行一系列复杂的分析的，这其实也是一个相对耗时的过程。</strong></p>
<p>一个极端的例子，就是经过逃逸分析之后，发现没有一个对象是不逃逸的。那这个逃逸分析的过程就白白浪费掉了。</p>
<p>虽然这项技术并不十分成熟，但是他也是即时编译器优化技术中一个十分重要的手段。</p>
<h2 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h2><ul>
<li>方法区（Method Area）与 Java 堆一样，是所有线程共享的内存区域。</li>
<li>虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫 Non-Heap（非堆），目的应该是与 Java 堆区分开。</li>
<li>运行时常量池（Runtime Constant Pool）是方法区的一部分。Class 文件中除了有类的版本&#x2F;字段&#x2F;方法&#x2F;接口等描述信息外，还有一项信息是常量池（Constant Pool Table），用于存放编译期生成的各种字面量和符号引用，这部分内容将类在加载后进入方法区的运行时常量池中存放。运行期间也可能将新的常量放入池中，这种特性被开发人员利用得比较多的是 <code>String.intern()</code>方法。受方法区内存的限制，当常量池无法再申请到内存时会抛出 <code>OutOfMemoryErro</code>r 异常。</li>
<li>方法区的大小和堆空间一样，可以选择固定大小也可选择可扩展，方法区的大小决定了系统可以放多少个类，如果系统类太多，导致方法区溢出，虚拟机同样会抛出内存溢出错误</li>
<li>JVM 关闭后方法区即被释放</li>
</ul>
<h3 id="解惑"><a href="#解惑" class="headerlink" title="解惑"></a>解惑</h3><p>你是否也有看不同的参考资料，有的内存结构图有方法区，有的又是永久代，元数据区，一脸懵逼的时候？</p>
<ul>
<li><strong>方法区（method area）只是 JVM 规范中定义的一个概念</strong> ，用于存储类信息、常量池、静态变量、JIT编译后的代码等数据，并没有规定如何去实现它，不同的厂商有不同的实现。而 <strong>永久代（PermGen）是 Hotspot 虚拟机特有的概念， Java8 的时候又被元空间</strong> 取代了，永久代和元空间都可以理解为方法区的落地实现。</li>
<li>永久代物理是堆的一部分，和新生代，老年代地址是连续的（受垃圾回收器管理），而元空间存在于本地内存（我们常说的堆外内存，不受垃圾回收器管理），这样就不受 JVM 限制了，也比较难发生OOM（都会有溢出异常）</li>
<li>Java7 中我们通过<code>-XX:PermSize</code> 和 <code>-xx:MaxPermSize</code> 来设置永久代参数，Java8 之后，随着永久代的取消，这些参数也就随之失效了，改为通过<code>-XX:MetaspaceSize</code> 和 <code>-XX:MaxMetaspaceSize</code> 用来设置元空间参数</li>
<li>存储内容不同，元空间存储类的元信息，静态变量和常量池等并入堆中。相当于永久代的数据被分到了堆和元空间中</li>
<li>如果方法区域中的内存不能用于满足分配请求，则 Java 虚拟机抛出 <code>OutOfMemoryError</code></li>
<li>JVM 规范说方法区在逻辑上是堆的一部分，但目前实际上是与 Java 堆分开的（Non-Heap）</li>
</ul>
<p>所以对于方法区，Java8 之后的变化：</p>
<ul>
<li>移除了永久代（PermGen），替换为元空间（Metaspace）；</li>
<li>永久代中的 class metadata 转移到了 native memory（本地内存，而不是虚拟机）；</li>
<li>永久代中的 interned Strings 和 class static variables 转移到了 Java heap；</li>
<li>永久代参数 （PermSize MaxPermSize） -&gt; 元空间参数（MetaspaceSize MaxMetaspaceSize）</li>
</ul>
<h3 id="设置方法区内存的大小"><a href="#设置方法区内存的大小" class="headerlink" title="设置方法区内存的大小"></a>设置方法区内存的大小</h3><p>JDK8 及以后：</p>
<ul>
<li>元数据区大小可以使用参数 <code>-XX:MetaspaceSize</code> 和 <code>-XX:MaxMetaspaceSize</code> 指定，替代上述原有的两个参数</li>
<li>默认值依赖于平台。Windows 下，<code>-XX:MetaspaceSize</code> 是 21M，<code>-XX:MaxMetaspacaSize</code> 的值是 -1，即没有限制</li>
<li>与永久代不同，如果不指定大小，默认情况下，虚拟机会耗尽所有的可用系统内存。如果元数据发生溢出，虚拟机一样会抛出异常 <code>OutOfMemoryError:Metaspace</code></li>
<li><code>-XX:MetaspaceSize</code> ：设置初始的元空间大小。对于一个 64 位的服务器端 JVM 来说，其默认的 <code>-XX:MetaspaceSize</code> 的值为20.75MB，这就是初始的高水位线，一旦触及这个水位线，Full GC 将会被触发并卸载没用的类（即这些类对应的类加载器不再存活），然后这个高水位线将会重置，新的高水位线的值取决于 GC 后释放了多少元空间。如果释放的空间不足，那么在不超过 <code>MaxMetaspaceSize</code>时，适当提高该值。如果释放空间过多，则适当降低该值</li>
<li>如果初始化的高水位线设置过低，上述高水位线调整情况会发生很多次，通过垃圾回收的日志可观察到 Full GC 多次调用。为了避免频繁 GC，建议将 <code>-XX:MetaspaceSize</code> 设置为一个相对较高的值。</li>
</ul>
<h3 id="方法区内部结构"><a href="#方法区内部结构" class="headerlink" title="方法区内部结构"></a>方法区内部结构</h3><p>方法区用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等。</p>
<h4 id="类型信息"><a href="#类型信息" class="headerlink" title="类型信息"></a>类型信息</h4><p>对每个加载的类型（类 class、接口 interface、枚举 enum、注解 annotation），JVM 必须在方法区中存储以下类型信息</p>
<ul>
<li>这个类型的完整有效名称（全名&#x3D;包名.类名）</li>
<li>这个类型直接父类的完整有效名（对于 interface或是 java.lang.Object，都没有父类）</li>
<li>这个类型的修饰符（public，abstract，final 的某个子集）</li>
<li>这个类型直接接口的一个有序列表</li>
</ul>
<h4 id="域（Field）信息"><a href="#域（Field）信息" class="headerlink" title="域（Field）信息"></a>域（Field）信息</h4><ul>
<li>JVM 必须在方法区中保存类型的所有域的相关信息以及域的声明顺序</li>
<li>域的相关信息包括：域名称、域类型、域修饰符（public、private、protected、static、final、volatile、transient 的某个子集）</li>
</ul>
<h4 id="方法（Method）信息"><a href="#方法（Method）信息" class="headerlink" title="方法（Method）信息"></a>方法（Method）信息</h4><p>JVM 必须保存所有方法的</p>
<ul>
<li>方法名称</li>
<li>方法的返回类型</li>
<li>方法参数的数量和类型</li>
<li>方法的修饰符（public，private，protected，static，final，synchronized，native，abstract 的一个子集）</li>
<li>方法的字符码（bytecodes）、操作数栈、局部变量表及大小（abstract 和 native 方法除外）</li>
<li>异常表（abstract 和 native 方法除外） <ul>
<li>每个异常处理的开始位置、结束位置、代码处理在程序计数器中的偏移地址、被捕获的异常类的常量池索引</li>
</ul>
</li>
</ul>
<h3 id="运行时常量池"><a href="#运行时常量池" class="headerlink" title="运行时常量池"></a>运行时常量池</h3><p>运行时常量池（Runtime Constant Pool）是方法区的一部分，理解运行时常量池的话，我们先来说说字节码文件（Class<br>文件）中的常量池（常量池表）</p>
<h4 id="常量池"><a href="#常量池" class="headerlink" title="常量池"></a>常量池</h4><p>一个有效的字节码文件中除了包含类的版本信息、字段、方法以及接口等描述信息外，还包含一项信息那就是常量池表（Constant Pool<br>Table），包含各种字面量和对类型、域和方法的符号引用。</p>
<h5 id="为什么需要常量池？"><a href="#为什么需要常量池？" class="headerlink" title="为什么需要常量池？"></a>为什么需要常量池？</h5><p>一个 Java 源文件中的类、接口，编译后产生一个字节码文件。而 Java<br>中的字节码需要数据支持，通常这种数据会很大以至于不能直接存到字节码里，换另一种方式，可以存到常量池，这个字节码包含了指向常量池的引用。在动态链接的时候用到的就是运行时常量池。</p>
<p>如下，我们通过 jclasslib 查看一个只有 Main 方法的简单类，字节码中的 #2 指向的就是 Constant Pool</p>
<p>![ Constant Pool](&#x2F;images&#x2F; Constant Pool.jpg)</p>
<p>常量池可以看作是一张表，虚拟机指令根据这张常量表找到要执行的类名、方法名、参数类型、字面量等类型。</p>
<h4 id="运行时常量池-1"><a href="#运行时常量池-1" class="headerlink" title="运行时常量池"></a>运行时常量池</h4><ul>
<li>在加载类和结构到虚拟机后，就会创建对应的运行时常量池</li>
<li>常量池表（Constant Pool Table）是 Class 文件的一部分，用于存储编译期生成的各种字面量和符号引用， <strong>这部分内容将在类加载后存放到方法区的运行时常量池中</strong></li>
<li>JVM 为每个已加载的类型（类或接口）都维护一个常量池。池中的数据项像数组项一样，是通过索引访问的</li>
<li>运行时常量池中包含各种不同的常量，包括编译器就已经明确的数值字面量，也包括到运行期解析后才能够获得的方法或字段引用。此时不再是常量池中的符号地址了，这里换为真实地址 <ul>
<li>运行时常量池，相对于 Class 文件常量池的另一个重要特征是： <strong>动态性</strong> ，Java 语言并不要求常量一定只有编译期间才能产生，运行期间也可以将新的常量放入池中，String 类的 <code>intern()</code> 方法就是这样的</li>
</ul>
</li>
<li>当创建类或接口的运行时常量池时，如果构造运行时常量池所需的内存空间超过了方法区所能提供的最大值，则 JVM 会抛出 OutOfMemoryError 异常。</li>
</ul>
<h3 id="方法区在-JDK6、7、8中的演进细节"><a href="#方法区在-JDK6、7、8中的演进细节" class="headerlink" title="方法区在 JDK6、7、8中的演进细节"></a>方法区在 JDK6、7、8中的演进细节</h3><p>只有 HotSpot 才有永久代的概念</p>
<table>
<thead>
<tr>
<th>jdk1.6及之前</th>
<th>有永久代，静态变量存放在永久代上</th>
</tr>
</thead>
<tbody><tr>
<td>jdk1.7</td>
<td>有永久代，但已经逐步“去永久代”，字符串常量池、静态变量移除，保存在堆中</td>
</tr>
<tr>
<td>jdk1.8及之后</td>
<td>取消永久代，类型信息、字段、方法、常量保存在本地内存的元空间，但字符串常量池、静态变量仍在堆中</td>
</tr>
</tbody></table>
<ul>
<li>HotSpot中字符串常量池保存哪里？永久代？方法区还是堆区**？</li>
</ul>
<ol>
<li>运行时常量池（Runtime Constant Pool）是虚拟机规范中是方法区的一部分，在加载类和结构到虚拟机后，就会创建对应的运行时常量池；而字符串常量池是这个过程中常量字符串的存放位置。所以从这个角度，字符串常量池属于虚拟机规范中的方法区，它是一个 <strong>逻辑上的概念</strong> ；而堆区，永久代以及元空间是实际的存放位置。</li>
<li>不同的虚拟机对虚拟机的规范（比如方法区）是不一样的，只有 HotSpot 才有永久代的概念。</li>
<li>HotSpot也是发展的，由于<a target="_blank" rel="noopener" href="http://openjdk.java.net/jeps/122">一些问题</a>的存在，HotSpot考虑逐渐去永久代，对于不同版本的JDK， <strong>实际的存储位置</strong> 是有差异的，具体看如下表格：</li>
</ol>
<table>
<thead>
<tr>
<th>JDK版本</th>
<th>是否有永久代，字符串常量池放在哪里？</th>
<th>方法区逻辑上规范，由哪些实际的部分实现的？</th>
</tr>
</thead>
<tbody><tr>
<td>jdk1.6及之前</td>
<td>有永久代，运行时常量池（包括字符串常量池），静态变量存放在永久代上</td>
<td>这个时期方法区在HotSpot中是由永久代来实现的，以至于</td>
</tr>
<tr>
<td><strong>这个时期说方法区就是指永久代</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>jdk1.7</td>
<td>有永久代，但已经逐步“去永久代”，字符串常量池、静态变量移除，保存在堆中；</td>
<td>这个时期方法区在HotSpot中由 <strong>永久代</strong></td>
</tr>
<tr>
<td>（类型信息、字段、方法、常量）和 <strong>堆</strong> （字符串常量池、静态变量）共同实现</td>
<td></td>
<td></td>
</tr>
<tr>
<td>jdk1.8及之后</td>
<td>取消永久代，类型信息、字段、方法、常量保存在本地内存的元空间，但字符串常量池、静态变量仍在堆中</td>
<td></td>
</tr>
<tr>
<td>这个时期方法区在HotSpot中由本地内存的 <strong>元空间</strong> （类型信息、字段、方法、常量）和 <strong>堆</strong> （字符串常量池、静态变量）共同实现</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h4 id="移除永久代原因"><a href="#移除永久代原因" class="headerlink" title="移除永久代原因"></a>移除永久代原因</h4><p><a target="_blank" rel="noopener" href="http://openjdk.java.net/jeps/122">http://openjdk.java.net/jeps/122</a></p>
<ul>
<li>为永久代设置空间大小是很难确定的。</li>
</ul>
<p>在某些场景下，如果动态加载类过多，容易产生 Perm 区的 OOM。如果某个实际 Web<br>工程中，因为功能点比较多，在运行过程中，要不断动态加载很多类，经常出现<br>OOM。而元空间和永久代最大的区别在于，元空间不在虚拟机中，而是使用本地内存，所以默认情况下，元空间的大小仅受本地内存限制</p>
<ul>
<li>对永久代进行调优较困难</li>
</ul>
<h3 id="方法区的垃圾回收"><a href="#方法区的垃圾回收" class="headerlink" title="方法区的垃圾回收"></a>方法区的垃圾回收</h3><p>方法区的垃圾收集主要回收两部分内容： <strong>常量池中废弃的常量和不再使用的类型</strong> 。</p>
<p>先来说说方法区内常量池之中主要存放的两大类常量：字面量和符号引用。字面量比较接近 Java 语言层次的常量概念，如文本字符串、被声明为 final<br>的常量值等。而符号引用则属于编译原理方面的概念，包括下面三类常量：</p>
<ul>
<li>类和接口的全限定名</li>
<li>字段的名称和描述符</li>
<li>方法的名称和描述符</li>
</ul>
<p>HotSpot 虚拟机对常量池的回收策略是很明确的，只要常量池中的常量没有被任何地方引用，就可以被回收</p>
<p>判定一个类型是否属于“不再被使用的类”，需要同时满足三个条件：</p>
<ul>
<li>该类所有的实例都已经被回收，也就是 Java 堆中不存在该类及其任何派生子类的实例</li>
<li>加载该类的类加载器已经被回收，这个条件除非是经过精心设计的可替换类加载器的场景，如 OSGi、JSP 的重加载等，否则通常很难达成</li>
<li>该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法</li>
</ul>
<p>Java<br>虚拟机被允许堆满足上述三个条件的无用类进行回收，这里说的仅仅是“被允许”，而并不是和对象一样，不使用了就必然会回收。是否对类进行回收，HotSpot<br>虚拟机提供了 <code>-Xnoclassgc</code> 参数进行控制，还可以使用 <code>-verbose:class</code> 以及 <code>-XX:+TraceClassLoading</code><br>、<code>-XX:+TraceClassUnLoading</code> 查看类加载和卸载信息。</p>
<p>在大量使用反射、动态代理、CGLib 等 ByteCode 框架、动态生成 JSP 以及 OSGi 这类频繁自定义 ClassLoader<br>的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/UDP%E5%92%8CTCP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="merric">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Myoboku">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Myoboku">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/UDP%E5%92%8CTCP/" class="post-title-link" itemprop="url">TCP和UDP</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-01-15 22:30:00" itemprop="dateCreated datePublished" datetime="2020-01-15T22:30:00+00:00">2020-01-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">计算机网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>先上两张图。</p>
<p><img src="/images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%88%86%E5%B1%82.jpg" alt="计算机网络体系结构分层"></p>
<p><img src="/images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84.jpg" alt="计算机网络体系结构"></p>
<h1 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h1><p>TCP 与 UDP 的区别相当大。它充分地实现了数据传输时各种控制功能，可以进行丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。而这些在 UDP<br>中都没有。</p>
<p>此外，TCP 作为一种面向有连接的协议，只有在确认通信对端存在时才会发送数据，从而可以控制通信流量的浪费。</p>
<p>根据 TCP 的这些机制，在 IP 这种无连接的网络上也能够实现高可靠性的通信（<br>主要通过检验和、序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现）。</p>
<h2 id="通过序列号与确认应答提高可靠性"><a href="#通过序列号与确认应答提高可靠性" class="headerlink" title="通过序列号与确认应答提高可靠性"></a>通过序列号与确认应答提高可靠性</h2><ul>
<li>在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个已收到消息的通知。这个消息叫做确认应答（ACK）。当发送端将数据发出之后会等待对端的确认应答。如果有确认应答，说明数据已经成功到达对端。 <strong>反之，则数据丢失的可能性很大</strong> 。</li>
<li>在一定时间内没有等待到确认应答，发送端就可以认为数据已经丢失，并进行重发。由此，即使产生了丢包，仍然能够保证数据能够到达对端，实现可靠传输。</li>
<li>未收到确认应答并不意味着数据一定丢失。也有可能是数据对方已经收到，只是返回的确认应答在途中丢失。这种情况也会导致发送端误以为数据没有到达目的地而重发数据。</li>
<li>此外，也有可能因为一些其他原因导致确认应答延迟到达，在源主机重发数据以后才到达的情况也屡见不鲜。此时，源主机只要按照机制重发数据即可。</li>
<li>对于目标主机来说，反复收到相同的数据是不可取的。为了对上层应用提供可靠的传输，目标主机必须放弃重复的数据包。为此我们引入了序列号。</li>
<li><strong>序列号是按照顺序给发送数据的每一个字节（8位字节）都标上号码的编号。接收端查询接收数据 TCP 首部中的序列号和数据的长度，将自己下一步应该接收的序列号作为确认应答返送回去。通过序列号和确认应答号，TCP 能够识别是否已经接收数据，又能够判断是否需要接收，从而实现可靠传输。</strong></li>
</ul>
<p><img src="/images/%E5%BA%8F%E5%88%97%E5%8F%B7%E5%92%8C%E7%A1%AE%E8%AE%A4%E5%BA%94%E7%AD%94.jpg" alt="序列号和确认应答"></p>
<h2 id="重发超时的确定"><a href="#重发超时的确定" class="headerlink" title="重发超时的确定"></a>重发超时的确定</h2><ul>
<li><strong>重发超时是指在重发数据之前，等待确认应答到来的那个特定时间间隔。</strong> 如果超过这个时间仍未收到确认应答，发送端将进行数据重发。最理想的是，找到一个最小时间，它能保证“确认应答一定能在这个时间内返回”。</li>
<li>TCP 要求不论处在何种网络环境下都要提供高性能通信，并且无论网络拥堵情况发生何种变化，都必须保持这一特性。为此，它在每次发包时都会计算往返时间及其偏差。将这个往返时间和偏差时间相加，重发超时的时间就是比这个总和要稍大一点的值。</li>
<li>在 BSD 的 Unix 以及 Windows 系统中，超时都以0.5秒为单位进行控制，因此重发超时都是0.5秒的整数倍。不过，最初其重发超时的默认值一般设置为6秒左右。</li>
<li>数据被重发之后若还是收不到确认应答，则进行再次发送。此时，等待确认应答的时间将会以2倍、4倍的指数函数延长。</li>
<li>此外， <strong>数据也不会被无限、反复地重发。达到一定重发次数之后，如果仍没有任何确认应答返回，就会判断为网络或对端主机发生了异常，强制关闭连接。并且通知应用通信异常强行终止。</strong></li>
</ul>
<h2 id="以段为单位发送数据"><a href="#以段为单位发送数据" class="headerlink" title="以段为单位发送数据"></a>以段为单位发送数据</h2><ul>
<li>在建立 TCP 连接的同时，也可以确定发送数据包的单位，我们也可以称其为“最大消息长度”（MSS）。最理想的情况是，最大消息长度正好是 IP 中不会被分片处理的最大数据长度。</li>
<li>TCP 在传送大量数据时，是以 MSS 的大小将数据进行分割发送。进行重发时也是以 MSS 为单位。</li>
<li>MSS 在三次握手的时候，在两端主机之间被计算得出。两端的主机在发出建立连接的请求时，会在 TCP 首部中写入 MSS 选项，告诉对方自己的接口能够适应的 MSS 的大小。然后会在两者之间选择一个较小的值投入使用。</li>
</ul>
<h2 id="利用窗口控制提高速度"><a href="#利用窗口控制提高速度" class="headerlink" title="利用窗口控制提高速度"></a>利用窗口控制提高速度</h2><p>TCP 以1个段为单位，每发送一个段进行一次确认应答的处理。这样的传输方式有一个缺点，就是包的往返时间越长通信性能就越低。</p>
<p>为解决这个问题，TCP<br>引入了窗口这个概念。确认应答不再是以每个分段，而是以更大的单位进行确认，转发时间将会被大幅地缩短。也就是说，发送端主机，在发送了一个段以后不必要一直等待确认应答，而是继续发送。如下图所示：</p>
<p><img src="/images/%E7%AA%97%E5%8F%A3%E6%8E%A7%E5%88%B6.jpg" alt="窗口控制"></p>
<p>窗口大小就是指无需等待确认应答而可以继续发送数据的最大值。上图中窗口大小为4个段。这个机制实现了使用大量的缓冲区，通过对多个段同时进行确认应答的功能。</p>
<h2 id="滑动窗口控制"><a href="#滑动窗口控制" class="headerlink" title="滑动窗口控制"></a>滑动窗口控制</h2><p><img src="/images/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3.jpg" alt="滑动窗口"></p>
<p>上图中的窗口内的数据即便没有收到确认应答也可以被发送出去。不过，在整个窗口的确认应答没有到达之前，如果其中部分数据出现丢包，那么发送端仍然要负责重传。为此，发送端主机需要设置缓存保留这些待被重传的数据，直到收到他们的确认应答。</p>
<p>在滑动窗口以外的部分包括未发送的数据以及已经确认对端已收到的数据。当数据发出后若如期收到确认应答就可以不用再进行重发，此时数据就可以从缓存区清除。</p>
<p>收到确认应答的情况下，将窗口滑动到确认应答中的序列号的位置。这样可以顺序地将多个段同时发送提高通信性能。这种机制也别称为滑动窗口控制。</p>
<h2 id="窗口控制中的重发控制"><a href="#窗口控制中的重发控制" class="headerlink" title="窗口控制中的重发控制"></a>窗口控制中的重发控制</h2><p>在使用窗口控制中， 出现丢包一般分为两种情况：</p>
<ul>
<li>① 确认应答未能返回的情况。在这种情况下，数据已经到达对端，是不需要再进行重发的，如下图：</li>
</ul>
<p><img src="/images/%E9%83%A8%E5%88%86%E7%A1%AE%E8%AE%A4%E5%BA%94%E7%AD%94%E4%B8%A2%E5%A4%B1.jpg" alt="部分确认应答丢失"></p>
<ul>
<li>② 某个报文段丢失的情况。接收主机如果收到一个自己应该接收的序列号以外的数据时，会针对当前为止收到数据返回确认应答。如下图所示，当某一报文段丢失后，发送端会一直收到序号为1001的确认应答，因此，在窗口比较大，又出现报文段丢失的情况下，同一个序列号的确认应答将会被重复不断地返回。而发送端主机如果连续3次收到同一个确认应答，就会将其对应的数据进行重发。这种机制比之前提到的超时管理更加高效，因此也被称为高速重发控制。</li>
</ul>
<p><img src="/images/%E9%AB%98%E9%80%9F%E9%87%8D%E5%8F%91%E6%8E%A7%E5%88%B6.jpg" alt="高速重发控制"></p>
<h2 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h2><p>在介绍具体的概念之前，首先我要提到的是TCP中对于拥塞控制的最高思想，主要有三条，那就是既要尽量快的利用信道的最大能力，不要浪费；又要谨慎的控制信道的负载，不要拥堵；同时如果发生了拥堵，必须能够自我调节，不要崩溃。根据这个最高思想，TCP设计了一系列拥塞避免的算法。</p>
<h3 id="慢启动"><a href="#慢启动" class="headerlink" title="慢启动"></a>慢启动</h3><p>在一个网络环境下，信道是共享的，也就是说所有发送的数据都会在这个信道上穿梭。这个道理和高速公路是一样的，你只是高速公路上车流中的一辆车。所以说，当你准备开始发送数据的时候，你不能仅仅做到不管三七二十一，就先按自己的节奏发出自己的数据。如果这个时候信道已经很拥挤，你发出的数据一定也会堵在路上，从而造成进一步的重传，这些重传更加加重了网络的负担，本来拥堵不堪的道路只会越来越差。</p>
<p>所以TCP的设计者们设计了一个保守的策略，这种策略带有浓浓的工科生特点，就是先谨慎的试试，再大胆的前进，实践检验效果。具体的说就是TCP的设计者们采用了一个新的窗口，称之为拥塞窗口，记为cwnd，这个cwnd初始设置为一个one<br>segment的大小，在这里我们简单的理解为TCP报文一次允许发送的最大的大小以方便后面叙述。当发出这个一个报文之后，如果发送端能够收到对应的ACK。那么下一次就会发送2个segment的报文，接着如果还是收到这2个segment的ACK，那么说明这个信道还是可以承受当前大小的包的，那么接着进行试探，发送4个segment的包，收到4ACK，就发送8个segment，以此指数级增长的类推。</p>
<p>简单的说，慢启动就是一句话，大胆尝试，小心求证。而且在慢启动算法中，报文的增长速度是很快的，所以说这个算法的过程并不符合这个算法的名称，之所以称之为慢启动，是他小心的去试探网络情况的哲学上的”慢慢来”。</p>
<h3 id="拥塞避免"><a href="#拥塞避免" class="headerlink" title="拥塞避免"></a>拥塞避免</h3><p>上面的慢启动很明显可以在很短的时间内让信道的利用率达到一个比较理想的值，由于前面一直强调过，信道的资源总是有限的，所以到某一个阶段，这些快速增长的报文必定会充满信道使得信道变得开始拥挤。TCP的设计者们为了不要使得慢启动算法变成一个只有理论意义，而在很短的时间内又会造成网络崩溃从而导致本末倒置。所以说在慢启动的基础上，设计者们做了一些现实的改进与妥协。除了cwnd这个概念，设计者们还定义了一个叫做ssthresh的概念,slow<br>start thresh,<br>中文一般翻译为慢启动阈值，比如65535个字节。如果cwnd的大小达到了这个阈值，那么就不采用指数增长这样的比较暴力的方法，而是采用每次收到一个ACK，cwnd就扩大1个单位的方法，这样比较保守，目的之一就是慢慢而可靠的试出来信道所能承受的最大的负载，符合前面所说的哲学的第一条。</p>
<p>但是信道资源总是有限的，而cwnd在前面描述的过程中无论是怎样的方式，他一直递增的，所以触碰到天花板是必然，按照前面的“三条不要”的最高思想，在遇到信道已经塞满的情况下，需要做的就是快速的减少对信道的负担并且能够快速的恢复。</p>
<p>TCP怎么知道信道拥堵了呢？反过来问，信道拥堵会给发送端带来什么呢？第一个明显的效应就是发送出去的消息收不到ACK，也就是前面说的超时了，如果连续几个消息都没有收到ACK而不停的发生重传，那么就可以判定为信道已经拥堵了。这个时候，拥塞避免算法会进入恢复阶段，其方法很简单：</p>
<ul>
<li>ssthresh设置为当前发生拥塞cwnd的一般，如果cwnd在30个字节的时候（当然不可能只有这么小）发生了拥堵，那么新的ssthresh就设置为15。</li>
<li>TCP重新进入慢启动阶段，也就是将cwnd设置为1，指数增长知道达到新的ssthresh的15，然后再重新按照拥塞避免第一个阶段，线性增长。<br>这个过程可以用图表示：</li>
</ul>
<p><img src="/images/%E6%8B%A5%E5%A1%9E%E9%81%BF%E5%85%8D.jpeg" alt="拥塞避免"></p>
<h3 id="快速重传"><a href="#快速重传" class="headerlink" title="快速重传"></a>快速重传</h3><p>网络是一个很复杂的环境，如果有这么一种情况，网络发生了拥堵但是又那么的拥堵，这种情况的表现是什么呢？按照前面介绍过的滑动窗口，TCP不是one by<br>one的发送数据包的，如果发送的数据包是1,2,3，1和3已经到，但是2没有到，由于拥堵在网络中丢失了，那么接收端会不断告诉发送端下一个需要的报文是2号报文，即使你后面的报文都到了，在2号报文没有收到的情况下，会一直发送对1号报文的ACK，表示需要的是2号报文。如果连续收到三个连续的ACK,就认为网络发生了拥堵。用语言描述有点绕，用图来表示就比较清晰。</p>
<p><img src="/images/%E7%BD%91%E7%BB%9C%E6%8B%A5%E5%A0%B5.jpeg" alt="网络拥堵"></p>
<p>这种情况说明了两种情况：网络确实发生了拥堵，但是又没有完全拥堵。因为如果完全拥堵了，那么发送端也不会受到三个ACK数据报文，所以这种情况没有必要从头再来，因为最高思想的第二点让我们最大的利用信道的能力。按照这个，设计者们又改进了上面的算法，提出了一个快速重传的方案，其思想如下：</p>
<ul>
<li>ssthresh设置为cwnd的一半</li>
<li>cwnd设置为ssthresh的值</li>
<li>不需要重新进入慢启动阶段而是进入拥塞避免阶段<br>用图来表示这个过程如下：</li>
</ul>
<p><img src="/images/%E5%BF%AB%E9%80%9F%E9%87%8D%E4%BC%A0.jpeg" alt="快速重传"></p>
<h3 id="快速恢复"><a href="#快速恢复" class="headerlink" title="快速恢复"></a>快速恢复</h3><p>快速重传算法已经尽力快的恢复对于网络的传送，但是设计们本着”面包里面抠面粉”的原则，在上面的快速重传算法中尝试想想有没有进步空间，在全面分析之后，提出了快速恢复的算法，其具体做法如下：</p>
<ul>
<li>在收到3个重复的ACK之后，ssthresh设置为cwnd的一半，然后把cwnd设置为ssthresh加3个单位的大小，接着重传丢失的报文段，如果用前面的例子来举例就是重传2号报文。</li>
<li>如果这个时候再次收到重传的ACK，那么拥塞窗口增加1。</li>
<li>如果收到的是新的数据包的ACK，把cwnd设置为第一步的ssthresh的值。为什么这么做，因为如果收到的新的ACK，说明网络已经恢复了，可以进入拥塞避免的线性增长阶段了。<br>第一个例子里为什么加3呢，因为这个时候连续的收到3个ACK包，那么可以认为网络还有3个单位大小的余额，同时也可以这么想，说明有3个“老”的数据包已经从网络上离开了。</li>
</ul>
<h2 id="粘包和拆包"><a href="#粘包和拆包" class="headerlink" title="粘包和拆包"></a>粘包和拆包</h2><p>首先因为tcp是面向字节流的协议，所以他不保证包的独立性，只能在上层应用层进行拆包处理。</p>
<p>发送粘包的原因：</p>
<ol>
<li>要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区的数据一次发送出去；</li>
<li>接收数据端的应用层没有及时读取接收缓冲区中的数据；</li>
<li>数据发送过快，数据包堆积导致缓冲区积压多个数据后才一次性发送出去(如果客户端每发送一条数据就睡眠一段时间就不会发生粘包)；</li>
</ol>
<p>拆包：</p>
<ol>
<li>消息定长，例如每个报文的大小为固定长度200字节，如果不够，空位补空格；</li>
<li>在包尾增加回车换行符进行分割，例如FTP协议；</li>
<li>将消息分为消息头和消息体，消息头中包含表示消息总长度（或者消息体长度）的字段，通常设计思路为消息头的第一个字段使用int32来表示消息的总长度；</li>
<li>更复杂的应用层协议。</li>
</ol>
<h1 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h1><p>UDP协议，即用户数据报协议（User Datagram<br>Protocol），是一个简单的面向数据报的传输层协议。UDP协议只在IP数据报服务商增加了很少一点的功能，就是复用和分用，以及差错检测的功能。</p>
<p>UDP 常用于一下几个方面：1.包总量较少的通信（DNS、SNMP等）；2.视频、音频等多媒体通信（即时通信）；3.限定于 LAN<br>等特定网络中的应用通信；4.广播通信（广播、多播）。</p>
<h2 id="UDP特点"><a href="#UDP特点" class="headerlink" title="UDP特点"></a>UDP特点</h2><ol>
<li>无连接的</li>
</ol>
<p>发送数据之前不需要建立连接，减少了开销和发送数据之前的时延。</p>
<ol start="2">
<li>尽最大努力交付</li>
</ol>
<p>不保证可靠的交付，主机不需要维持复杂的链接状态表。</p>
<ol start="3">
<li>面向报文的</li>
</ol>
<p>发送方的UDP对应用程序交下来的报文，在添加首部后就向下交付给IP层。既不拆分，也不合并，而是保留这些报文的边界，因此，应用程序需要选择合适的报文大小。</p>
<ol start="4">
<li><p>没有拥塞控制。</p>
</li>
<li><p>支持一对一、多对一和多对多的交互通信。</p>
</li>
<li><p>首部开销小，只有8个字节。</p>
</li>
</ol>
<h2 id="UDP首部结构"><a href="#UDP首部结构" class="headerlink" title="UDP首部结构"></a>UDP首部结构</h2><p><img src="/images/UDP%E9%A6%96%E9%83%A8%E7%BB%93%E6%9E%84.jpg" alt="UDP首部结构"></p>
<p>UDP首部由4各字段组成，各占两个字节：</p>
<ol>
<li>（1）源端口</li>
</ol>
<p>在需要对方回信时使用，不需要时全为0。</p>
<ol start="2">
<li>目的端口</li>
</ol>
<p>发送UDP数据报的目的地。</p>
<ol start="3">
<li>长度</li>
</ol>
<p>UDP数据报的长度，最短为8个字节，只包含首部。</p>
<ol start="4">
<li>检验和</li>
</ol>
<p>用于检验UDP数据报在传输过程中有没有出差错，有则丢弃。</p>
<h1 id="两者的差别与联系"><a href="#两者的差别与联系" class="headerlink" title="两者的差别与联系"></a>两者的差别与联系</h1><ul>
<li>TCP 是面向连接的、可靠的流协议。流就是指不间断的数据结构，当应用程序采用 TCP 发送消息时，虽然可以保证发送的顺序，但还是犹如没有任何间隔的数据流发送给接收端。TCP 为提供可靠性传输，实行“顺序控制”或“重发控制”机制。此外还具备“流控制（流量控制）”、“拥塞控制”、提高网络利用率等众多功能。</li>
<li>UDP 是不具有可靠性的数据报协议。细微的处理它会交给上层的应用去完成。在 UDP 的情况下，虽然可以确保发送消息的大小，却不能保证消息一定会到达。因此，应用有时会根据自己的需要进行重发处理。</li>
<li>TCP 和 UDP 的优缺点无法简单地、绝对地去做比较：TCP 用于在传输层有必要实现可靠传输的情况；而在一方面，UDP 主要用于那些对高速传输和实时性有较高要求的通信或广播通信。TCP 和 UDP 应该根据应用的目的按需使用。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/01/14/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="merric">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Myoboku">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Myoboku">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/01/14/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" class="post-title-link" itemprop="url">计算机网络</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-01-14 22:30:00" itemprop="dateCreated datePublished" datetime="2020-01-14T22:30:00+00:00">2020-01-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">计算机网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="计算机网络体系结构"><a href="#计算机网络体系结构" class="headerlink" title="计算机网络体系结构"></a>计算机网络体系结构</h1><p>在计算机网络的基本概念中，分层次的体系结构是最基本的。计算机网络体系结构的抽象概念较多，在学习时要多思考。这些概念对后面的学习很有帮助。</p>
<h2 id="网络协议是什么？"><a href="#网络协议是什么？" class="headerlink" title="网络协议是什么？"></a>网络协议是什么？</h2><p>在计算机网络要做到有条不紊地交换数据，就必须遵守一些事先约定好的规则，比如交换数据的格式、是否需要发送一个应答信息。这些规则被称为网络协议。</p>
<h2 id="为什么要对网络协议分层？"><a href="#为什么要对网络协议分层？" class="headerlink" title="为什么要对网络协议分层？"></a>为什么要对网络协议分层？</h2><ul>
<li>简化问题难度和复杂度。由于各层之间独立，我们可以分割大问题为小问题。</li>
<li>灵活性好。当其中一层的技术变化时，只要层间接口关系保持不变，其他层不受影响。</li>
<li>易于实现和维护。</li>
<li>促进标准化工作。分开后，每层功能可以相对简单地被描述。</li>
</ul>
<p>网络协议分层的缺点： 功能可能出现在多个层里，产生了额外开销。</p>
<p>为了使不同体系结构的计算机网络都能互联，国际标准化组织 ISO 于1977年提出了一个试图使各种计算机在世界范围内互联成网的标准框架，即著名的开放系统互联基本参考模型 OSI&#x2F;RM，简称为OSI。</p>
<p>OSI 的七层协议体系结构的概念清楚，理论也较完整，但它既复杂又不实用，TCP&#x2F;IP 体系结构则不同，但它现在却得到了非常广泛的应用。TCP&#x2F;IP 是一个四层体系结构，它包含应用层，运输层，网际层和网络接口层（用网际层这个名字是强调这一层是为了解决不同网络的互连问题），不过从实质上讲，TCP&#x2F;IP 只有最上面的三层，因为最下面的网络接口层并没有什么具体内容，因此在学习计算机网络的原理时往往采用折中的办法，即综合 OSI 和 TCP&#x2F;IP 的优点，采用一种只有五层协议的体系结构，这样既简洁又能将概念阐述清楚，有时为了方便，也可把最底下两层称为网络接口层。</p>
<p>四层协议，五层协议和七层协议的关系如下：</p>
<ul>
<li>TCP&#x2F;IP是一个四层的体系结构，主要包括：应用层、运输层、网际层和网络接口层。</li>
<li>五层协议的体系结构主要包括：应用层、运输层、网络层，数据链路层和物理层。</li>
<li>OSI七层协议模型主要包括是：应用层（Application）、表示层（Presentation）、会话层（Session）、运输层（Transport）、网络层（Network）、数据链路层（Data Link）、物理层（Physical）。</li>
</ul>
<p><img src="/images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84.png" alt="图片" title="计算机网络体系结构"></p>
<p>注：五层协议的体系结构只是为了介绍网络原理而设计的，实际应用还是 TCP&#x2F;IP 四层体系结构。</p>
<h2 id="TCP-IP-协议族"><a href="#TCP-IP-协议族" class="headerlink" title="TCP&#x2F;IP 协议族"></a>TCP&#x2F;IP 协议族</h2><h3 id="应用层"><a href="#应用层" class="headerlink" title="应用层"></a>应用层</h3><p>应用层( application-layer ）的任务是通过应用进程间的交互来完成特定网络应用。应用层协议定义的是应用进程（进程：主机中正在运行的程序）间的通信和交互的规则。</p>
<p>对于不同的网络应用需要不同的应用层协议。在互联网中应用层协议很多，如域名系统 DNS，支持万维网应用的 HTTP 协议，支持电子邮件的 SMTP 协议等等。</p>
<h3 id="运输层"><a href="#运输层" class="headerlink" title="运输层"></a>运输层</h3><p>运输层(transport layer)的主要任务就是负责向两台主机进程之间的通信提供通用的<strong>数据传输服务</strong>。应用进程利用该服务传送应用层报文。</p>
<p>运输层主要使用一下两种协议</p>
<ol>
<li>传输控制协议-TCP：提供面向连接的，可靠的数据传输服务。</li>
<li>用户数据协议-UDP：提供无连接的，尽最大努力的数据传输服务（不保证数据传输的可靠性）。</li>
</ol>
<table>
<thead>
<tr>
<th></th>
<th>UDP</th>
<th>TCP</th>
</tr>
</thead>
<tbody><tr>
<td>是否连接</td>
<td>无连接</td>
<td>面向连接</td>
</tr>
<tr>
<td>是否可靠</td>
<td>不可靠传输，不使用流量控制和拥塞控制</td>
<td>可靠传输，使用流量控制和拥塞控制</td>
</tr>
<tr>
<td>连接对象个数</td>
<td>支持一对一，一对多，多对一和多对多交互通信</td>
<td>只能是一对一通信</td>
</tr>
<tr>
<td>传输方式</td>
<td>面向报文</td>
<td>面向字节流</td>
</tr>
<tr>
<td>首部开销</td>
<td>首部开销小，仅8字节</td>
<td>首部最小20字节，最大60字节</td>
</tr>
<tr>
<td>场景</td>
<td>适用于实时应用（IP电话、视频会议、直播等）</td>
<td>适用于要求可靠传输的应用，例如文件传输</td>
</tr>
</tbody></table>
<p><strong>每一个应用层（TCP&#x2F;IP参考模型的最高层）协议一般都会使用到两个传输层协议之一：</strong></p>
<p>运行在<code>TCP协议</code>上的协议：</p>
<ul>
<li><code>HTTP（Hypertext Transfer Protocol，超文本传输协议）</code>，主要用于普通浏览。</li>
<li><code>HTTPS（HTTP over SSL，安全超文本传输协议）</code>,<code>HTTP</code>协议的安全版本。</li>
<li><code>FTP（File Transfer Protocol，文件传输协议）</code>，用于文件传输。</li>
<li><code>POP3（Post Office Protocol, version 3，邮局协议）</code>，收邮件用。</li>
<li><code>SMTP（Simple Mail Transfer Protocol，简单邮件传输协议）</code>，用来发送电子邮件。</li>
<li><code>TELNET（Teletype over the Network，网络电传）</code>，通过一个<code>终端（terminal）</code>登陆到网络。</li>
<li><code>SSH（Secure Shell，用于替代安全性差的TELNET）</code>，用于加密安全登陆用。</li>
</ul>
<p>运行在<code>UDP协议</code>上的协议：</p>
<ul>
<li><code>BOOTP（Boot Protocol，启动协议）</code>，应用于无盘设备。</li>
<li><code>NTP（Network Time Protocol，网络时间协议）</code>，用于网络同步。</li>
<li><code>DHCP（Dynamic Host Configuration Protocol，动态主机配置协议）</code>，动态配置IP地址。</li>
</ul>
<p>运行在<code>TCP</code>和<code>UDP</code>协议上：</p>
<ul>
<li><code>DNS（Domain Name Service，域名服务）</code>，用于完成地址查找，邮件转发等工作。</li>
</ul>
<h3 id="网络层"><a href="#网络层" class="headerlink" title="网络层"></a>网络层</h3><p>网络层的任务就是选择合适的网间路由和交换结点，确保计算机通信的数据及时传送。在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP&#x2F;IP 体系结构中，由于网络层使用 IP 协议，因此分组也叫 IP 数据报 ，简称数据报。</p>
<p>互联网是由大量的异构（heterogeneous）网络通过路由器（router）相互连接起来的。互联网使用的网络层协议是无连接的网际协议（Intert Prococol）和许多路由选择协议，因此互联网的网络层也叫做网际层或 IP 层。</p>
<h3 id="数据链路层"><a href="#数据链路层" class="headerlink" title="数据链路层"></a>数据链路层</h3><p>数据链路层(data link layer)通常简称为链路层。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。</p>
<p>在两个相邻节点之间传送数据时，数据链路层将网络层交下来的 IP 数据报组装成帧，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如同步信息，地址信息，差错控制等）。</p>
<p>在接收数据时，控制信息使接收端能够知道一个帧从哪个比特开始和到哪个比特结束。</p>
<p>一般的web应用的通信传输流是这样的：</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOS81LzkvMTZhOWM5Y2Q1MjNlMDU5OQ?x-oss-process=image/format,png" alt="图片"></p>
<p>发送端在层与层之间传输数据时，每经过一层时会被打上一个该层所属的首部信息。反之，接收端在层与层之间传输数据时，每经过一层时会把对应的首部信息去除。</p>
<h3 id="物理层"><a href="#物理层" class="headerlink" title="物理层"></a>物理层</h3><p>在物理层上所传送的数据单位是比特。 物理层(physical layer)的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。使其上面的数据链路层不必考虑网络的具体传输介质是什么。“透明传送比特流”表示经实际电路传送后的比特流没有发生变化，对传送的比特流来说，这个电路好像是看不见的。</p>
<h3 id="TCP-IP-协议族-1"><a href="#TCP-IP-协议族-1" class="headerlink" title="TCP&#x2F;IP 协议族"></a>TCP&#x2F;IP 协议族</h3><p>在互联网使用的各种协议中最重要和最著名的就是 TCP&#x2F;IP 两个协议。现在人们经常提到的 TCP&#x2F;IP 并不一定是单指 TCP 和 IP 这两个具体的协议，而往往是表示互联网所使用的整个 TCP&#x2F;IP 协议族。</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOS80LzcvMTY5ZjY5NjZjMjRhZjM0NQ?x-oss-process=image/format,png" alt="图片"></p>
<blockquote>
<p>互联网协议套件（英语：Internet Protocol Suite，缩写<code>IPS</code>）是一个网络通讯模型，以及一整个网络传输协议家族，为网际网络的基础通讯架构。它常被通称为TCP&#x2F;IP协议族（英语：<code>TCP/IP Protocol Suite</code>，或<code>TCP/IP Protocols</code>），简称<code>TCP/IP</code>。因为该协定家族的两个核心协定：<code>TCP（传输控制协议）和IP（网际协议）</code>，为该家族中最早通过的标准。</p>
</blockquote>
<h1 id="TCP的三次握手四次挥手"><a href="#TCP的三次握手四次挥手" class="headerlink" title="TCP的三次握手四次挥手"></a>TCP的三次握手四次挥手</h1><p>TCP是一种面向连接的、可靠的、基于字节流的传输层通信协议，在发送数据前，通信双方必须在彼此间建立一条连接。所谓的“连接”，其实是客户端和服务端保存的一份关于对方的信息，如ip地址、端口号等。</p>
<p>TCP可以看成是一种字节流，它会处理IP层或以下的层的丢包、重复以及错误问题。在连接的建立过程中，双方需要交换一些连接的参数。这些参数可以放在TCP头部。</p>
<p>一个TCP连接由一个4元组构成，分别是两个IP地址和两个端口号。一个TCP连接通常分为三个阶段：连接、数据传输、退出（关闭）。<strong>通过三次握手建立一个链接，通过四次挥手来关闭一个连接</strong>。</p>
<p><strong>当一个连接被建立或被终止时，交换的报文段只包含TCP头部，而没有数据</strong>。</p>
<h2 id="TCP报文的头部结构"><a href="#TCP报文的头部结构" class="headerlink" title="TCP报文的头部结构"></a>TCP报文的头部结构</h2><p>在了解TCP连接之前先来了解一下TCP报文的头部结构。</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAyMC8xLzcvMTZmN2UwM2IxOWU2YzEzNA?x-oss-process=image/format,png" alt="图片"></p>
<p>上图中有几个字段需要重点介绍下：</p>
<p>（1）序号：seq序号，占32位，用来标识从TCP源端向目的端发送的字节流，发起方发送数据时对此进行标记。</p>
<p>（2）确认序号：ack序号，占32位，只有ACK标志位为1时，确认序号字段才有效，ack&#x3D;seq+1。</p>
<p>（3）标志位：共6个，即URG、ACK、PSH、RST、SYN、FIN等，具体含义如下：</p>
<ul>
<li>ACK：确认序号有效。</li>
<li>FIN：释放一个连接。</li>
<li>PSH：接收方应该尽快将这个报文交给应用层。</li>
<li>RST：重置连接。</li>
<li>SYN：发起一个新连接。</li>
<li>URG：紧急指针（urgent pointer）有效。</li>
</ul>
<p>需要注意的是：</p>
<ul>
<li>不要将确认序号ack与标志位中的ACK搞混了。</li>
<li>确认方ack&#x3D;发起方seq+1，两端配对。</li>
</ul>
<h2 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h2><blockquote>
<p>三次握手的本质是确认通信双方收发数据的能力</p>
</blockquote>
<p>首先，我让信使运输一份信件给对方，<strong>对方收到了，那么他就知道了我的发件能力和他的收件能力是可以的</strong>。</p>
<p>于是他给我回信，<strong>我若收到了，我便知我的发件能力和他的收件能力是可以的，并且他的发件能力和我的收件能力是可以</strong>。</p>
<p>然而此时他还不知道他的发件能力和我的收件能力到底可不可以，于是我最后回馈一次，<strong>他若收到了，他便清楚了他的发件能力和我的收件能力是可以的</strong>。</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAyMC8xLzcvMTZmN2UwM2IxZWE1MDdlOA?x-oss-process=image/format,png" alt="图片"></p>
<ul>
<li><code>第一次握手</code>：客户端要向服务端发起连接请求，首先客户端随机生成一个起始序列号ISN(比如是100)，那客户端向服务端发送的报文段包含SYN标志位(也就是SYN&#x3D;1)，序列号seq&#x3D;100。</li>
<li><code>第二次握手</code>：服务端收到客户端发过来的报文后，发现SYN&#x3D;1，知道这是一个连接请求，于是将客户端的起始序列号100存起来，并且随机生成一个服务端的起始序列号(比如是300)。然后给客户端回复一段报文，回复报文包含SYN和ACK标志(也就是SYN&#x3D;1,ACK&#x3D;1)、序列号seq&#x3D;300、确认号ack&#x3D;101(客户端发过来的序列号+1)。</li>
<li><code>第三次握手</code>：客户端收到服务端的回复后发现ACK&#x3D;1并且ack&#x3D;101,于是知道服务端已经收到了序列号为100的那段报文；同时发现SYN&#x3D;1，知道了服务端同意了这次连接，于是就将服务端的序列号300给存下来。然后客户端再回复一段报文给服务端，报文包含ACK标志位(ACK&#x3D;1)、ack&#x3D;301(服务端序列号+1)、seq&#x3D;101(第一次握手时发送报文是占据一个序列号的，所以这次seq就从101开始，需要注意的是不携带数据的ACK报文是不占据序列号的，所以后面第一次正式发送数据时seq还是101)。当服务端收到报文后发现ACK&#x3D;1并且ack&#x3D;301，就知道客户端收到序列号为300的报文了，就这样客户端和服务端通过TCP建立了连接。</li>
</ul>
<h2 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h2><blockquote>
<p>四次挥手的目的是关闭一个连接</p>
</blockquote>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAyMC8xLzcvMTZmN2UwM2IyMWEwN2YwYw?x-oss-process=image/format,png" alt="图片"></p>
<p>比如客户端初始化的序列号ISA&#x3D;100，服务端初始化的序列号ISA&#x3D;300。TCP连接成功后客户端总共发送了1000个字节的数据，服务端在客户端发FIN报文前总共回复了2000个字节的数据。</p>
<ul>
<li><code>第一次挥手</code>：当客户端的数据都传输完成后，客户端向服务端发出连接释放报文(当然数据没发完时也可以发送连接释放报文并停止发送数据)，释放连接报文包含FIN标志位(FIN&#x3D;1)、序列号seq&#x3D;1101(100+1+1000，其中的1是建立连接时占的一个序列号)。需要注意的是客户端发出FIN报文段后只是不能发数据了，但是还可以正常收数据；另外FIN报文段即使不携带数据也要占据一个序列号。</li>
<li><code>第二次挥手</code>：服务端收到客户端发的FIN报文后给客户端回复确认报文，确认报文包含ACK标志位(ACK&#x3D;1)、确认号ack&#x3D;1102(客户端FIN报文序列号1101+1)、序列号seq&#x3D;2300(300+2000)。此时服务端处于关闭等待状态，而不是立马给客户端发FIN报文，这个状态还要持续一段时间，因为服务端可能还有数据没发完。</li>
<li><code>第三次挥手</code>：服务端将最后数据(比如50个字节)发送完毕后就向客户端发出连接释放报文，报文包含FIN和ACK标志位(FIN&#x3D;1,ACK&#x3D;1)、确认号和第二次挥手一样ack&#x3D;1102、序列号seq&#x3D;2350(2300+50)。</li>
<li><code>第四次挥手</code>：客户端收到服务端发的FIN报文后，向服务端发出确认报文，确认报文包含ACK标志位(ACK&#x3D;1)、确认号ack&#x3D;2351、序列号seq&#x3D;1102。注意客户端发出确认报文后不是立马释放TCP连接，而是要经过2MSL(最长报文段寿命的2倍时长)后才释放TCP连接。而服务端一旦收到客户端发出的确认报文就会立马释放TCP连接，所以服务端结束TCP连接的时间要比客户端早一些。</li>
</ul>
<h3 id="为什么TCP连接的时候是3次？2次不可以吗？"><a href="#为什么TCP连接的时候是3次？2次不可以吗？" class="headerlink" title="为什么TCP连接的时候是3次？2次不可以吗？"></a>为什么TCP连接的时候是3次？2次不可以吗？</h3><p>因为需要考虑连接时丢包的问题，如果只握手2次，第二次握手时如果服务端发给客户端的确认报文段丢失，此时服务端已经准备好了收发数(可以理解服务端已经连接成功)据，而客户端一直没收到服务端的确认报文，所以客户端就不知道服务端是否已经准备好了(可以理解为客户端未连接成功)，这种情况下客户端不会给服务端发数据，也会忽略服务端发过来的数据。</p>
<p>如果是三次握手，即便发生丢包也不会有问题，比如如果第三次握手客户端发的确认ack报文丢失，服务端在一段时间内没有收到确认ack报文的话就会重新进行第二次握手，也就是服务端会重发SYN报文段，客户端收到重发的报文段后会再次给服务端发送确认ack报文。</p>
<h3 id="为什么TCP连接的时候是3次，关闭的时候却是4次？"><a href="#为什么TCP连接的时候是3次，关闭的时候却是4次？" class="headerlink" title="为什么TCP连接的时候是3次，关闭的时候却是4次？"></a>为什么TCP连接的时候是3次，关闭的时候却是4次？</h3><p>因为只有在客户端和服务端都没有数据要发送的时候才能断开TCP。而客户端发出FIN报文时只能保证客户端没有数据发了，服务端还有没有数据发客户端是不知道的。而服务端收到客户端的FIN报文后只能先回复客户端一个确认报文来告诉客户端我服务端已经收到你的FIN报文了，但我服务端还有一些数据没发完，等这些数据发完了服务端才能给客户端发FIN报文(所以不能一次性将确认报文和FIN报文发给客户端，就是这里多出来了一次)。</p>
<h3 id="为什么客户端发出第四次挥手的确认报文后要等2MSL的时间才能释放TCP连接？"><a href="#为什么客户端发出第四次挥手的确认报文后要等2MSL的时间才能释放TCP连接？" class="headerlink" title="为什么客户端发出第四次挥手的确认报文后要等2MSL的时间才能释放TCP连接？"></a>为什么客户端发出第四次挥手的确认报文后要等2MSL的时间才能释放TCP连接？</h3><p>这里同样是要考虑丢包的问题，如果第四次挥手的报文丢失，服务端没收到确认ack报文就会重发第三次挥手的报文，这样报文一去一回最长时间就是2MSL，所以需要等这么长时间来确认服务端确实已经收到了。</p>
<h3 id="如果已经建立了连接，但是客户端突然出现故障了怎么办？"><a href="#如果已经建立了连接，但是客户端突然出现故障了怎么办？" class="headerlink" title="如果已经建立了连接，但是客户端突然出现故障了怎么办？"></a>如果已经建立了连接，但是客户端突然出现故障了怎么办？</h3><p>TCP设有一个保活计时器，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。</p>
<h3 id="什么是HTTP，HTTP-与-HTTPS-的区别"><a href="#什么是HTTP，HTTP-与-HTTPS-的区别" class="headerlink" title="什么是HTTP，HTTP 与 HTTPS 的区别"></a>什么是HTTP，HTTP 与 HTTPS 的区别</h3><p>HTTP 是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范</p>
<table>
<thead>
<tr>
<th>区别</th>
<th>HTTP</th>
<th>HTTPS</th>
</tr>
</thead>
<tbody><tr>
<td>协议</td>
<td>运行在 TCP 之上，明文传输，<strong>客户端与服务器端都无法验证对方的身份</strong></td>
<td>身披 SSL( Secure Socket Layer )外壳的 HTTP，运行于 SSL 上，SSL 运行于 TCP 之上， <strong>是添加了加密和认证机制的 HTTP</strong>。</td>
</tr>
<tr>
<td>端口</td>
<td>80</td>
<td>443</td>
</tr>
<tr>
<td>资源消耗</td>
<td>较少</td>
<td>由于加解密处理，会消耗更多的 CPU 和内存资源</td>
</tr>
<tr>
<td>开销</td>
<td>无需证书</td>
<td>需要证书，而证书一般需要向认证机构购买</td>
</tr>
<tr>
<td>加密机制</td>
<td>无</td>
<td>共享密钥加密和公开密钥加密并用的混合加密机制</td>
</tr>
<tr>
<td>安全性</td>
<td>弱</td>
<td>由于加密机制，安全性强</td>
</tr>
</tbody></table>
<h3 id="常用HTTP状态码"><a href="#常用HTTP状态码" class="headerlink" title="常用HTTP状态码"></a>常用HTTP状态码</h3><p>HTTP状态码表示客户端HTTP请求的返回结果、标识服务器处理是否正常、表明请求出现的错误等。</p>
<p>状态码的类别：</p>
<table>
<thead>
<tr>
<th>类别</th>
<th>原因短语</th>
</tr>
</thead>
<tbody><tr>
<td>1XX</td>
<td>Informational（信息性状态码） 接受的请求正在处理</td>
</tr>
<tr>
<td>2XX</td>
<td>Success（成功状态码） 请求正常处理完毕</td>
</tr>
<tr>
<td>3XX</td>
<td>Redirection（重定向状态码） 需要进行附加操作以完成请求</td>
</tr>
<tr>
<td>4XX</td>
<td>Client Error（客户端错误状态码） 服务器无法处理请求</td>
</tr>
<tr>
<td>5XX</td>
<td>Server Error（服务器错误状态码） 服务器处理请求出错</td>
</tr>
</tbody></table>
<p>常用HTTP状态码：</p>
<table>
<thead>
<tr>
<th>2XX</th>
<th>成功（这系列表明请求被正常处理了）</th>
</tr>
</thead>
<tbody><tr>
<td>200</td>
<td>OK，表示从客户端发来的请求在服务器端被正确处理</td>
</tr>
<tr>
<td>204</td>
<td>No content，表示请求成功，但响应报文不含实体的主体部分</td>
</tr>
<tr>
<td>206</td>
<td>Partial Content，进行范围请求成功</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>3XX</th>
<th>重定向（表明浏览器要执行特殊处理）</th>
</tr>
</thead>
<tbody><tr>
<td>301</td>
<td>moved permanently，永久性重定向，表示资源已被分配了新的 URL</td>
</tr>
<tr>
<td>302</td>
<td>found，临时性重定向，表示资源临时被分配了新的 URL</td>
</tr>
<tr>
<td>303</td>
<td>see other，表示资源存在着另一个 URL，应使用 GET 方法获取资源（对于301&#x2F;302&#x2F;303响应，几乎所有浏览器都会删除报文主体并自动用GET重新请求）</td>
</tr>
<tr>
<td>304</td>
<td>not modified，表示服务器允许访问资源，但请求未满足条件的情况（与重定向无关）</td>
</tr>
<tr>
<td>307</td>
<td>temporary redirect，临时重定向，和302含义类似，但是期望客户端保持请求方法不变向新的地址发出请求</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>4XX</th>
<th>客户端错误</th>
</tr>
</thead>
<tbody><tr>
<td>400</td>
<td>bad request，请求报文存在语法错误</td>
</tr>
<tr>
<td>401</td>
<td>unauthorized，表示发送的请求需要有通过 HTTP 认证的认证信息</td>
</tr>
<tr>
<td>403</td>
<td>forbidden，表示对请求资源的访问被服务器拒绝，可在实体主体部分返回原因描述</td>
</tr>
<tr>
<td>404</td>
<td>not found，表示在服务器上没有找到请求的资源</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>5XX</th>
<th>服务器错误</th>
</tr>
</thead>
<tbody><tr>
<td>500</td>
<td>internal sever error，表示服务器端在执行请求时发生了错误</td>
</tr>
<tr>
<td>501</td>
<td>Not Implemented，表示服务器不支持当前请求所需要的某个功能</td>
</tr>
<tr>
<td>503</td>
<td>service unavailable，表明服务器暂时处于超负载或正在停机维护，无法处理请求</td>
</tr>
</tbody></table>
<h3 id="GET和POST区别"><a href="#GET和POST区别" class="headerlink" title="GET和POST区别"></a>GET和POST区别</h3><p>说道GET和POST，就不得不提HTTP协议，因为浏览器和服务器的交互是通过HTTP协议执行的，而GET和POST也是HTTP协议中的两种方法。</p>
<p>HTTP全称为Hyper Text Transfer Protocol，中文翻译为超文本传输协议，目的是保证浏览器与服务器之间的通信。HTTP的工作方式是客户端与服务器之间的请求-应答协议。</p>
<p>HTTP协议中定义了浏览器和服务器进行交互的不同方法，基本方法有4种，分别是GET，POST，PUT，DELETE。这四种方法可以理解为，对服务器资源的查，改，增，删。</p>
<ul>
<li>GET：从服务器上获取数据，也就是所谓的查，仅仅是获取服务器资源，不进行修改。</li>
<li>POST：向服务器提交数据，这就涉及到了数据的更新，也就是更改服务器的数据。</li>
<li>PUT：英文含义是放置，也就是向服务器新添加数据，就是所谓的增。</li>
<li>DELETE：从字面意思也能看出，这种方式就是删除服务器数据的过程。</li>
</ul>
<p><strong>GET和POST区别</strong></p>
<ol>
<li><p>Get是不安全的，因为在传输过程，数据被放在请求的URL中；Post的所有操作对用户来说都是不可见的。 但是这种做法也不时绝对的，大部分人的做法也是按照上面的说法来的，但是也可以在get请求加上 request body，给 post请求带上 URL 参数。</p>
</li>
<li><p>Get请求提交的url中的数据最多只能是2048字节，这个限制是浏览器或者服务器给添加的，http协议并没有对url长度进行限制，目的是为了保证服务器和浏览器能够正常运行，防止有人恶意发送请求。Post请求则没有大小限制。</p>
</li>
<li><p>Get限制Form表单的数据集的值必须为ASCII字符；而Post支持整个ISO10646字符集。</p>
</li>
<li><p>Get执行效率却比Post方法好。Get是form提交的默认方法。</p>
</li>
<li><p>GET产生一个TCP数据包；POST产生两个TCP数据包。</p>
<p>对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；</p>
<p>而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。</p>
</li>
</ol>
<h3 id="什么是对称加密与非对称加密"><a href="#什么是对称加密与非对称加密" class="headerlink" title="什么是对称加密与非对称加密"></a>什么是对称加密与非对称加密</h3><p>对称密钥加密是指加密和解密使用同一个密钥的方式，<strong>这种方式存在的最大问题就是密钥发送问题，即如何安全地将密钥发给对方；</strong></p>
<p>而非对称加密是指使用一对非对称密钥，即公钥和私钥，公钥可以随意发布，但私钥只有自己知道。发送密文的一方使用对方的公钥进行加密处理，对方接收到加密信息后，使用自己的私钥进行解密。<br>由于非对称加密的方式不需要发送用来解密的私钥，所以可以保证安全性；但是和对称加密比起来，非常的慢</p>
<h3 id="什么是HTTP2"><a href="#什么是HTTP2" class="headerlink" title="什么是HTTP2"></a>什么是HTTP2</h3><p>HTTP2 可以提高了网页的性能。</p>
<p>在 HTTP1 中浏览器限制了同一个域名下的请求数量（Chrome 下一般是六个），当在请求很多资源的时候，由于队头阻塞当浏览器达到最大请求数量时，剩余的资源需等待当前的六个请求完成后才能发起请求。</p>
<p>HTTP2 中引入了多路复用的技术，这个技术可以只通过一个 TCP 连接就可以传输所有的请求数据。多路复用可以绕过浏览器限制同一个域名下的请求数量的问题，进而提高了网页的性能。</p>
<h3 id="Session、Cookie和Token的主要区别"><a href="#Session、Cookie和Token的主要区别" class="headerlink" title="Session、Cookie和Token的主要区别"></a>Session、Cookie和Token的主要区别</h3><p>HTTP协议本身是无状态的。什么是无状态呢，即服务器无法判断用户身份。</p>
<p><strong>什么是cookie</strong></p>
<p>cookie是由Web服务器保存在用户浏览器上的小文件（key-value格式），包含用户相关的信息。客户端向服务器发起请求，如果服务器需要记录该用户状态，就使用response向客户端浏览器颁发一个Cookie。客户端浏览器会把Cookie保存起来。当浏览器再请求该网站时，浏览器把请求的网址连同该Cookie一同提交给服务器。服务器检查该Cookie，以此来辨认用户身份。</p>
<p><strong>什么是session</strong></p>
<p>session是依赖Cookie实现的。session是服务器端对象</p>
<p>session 是浏览器和服务器会话过程中，服务器分配的一块储存空间。服务器默认为浏览器在cookie中设置 sessionid，浏览器在向服务器请求过程中传输 cookie 包含 sessionid ，服务器根据 sessionid 获取出会话中存储的信息，然后确定会话的身份信息。</p>
<p><strong>cookie与session区别</strong></p>
<ul>
<li>存储位置与安全性：cookie数据存放在客户端上，安全性较差，session数据放在服务器上，安全性相对更高；</li>
<li>存储空间：单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie，session无此限制</li>
<li>占用服务器资源：session一定时间内保存在服务器上，当访问增多，占用服务器性能，考虑到服务器性能方面，应当使用cookie。</li>
</ul>
<p><strong>什么是Token</strong></p>
<p>Token的引入：Token是在客户端频繁向服务端请求数据，服务端频繁的去数据库查询用户名和密码并进行对比，判断用户名和密码正确与否，并作出相应提示，在这样的背景下，Token便应运而生。</p>
<p>Token的定义：Token是服务端生成的一串字符串，以作客户端进行请求的一个令牌，当第一次登录后，服务器生成一个Token便将此Token返回给客户端，以后客户端只需带上这个Token前来请求数据即可，无需再次带上用户名和密码。</p>
<p>使用Token的目的：Token的目的是为了减轻服务器的压力，减少频繁的查询数据库，使服务器更加健壮。</p>
<p>Token 是在服务端产生的。如果前端使用用户名&#x2F;密码向服务端请求认证，服务端认证成功，那么在服务端会返回 Token 给前端。前端可以在每次请求的时候带上 Token 证明自己的合法地位</p>
<p><strong>session与token区别</strong></p>
<ul>
<li>session机制存在服务器压力增大，CSRF跨站伪造请求攻击，扩展性不强等问题；</li>
<li>session存储在服务器端，token存储在客户端</li>
<li>token提供认证和授权功能，作为身份认证，token安全性比session好；</li>
<li>session这种会话存储方式方式只适用于客户端代码和服务端代码运行在同一台服务器上，token适用于项目级的前后端分离（前后端代码运行在不同的服务器下）</li>
</ul>
<h3 id="Servlet是线程安全的吗"><a href="#Servlet是线程安全的吗" class="headerlink" title="Servlet是线程安全的吗"></a>Servlet是线程安全的吗</h3><p><strong>Servlet不是线程安全的，多线程并发的读写会导致数据不同步的问题。</strong></p>
<p>解决的办法是尽量不要定义name属性，而是要把name变量分别定义在doGet()和doPost()方法内。虽然使用synchronized(name){}语句块可以解决问题，但是会造成线程的等待，不是很科学的办法。</p>
<p>注意：多线程的并发的读写Servlet类属性会导致数据不同步。但是如果只是并发地读取属性而不写入，则不存在数据不同步的问题。因此Servlet里的只读属性最好定义为final类型的。</p>
<h3 id="Servlet接口中有哪些方法及Servlet生命周期探秘"><a href="#Servlet接口中有哪些方法及Servlet生命周期探秘" class="headerlink" title="Servlet接口中有哪些方法及Servlet生命周期探秘"></a>Servlet接口中有哪些方法及Servlet生命周期探秘</h3><p>在Java Web程序中，<strong>Servlet</strong>主要负责接收用户请求<strong>HttpServletRequest</strong>，在<em>*doGet()**，**doPost()<strong>中做相应的处理，并将回应</strong>HttpServletResponse</em>*反馈给用户。Servlet可以设置初始化参数，供Servlet内部使用。</p>
<p>Servlet接口定义了5个方法，其中<strong>前三个方法与Servlet生命周期相关</strong>：</p>
<ul>
<li><strong>void init(ServletConfig config) throws ServletException</strong></li>
<li><strong>void service(ServletRequest req, ServletResponse resp) throws ServletException, java.io.IOException</strong></li>
<li><strong>void destory()</strong></li>
<li>java.lang.String getServletInfo()</li>
<li>ServletConfig getServletConfig()</li>
</ul>
<p><strong>生命周期：</strong></p>
<p><strong>Web容器加载Servlet并将其实例化后，Servlet生命周期开始</strong>，容器运行其<strong>init()方法</strong>进行Servlet的初始化；</p>
<p>请求到达时调用Servlet的<strong>service()方法</strong>，service()方法会根据需要调用与请求对应的<strong>doGet或doPost</strong>等方法；</p>
<p>当服务器关闭或项目被卸载时服务器会将Servlet实例销毁，此时会调用Servlet的<strong>destroy()方法</strong>。</p>
<p><strong>init方法和destory方法只会执行一次，service方法客户端每次请求Servlet都会执行</strong>。Servlet中有时会用到一些需要初始化与销毁的资源，因此可以把初始化资源的代码放入init方法中，销毁资源的代码放入destroy方法中，这样就不需要每次处理客户端的请求都要初始化与销毁资源。</p>
<h3 id="如果客户端禁止-cookie-能实现-session-还能用吗？"><a href="#如果客户端禁止-cookie-能实现-session-还能用吗？" class="headerlink" title="如果客户端禁止 cookie 能实现 session 还能用吗？"></a>如果客户端禁止 cookie 能实现 session 还能用吗？</h3><p>Cookie 与 Session，一般认为是两个独立的东西，Session采用的是在服务器端保持状态的方案，而Cookie采用的是在客户端保持状态的方案。</p>
<p>但为什么禁用Cookie就不能得到Session呢？因为Session是用Session ID来确定当前对话所对应的服务器Session，而Session ID是通过Cookie来传递的，禁用Cookie相当于失去了Session ID，也就得不到Session了。</p>
<p>假定用户关闭Cookie的情况下使用Session，其实现途径有以下几种：</p>
<ol>
<li>手动通过URL传值、隐藏表单传递Session ID。</li>
<li>用文件、数据库等形式保存Session ID，在跨页过程中手动调用。</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/01/13/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTPS%E7%9A%84%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6%E9%AA%8C%E8%AF%81%E5%8E%9F%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="merric">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Myoboku">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Myoboku">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/01/13/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTPS%E7%9A%84%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6%E9%AA%8C%E8%AF%81%E5%8E%9F%E7%90%86/" class="post-title-link" itemprop="url">Https中数字证书的原理</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-01-13 22:30:00" itemprop="dateCreated datePublished" datetime="2020-01-13T22:30:00+00:00">2020-01-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">计算机网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>网络请求方式通常分为两种，分别是HTTP请求和HTTPS请求，其中HTTP的传输属于明文传输，在传输的过程中容易被人截取并且偷窥其中的内容，而HTTPS是一种在HTTP的基础上加了SSL&#x2F;TLS层（安全套接层）的安全的超文本传输协议，其传输的内容是通过加密得到的，所以说是一种安全的传输。</p>
<p>说到加密算法，先来了解一下两种常用的加密方式，分别是对称加密和非对称加密：</p>
<p>1.对称加密：加密使用的秘钥和解密使用的秘钥是相同的，也就是说加密和解密都使用同一个秘钥，加密算法是公开的，秘钥是加密者和解密者绝对保密的。</p>
<p>2.非对称加密：加密使用的秘钥和解密使用的秘钥是不相同的，HTTPS在数字证书验证的时候，采用的RSA密码体制就是一种非对称加密。</p>
<p>RSA是一种公钥秘钥密码体制，现在使用非常广泛，这个密码体制分为三部分，公钥、私钥、加密算法，其中公钥和加密算法是公布的，私钥是自己保密的。这种机制最大的特点是，通过公钥加密的密文只有对应的私钥才能解密，同样通过私钥加密的密文也只有对应的公钥才能解密。下面我们将会讲到HTTPS是如何通过RSA这种密码体制去验证身份的。</p>
<p>首先了解一下数字证书，它有点像身份证，是由权威的CA机构颁发的，证书的主要内容有：公钥（Public Key）、ISSUER（证书的发布机构）、Subject（证书持有者）、证书有效期、签名算法、指纹及指纹算法。</p>
<p>下面csdn博客的CA证书内容：</p>
<p><img src="/images/csdnCA%E8%AF%81%E4%B9%A6%E5%86%85%E5%AE%B9.png" alt="图片" title="csdnCA证书内容"></p>
<p>可以看到公钥是一串很长的2048 Bits的字符串，同时也可以看到&lt;使用者&gt;的内容包含了csdn.net网址，这个网址是CSDN唯一拥有的，后面验证链接url是否正确的时候用到，还有颁发者、有效期、签名哈希算法等等。当然还有指纹及指纹算法等其他内容，我们滚动到下面看看另外一个截图</p>
<p><img src="/images/%E8%AF%81%E4%B9%A6%E8%AF%A6%E6%83%85.png" alt="图片" title="证书详情"></p>
<p>上面是CSDN网站CA证书，颁发者是GeoTrust，它就是权威的CA机构之一。到这里特别说明一下，CA机构除了给别人颁发证书以外，它也有自己的证书，为了区分我们称它为根证书，根证书也有自己的公钥和私钥，我们称之为根公钥和根私钥。然后根公钥和加密算法是向外公布的，而根私钥是机构自己绝对保密的。这个根证书在验证证书的过程中起着核心的作用。</p>
<p>指纹是什么？指纹是一个证书的签名，是通过指纹算法sha1计算出来的一个hash值，是用来验证证书内容有没有被篡改的。证书在发布之前，CA机构会把所颁发证书的内容用自己的根私钥通过指纹算法计算得到一个hash值，这个hash值只有对应的根公钥才能解密，所以在验证证书的时候，我们通过同样的指纹算法将证书内容通过计算得到另一个hash值，如果这个hash值跟证书上的签名解析出来的hash值相同，就代表证书没有被篡改过。</p>
<p>下面基于一个简单的图例，去分析整个HTTPS的数字证书验证过程：</p>
<p>图示如下：</p>
<p><img src="/images/HTTPS%E7%9A%84%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6%E9%AA%8C%E8%AF%81%E8%BF%87%E7%A8%8B.png" alt="图片" title="HTTPS的数字证书验证过程"></p>
<p>假设这是一个浏览器的HTTPS请求</p>
<p>一：首先浏览器通过URL网址去请求某个后台服务器，后台接收到请求后，就会给浏览器发送一个自己的CA数字证书。</p>
<p>二：浏览器接收到数字证书以后，就要开始进行验证工作了。首先从证书的内容中获取证书的颁发机构，然后从浏览器系统中去寻找此颁发机构是否为浏览器的信任机构。这里解析一下，世界上就几个权威的CA机构，这几个机构的信息都是预先嵌入到我们的浏览器系统中的。如果收到的一个数字证书但其颁发机构没有在我们浏览器系统中的，那么就会有警告提示无法确认证书的真假。如果是受信任的机构，那么就到下一步。</p>
<p>此时我们就可以从浏览器中找到CA机构的根公钥，用这个公钥去解析证书的签名得到一个hash值H1，上面提到过，这个签名是证书发布之前CA机构用自己的根私钥加密而成的，所以这里只能由根证书的根公钥去解密。然后用证书的指纹算法对证书的内容再进行hash计算得到另一个hash值H2，如果此时H1和H2是相等的，就代表证书没有被修改过。在证书没有被修改过的基础上，再检查证书上的使用者的URL（比如csdn.net）和我们请求的URL是否相等，如果相等，那么就可以证明当前浏览器连接的网址也是正确的，而不是一些钓鱼网之类的。</p>
<p>这里我们假设，如果浏览器的连接被某个钓鱼网截取了，钓鱼网也可以发一个自己的证书给浏览器，然后也可以通过证书没有被篡改的验证，但是在证书没有被篡改的情况下，通过对比证书上的URL和我们请求的URL，就可以发现这个证书的URL不是我们所要连接的网址，所以说钓鱼网也骗不了我们。</p>
<p>看到这里如果还不是很明白证书验证过程的话，我特别解析一下，我们知道CA机构有自己的根公钥和根私钥。在证书颁发之前，机构会用根私钥将这个证书内容加密得到一个签名，这个签名只能用对应的根公钥去解密。在客户端（浏览器）收到服务端发过来的证书以后，我们首先从浏览器中拿到机构的根公钥，用这个根公钥去解析证书的签名得到一个哈希值H1，这个H1代表证书的原始内容，假设这个证书上的签名是不法分子伪造的，但是伪造的签名不可能是根私钥加密生成的（因为根私钥是CA机构私有），所以根公钥也不可能去解密任何第三方生成的签名（加密内容只能由对应的公钥私钥解析）。然后我们再用同样的哈希算法对收证书内容进行计算得到哈希值H2，通过对比H1和H2是否相等就知道证书有没有被褚篡改过了。讲到这里，我们应该明白证书是否被篡改的验证机制了吧。</p>
<p>三：到这里，已经验证了证书是没有被篡改的并且确认连接的URL也是正确的，然后我们获取到了证书上的公钥。下一步有一个很重要的任务就是，如何将一个对称加密算法的秘钥安全地发给服务器。</p>
<p>首先随机生成一个字符串S作为我们的秘钥，然后通过证书公钥加密成密文，将密文发送给服务器。因为此密文是用公钥加密的，这是一个非对称加密，我们知道，这个密文只有私钥的持有者才能进行解密，所以说任何第三方截取到密文也是没用的，因为没有对应的私钥所以解析不出来。</p>
<p>一个关键步骤，发送密文的时候也会对消息内容进行签名操作。签名上面讲解过，就是对密文内容进行hash计算得到的一个hash值，将这个签名加密以后和消息内容一起发送出去。接收方收到消息以后，通过私钥解析出密文和签名的hash值，同时也会对接收的消息内容进行同样的计算得到另一个hash值，通过比对两个hash值是否相同来判断密文是否有修改过。</p>
<p>四：通过了上面的步骤以后，此时客户端和服务端都持有了对称加密算法的秘钥，然后兄弟两就可以愉快地安全通信了。</p>
<p>总结：数字证书的验证有两个重要的步骤，第一是验证数字证书没有被篡改以及连接的URL是否正确，第二是通过RSA机制的原理安全地将对称加密算法的秘钥发送给对方。这两步都完成以后，整个HTTPS的数字证书的验证就算是成功了。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/01/13/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP%E5%92%8CHTTPS/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="merric">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Myoboku">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Myoboku">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/01/13/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP%E5%92%8CHTTPS/" class="post-title-link" itemprop="url">Http和Https</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-01-13 22:30:00" itemprop="dateCreated datePublished" datetime="2020-01-13T22:30:00+00:00">2020-01-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">计算机网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="什么是HTTP"><a href="#什么是HTTP" class="headerlink" title="什么是HTTP"></a>什么是HTTP</h1><p>HTTP协议（HyperText Transfer<br>Protocol，超文本传输协议）是用于从WWW服务器传输超文本到本地浏览器的传输协议。它可以使浏览器更加高效，使网络传输减少。它不仅保证计算机正确快速地传输超文本文档，还确定传输文档中的哪一部分，以及哪部分内容首先显示(如文本先于图形)等。<br>HTTP是客户端浏览器或其他程序与Web服务器之间的应用层通信协议。在Internet上的Web服务器上存放的都是超文本信息，客户机需要通过HTTP协议传输所要访问的超文本信息。HTTP包含命令和传输信息，不仅可用于Web访问，也可以用于其他因特网&#x2F;内联网应用系统之间的通信，从而实现各类应用资源超媒体访问的集成。<br>我们在浏览器的地址栏里输入的网站地址叫做URL (Uniform Resource<br>Locator，统一资源定位符)。就像每家每户都有一个门牌地址一样，每个网页也都有一个Internet地址。当你在浏览器的地址框中输入一个URL或是单击一个超级链接时，URL就确定了要浏览的地址。浏览器通过超文本传输协议(HTTP)，将Web服务器上站点的网页代码提取出来，并翻译成漂亮的网页。</p>
<h2 id="HTTP工作过程"><a href="#HTTP工作过程" class="headerlink" title="HTTP工作过程"></a>HTTP工作过程</h2><p><img src="/images/HTTP%E8%AF%B7%E6%B1%82%E5%93%8D%E5%BA%94%E6%A8%A1%E5%9E%8B.jpg" alt="HTTP请求响应模型"></p>
<p>HTTP通信机制是在一次完整的 HTTP 通信过程中，客户端与服务器之间将完成下列7个步骤：</p>
<ol>
<li><p><strong>建立 TCP 连接</strong><br>在HTTP工作开始之前，客户端首先要通过网络与服务器建立连接，该连接是通过 TCP 来完成的，该协议与 IP 协议共同构建 Internet，即著名的<br>TCP&#x2F;IP 协议族，因此 Internet 又被称作是 TCP&#x2F;IP 网络。HTTP 是比 TCP<br>更高层次的应用层协议，根据规则，只有低层协议建立之后，才能进行高层协议的连接，因此，首先要建立 TCP 连接，一般 TCP 连接的端口号是80；</p>
</li>
<li><p><strong>客户端向服务器发送请求命令</strong><br>一旦建立了TCP连接，客户端就会向服务器发送请求命令；<br>例如：<code>GET/sample/hello.jsp HTTP/1.1</code></p>
</li>
<li><p><strong>客户端发送请求头信息</strong><br>客户端发送其请求命令之后，还要以头信息的形式向服务器发送一些别的信息，之后客户端发送了一空白行来通知服务器，它已经结束了该头信息的发送；</p>
</li>
<li><p><strong>服务器应答</strong><br>客户端向服务器发出请求后，服务器会客户端返回响应；<br>例如： <code>HTTP/1.1 200 OK</code><br>响应的第一部分是协议的版本号和响应状态码</p>
</li>
<li><p><strong>服务器返回响应头信息</strong><br>正如客户端会随同请求发送关于自身的信息一样，服务器也会随同响应向用户发送关于它自己的数据及被请求的文档；</p>
</li>
<li><p><strong>服务器向客户端发送数据</strong><br>服务器向客户端发送头信息后，它会发送一个空白行来表示头信息的发送到此为结束，接着，它就以 Content-Type<br>响应头信息所描述的格式发送用户所请求的实际数据；</p>
</li>
<li><p><strong>服务器关闭 TCP 连接</strong><br>一般情况下，一旦服务器向客户端返回了请求数据，它就要关闭 TCP 连接，然后如果客户端或者服务器在其头信息加入了这行代码 <code>Connection:keep- alive</code> ，TCP<br>连接在发送后将仍然保持打开状态，于是，客户端可以继续通过相同的连接发送请求。保持连接节省了为每个请求建立新连接所需的时间，还节约了网络带宽。</p>
</li>
</ol>
<h2 id="HTTP协议基础"><a href="#HTTP协议基础" class="headerlink" title="HTTP协议基础"></a>HTTP协议基础</h2><h3 id="通过请求和响应的交换达成通信"><a href="#通过请求和响应的交换达成通信" class="headerlink" title="通过请求和响应的交换达成通信"></a>通过请求和响应的交换达成通信</h3><p>应用 HTTP 协议时，必定是一端担任客户端角色，另一端担任服务器端角色。仅从一条通信线路来说，服务器端和客服端的角色是确定的。HTTP<br>协议规定，请求从客户端发出，最后服务器端响应该请求并返回。 <strong>换句话说，肯定是先从客户端开始建立通信的，服务器端在没有接收到请求之前不会发送响应。</strong></p>
<h3 id="HTTP-是不保存状态的协议"><a href="#HTTP-是不保存状态的协议" class="headerlink" title="HTTP 是不保存状态的协议"></a>HTTP 是不保存状态的协议</h3><p>HTTP 是一种无状态协议。协议自身不对请求和响应之间的通信状态进行保存。也就是说在 HTTP<br>这个级别，协议对于发送过的请求或响应都不做持久化处理。这是为了更快地处理大量事务，确保协议的可伸缩性，而特意把 HTTP 协议设计成如此简单的。<br>可是随着 Web 的不断发展，我们的很多业务都需要对通信状态进行保存。于是我们引入了 Cookie 技术。有了 Cookie 再用 HTTP<br>协议通信，就可以管理状态了。</p>
<h3 id="使用-Cookie-的状态管理"><a href="#使用-Cookie-的状态管理" class="headerlink" title="使用 Cookie 的状态管理"></a>使用 Cookie 的状态管理</h3><p>Cookie 技术通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。Cookie 会根据从服务器端发送的响应报文内的一个叫做 Set-<br>Cookie 的首部字段信息，通知客户端保存Cookie。当下次客户端再往该服务器发送请求时，客户端会自动在请求报文中加入 Cookie<br>值后发送出去。服务器端发现客户端发送过来的 Cookie 后，会去检查究竟是从哪一个客户端发来的连接请求，然后对比服务器上的记录，最后得到之前的状态信息。</p>
<h3 id="持久连接"><a href="#持久连接" class="headerlink" title="持久连接"></a>持久连接</h3><p>HTTP 协议的初始版本中，每进行一个 HTTP 通信都要断开一次 TCP 连接。比如使用浏览器浏览一个包含多张图片的 HTML 页面时，在发送请求访问<br>HTML 页面资源的同时，也会请求该 HTML 页面里包含的其他资源。因此，每次的请求都会造成无畏的 TCP 连接建立和断开，增加通信量的开销。<br>为了解决上述 TCP 连接的问题，HTTP&#x2F;1.1 和部分 HTTP&#x2F;1.0 想出了持久连接的方法。 <strong>其特点是，只要任意一端没有明确提出断开连接，则保持<br>TCP 连接状态。旨在建立一次 TCP 连接后进行多次请求和响应的交互。</strong> 在 HTTP&#x2F;1.1 中，所有的连接默认都是持久连接。</p>
<h3 id="管线化"><a href="#管线化" class="headerlink" title="管线化"></a>管线化</h3><p>持久连接使得多数请求以管线化方式发送成为可能。以前发送请求后需等待并接收到响应，才能发送下一个请求。管线化技术出现后，不用等待亦可发送下一个请求。这样就能做到同时并行发送多个请求，而不需要一个接一个地等待响应了。<br>比如，当请求一个包含多张图片的 HTML<br>页面时，与挨个连接相比，用持久连接可以让请求更快结束。而管线化技术要比持久连接速度更快。请求数越多，时间差就越明显。</p>
<h2 id="HTTP报文结构"><a href="#HTTP报文结构" class="headerlink" title="HTTP报文结构"></a>HTTP报文结构</h2><h3 id="HTTP-报文"><a href="#HTTP-报文" class="headerlink" title="HTTP 报文"></a>HTTP 报文</h3><p>用于 HTTP 协议交互的信息被称为 HTTP 报文。请求端（客户端）的 HTTP 报文叫做请求报文；响应端（服务器端）的叫做响应报文。HTTP<br>报文本身是由多行（用 CR+LF 作换行符）数据构成的字符串文本。</p>
<h3 id="HTTP-报文结构"><a href="#HTTP-报文结构" class="headerlink" title="HTTP 报文结构"></a>HTTP 报文结构</h3><p>HTTP 报文大致可分为报文首部和报文主体两部分。两者由最初出现的空行（CR+LF）来划分。通常，并不一定有报文主体。如下：</p>
<p><img src="/images/HTTP%E6%8A%A5%E6%96%87%E7%BB%93%E6%9E%84.jpg" alt="HTTP报文结构"></p>
<h4 id="请求报文结构"><a href="#请求报文结构" class="headerlink" title="请求报文结构"></a>请求报文结构</h4><p><img src="/images/%E8%AF%B7%E6%B1%82%E6%8A%A5%E6%96%87%E7%BB%93%E6%9E%84.jpg" alt="请求报文结构"></p>
<p>请求报文的首部内容由以下数据组成：</p>
<ul>
<li><strong>请求行</strong> —— 包含用于请求的方法、请求 URI 和 HTTP 版本。</li>
<li><strong>首部字段</strong> —— 包含表示请求的各种条件和属性的各类首部。（通用首部、请求首部、实体首部以及RFC里未定义的首部如 Cookie 等）</li>
</ul>
<p>请求报文的示例，如：</p>
<p><img src="/images/%E8%AF%B7%E6%B1%82%E6%8A%A5%E6%96%87%E7%A4%BA%E4%BE%8B.jpg" alt="请求报文示例"></p>
<h4 id="响应报文结构"><a href="#响应报文结构" class="headerlink" title="响应报文结构"></a>响应报文结构</h4><p><img src="/images/%E5%93%8D%E5%BA%94%E6%8A%A5%E6%96%87%E7%BB%93%E6%9E%84.jpg" alt="响应报文结构"></p>
<p>响应报文的首部内容由以下数据组成：</p>
<ul>
<li><strong>状态行</strong> —— 包含表明响应结果的状态码、原因短语和 HTTP 版本。</li>
<li><strong>首部字段</strong> —— 包含表示请求的各种条件和属性的各类首部。（通用首部、响应首部、实体首部以及RFC里未定义的首部如 Cookie 等）</li>
</ul>
<p>响应报文的示例，如下：</p>
<p><img src="/images/%E5%93%8D%E5%BA%94%E6%8A%A5%E6%96%87%E7%A4%BA%E4%BE%8B.jpg" alt="响应报文示例"></p>
<h1 id="HTTPS"><a href="#HTTPS" class="headerlink" title="HTTPS"></a>HTTPS</h1><h2 id="HTTP的弊端"><a href="#HTTP的弊端" class="headerlink" title="HTTP的弊端"></a>HTTP的弊端</h2><p>HTTP 之所以被 HTTPS 取代，最大的原因就是不安全，至于为什么不安全，看了下面这张图就一目了然了。</p>
<p><img src="/images/HTTP%E4%BC%A0%E8%BE%93%E8%BF%87%E7%A8%8B.png" alt="HTTP传输过程"></p>
<p>由图可见，HTTP<br>在传输数据的过程中，所有的数据都是明文传输，自然没有安全性可言，特别是一些敏感数据，比如用户密码和信用卡信息等，一旦被第三方获取，后果不堪设想。</p>
<h2 id="加密算法"><a href="#加密算法" class="headerlink" title="加密算法"></a>加密算法</h2><p>HTTPS<br>解决数据传输安全问题的方案就是使用加密算法，具体来说是混合加密算法，也就是对称加密和非对称加密的混合使用，这里有必要先了解一下这两种加密算法的区别和优缺点。</p>
<h3 id="对称加密"><a href="#对称加密" class="headerlink" title="对称加密"></a>对称加密</h3><p>对称加密，顾名思义就是加密和解密都是使用同一个密钥，常见的对称加密算法有 DES、3DES 和 AES 等，其优缺点如下：</p>
<ul>
<li><p>优点：算法公开、计算量小、加密速度快、加密效率高，适合加密比较大的数据。</p>
</li>
<li><p>缺点：</p>
</li>
<li><ol>
<li>交易双方需要使用相同的密钥，也就无法避免密钥的传输，而密钥在传输过程中无法保证不被截获，因此对称加密的安全性得不到保证。</li>
</ol>
</li>
<li><ol start="2">
<li>每对用户每次使用对称加密算法时，都需要使用其他人不知道的惟一密钥，这会使得发收信双方所拥有的钥匙数量急剧增长，密钥管理成为双方的负担。对称加密算法在分布式网络系统上使用较为困难，主要是因为密钥管理困难，使用成本较高。</li>
</ol>
</li>
</ul>
<p>如果直接将对称加密算法用在 HTTP 中，会是下面的效果：</p>
<p><img src="/images/%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86%E4%BC%A0%E8%BE%93%E8%BF%87%E7%A8%8B.png" alt="对称加密传输过程"></p>
<p>从图中可以看出，被加密的数据在传输过程中是无规则的乱码，即便被第三方截获，在没有密钥的情况下也无法解密数据，也就保证了数据的安全。但是有一个致命的问题，那就是既然双方要使用相同的密钥，那就必然要在传输数据之前先由一方把密钥传给另一方，那么在此过程中密钥就很有可能被截获，这样一来加密的数据也会被轻松解密。那如何确保密钥在传输过程中的安全呢？这就要用到非对称加密了。</p>
<h3 id="非对称加密"><a href="#非对称加密" class="headerlink" title="非对称加密"></a>非对称加密</h3><p>非对称加密，顾名思义，就是加密和解密需要使用两个不同的密钥：公钥（public key）和私钥（private<br>key）。公钥与私钥是一对，如果用公钥对数据进行加密，只有用对应的私钥才能解密；如果用私钥对数据进行加密，那么只有用对应的公钥才能解密。非对称加密算法实现机密信息交换的基本过程是：甲方生成一对密钥并将其中的一把作为公钥对外公开；得到该公钥的乙方使用公钥对机密信息进行加密后再发送给甲方；甲方再用自己保存的私钥对加密后的信息进行解密。如果对公钥和私钥不太理解，可以想象成一把钥匙和一个锁头，只是全世界只有你一个人有这把钥匙，你可以把锁头给别人，别人可以用这个锁把重要的东西锁起来，然后发给你，因为只有你一个人有这把钥匙，所以只有你才能看到被这把锁锁起来的东西。常用的非对称加密算法是<br>RSA 算法，其优缺点如下：</p>
<ul>
<li>优点：算法公开，加密和解密使用不同的钥匙，私钥不需要通过网络进行传输，安全性很高。</li>
<li>缺点：计算量比较大，加密和解密速度相比对称加密慢很多。</li>
</ul>
<p>由于非对称加密的强安全性，可以用它完美解决对称加密的密钥泄露问题，效果图如下：</p>
<p><img src="/images/%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86%E5%8F%91%E9%80%81KEY%E7%9A%84%E8%BF%87%E7%A8%8B.png" alt="非对称加密发送 KEY
的过程"></p>
<p>在上述过程中，客户端在拿到服务器的公钥后，会生成一个随机码 (用 KEY 表示，这个 KEY 就是后续双方用于对称加密的密钥)，然后客户端使用公钥把 KEY<br>加密后再发送给服务器，服务器使用私钥将其解密，这样双方就有了同一个密钥 KEY，然后双方再使用 KEY 进行对称加密交互数据。在非对称加密传输 KEY<br>的过程中，即便第三方获取了公钥和加密后的 KEY，在没有私钥的情况下也无法破解 KEY<br>(私钥存在服务器，泄露风险极小)，也就保证了接下来对称加密的数据安全。而上面这个流程图正是 HTTPS 的雏形，HTTPS<br>正好综合了这两种加密算法的优点，不仅保证了通信安全，还保证了数据传输效率。</p>
<h2 id="HTTPS原理详解"><a href="#HTTPS原理详解" class="headerlink" title="HTTPS原理详解"></a>HTTPS原理详解</h2><p>HTTPS 并非独立的通信协议，而是对 HTTP 的扩展，保证了通信安全，二者关系如下：</p>
<p><img src="/images/HTTP%E5%92%8CHTTPS%E7%9A%84%E5%85%B3%E7%B3%BB.png" alt="HTTP和HTTPS的关系"></p>
<p>也就是说 HTTPS &#x3D; HTTP + SSL &#x2F; TLS。</p>
<p>接下来就是最重要的 HTTPS 原理解析了，老规矩先上图</p>
<p><img src="/images/HTTPS%E5%8A%A0%E5%AF%86%E3%80%81%E8%A7%A3%E5%AF%86%E3%80%81%E9%AA%8C%E8%AF%81%E5%8F%8A%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E8%BF%87%E7%A8%8B.png" alt="HTTPS
加密、解密、验证及数据传输过程"></p>
<p>HTTPS 的整个通信过程可以分为两大阶段：证书验证和数据传输阶段，数据传输阶段又可以分为非对称加密和对称加密两个阶段。具体流程按图中的序号讲解。</p>
<ol>
<li><p>客户端请求 HTTPS 网址，然后连接到 server 的 443 端口 (HTTPS 默认端口，类似于 HTTP 的80端口)。</p>
</li>
<li><p>采用 HTTPS 协议的服务器必须要有一套数字 CA (Certification Authority)证书，证书是需要申请的，并由专门的数字证书认证机构(CA)通过非常严格的审核之后颁发的电子证书 (当然了是要钱的，安全级别越高价格越贵)。颁发证书的同时会产生一个私钥和公钥。私钥由服务端自己保存，不可泄漏。公钥则是附带在证书的信息中，可以公开的。证书本身也附带一个证书电子签名，这个签名用来验证证书的完整性和真实性，可以防止证书被篡改。</p>
</li>
<li><p>服务器响应客户端请求，将证书传递给客户端，证书包含公钥和大量其他信息，比如证书颁发机构信息，公司信息和证书有效期等。Chrome 浏览器点击地址栏的锁标志再点击证书就可以看到证书详细信息。</p>
</li>
</ol>
<p>![CA 证书](&#x2F;images&#x2F;CA 证书.png)</p>
<ol start="4">
<li>客户端解析证书并对其进行验证。如果证书没有问题，客户端就会从服务器证书中取出服务器的公钥A。然后客户端还会生成一个随机码 KEY，并使用公钥A将其加密。如果证书不是可信机构颁布，或者证书中的域名与实际域名不一致，或者证书已经过期，就会向访问者显示一个警告，由其选择是否还要继续通信。就像下面这样：</li>
</ol>
<p><img src="/images/%E6%B5%8F%E8%A7%88%E5%99%A8%E5%AE%89%E5%85%A8%E8%AD%A6%E5%91%8A.png" alt="浏览器安全警告"></p>
<ol start="5">
<li><p>客户端把加密后的随机码 KEY 发送给服务器，作为后面对称加密的密钥。</p>
</li>
<li><p>服务器在收到随机码 KEY 之后会使用私钥B将其解密。经过以上这些步骤，客户端和服务器终于建立了安全连接，完美解决了对称加密的密钥泄露问题，接下来就可以用对称加密愉快地进行通信了。</p>
</li>
<li><p>服务器使用密钥 (随机码 KEY)对数据进行对称加密并发送给客户端，客户端使用相同的密钥 (随机码 KEY)解密数据。</p>
</li>
<li><p>双方使用对称加密愉快地传输所有数据。</p>
</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p> <strong>HTTPS 和 HTTP 的区别：</strong></p>
<ul>
<li>最最重要的区别就是安全性，HTTP 明文传输，不对数据进行加密安全性较差。HTTPS (HTTP + SSL &#x2F; TLS)的数据传输过程是加密的，安全性较好。</li>
<li>使用 HTTPS 协议需要申请 CA 证书，一般免费证书较少，因而需要一定费用。证书颁发机构如：Symantec、Comodo、DigiCert 和 GlobalSign 等。</li>
<li>HTTP 页面响应速度比 HTTPS 快，这个很好理解，由于加了一层安全层，建立连接的过程更复杂，也要交换更多的数据，难免影响速度。</li>
<li>由于 HTTPS 是建构在 SSL &#x2F; TLS 之上的 HTTP 协议，所以，要比 HTTP 更耗费服务器资源。</li>
<li>HTTPS 和 HTTP 使用的是完全不同的连接方式，用的端口也不一样，前者是 443，后者是 80。</li>
</ul>
<p><strong>HTTPS 的缺点：</strong></p>
<ul>
<li>在相同网络环境中，HTTPS 相比 HTTP 无论是响应时间还是耗电量都有大幅度上升。</li>
<li>HTTPS 的安全是有范围的，在黑客攻击、服务器劫持等情况下几乎起不到作用。</li>
<li>在现有的证书机制下，中间人攻击依然有可能发生。</li>
<li>HTTPS 需要更多的服务器资源，也会导致成本的升高。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/01/13/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/RPC%E5%92%8CHTTP%E8%B0%83%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="merric">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Myoboku">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Myoboku">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/01/13/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/RPC%E5%92%8CHTTP%E8%B0%83%E7%94%A8/" class="post-title-link" itemprop="url">RPC和HTTP调用对比</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-01-13 22:30:00" itemprop="dateCreated datePublished" datetime="2020-01-13T22:30:00+00:00">2020-01-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">计算机网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>现在的公司基本上都是HTTP调用，个别服务会有RPC，突然发现之前自己知道这两个调用方式是不同的，具体有哪些不同还有点模糊，了解了之后发现难怪大厂都用RPC调用，包括gRPC和dubbo。</p>
<p>先说一下他们最本质的区别，就是RPC主要是基于TCP&#x2F;IP协议的，而HTTP服务主要是基于HTTP协议的，我们都知道HTTP协议是在传输层协议TCP之上的，所以效率来看的话，RPC当然是要更胜一筹啦！当然RPC也可以用HTTP调用，像Feign，不过也因此他被叫做伪RPC。下面来具体说一说RPC服务和HTTP服务。</p>
<h1 id="RPC服务"><a href="#RPC服务" class="headerlink" title="RPC服务"></a>RPC服务</h1><h2 id="RPC架构"><a href="#RPC架构" class="headerlink" title="RPC架构"></a>RPC架构</h2><p>一个完整的RPC架构里面包含了四个核心的组件，分别是Client ,Server,Client Stub以及Server<br>Stub，这个Stub大家可以理解为存根。分别说说这几个组件：</p>
<ul>
<li>客户端（Client），服务的调用方。</li>
<li>服务端（Server），真正的服务提供者。<br>客户端存根，存放服务端的地址消息，再将客户端的请求参数打包成网络消息，然后通过网络远程发送给服务方。<br>服务端存根，接收客户端发送过来的消息，将消息解包，并调用本地的方法。</li>
</ul>
<p><img src="/images/RPC%E6%9E%B6%E6%9E%84.jpeg" alt="RPC架构"></p>
<p>RPC主要是用在大型企业里面，因为大型企业里面系统繁多，业务线复杂，而且效率优势非常重要的一块，这个时候RPC的优势就比较明显了。实际的开发当中是这么做的，项目一般使用maven来管理。</p>
<p>比如我们有一个处理订单的系统服务，先声明它的所有的接口（这里就是具体指Java中的interface），然后将整个项目打包为一个jar包，服务端这边引入这个二方库，然后实现相应的功能，客户端这边也只需要引入这个二方库即可调用了。</p>
<p>为什么这么做？主要是为了减少客户端这边的jar包大小，因为每一次打包发布的时候，jar包太多总是会影响效率。另外也是将客户端和服务端解耦，提高代码的可移植性。</p>
<h2 id="同步调用和异步调用"><a href="#同步调用和异步调用" class="headerlink" title="同步调用和异步调用"></a>同步调用和异步调用</h2><p>同步调用就是客户端等待调用执行完成并返回结果。异步调用就是客户端不等待调用执行完成返回结果，不过依然可以通过回调函数等接收到返回结果的通知。如果客户端并不关心结果，则可以变成一个单向的调用。</p>
<p>这个过程有点类似于Java中的callable和runnable接口，我们进行异步执行的时候，如果需要知道执行的结果，就可以使用callable接口，并且可以通过Future类获取到异步执行的结果信息。如果不关心执行的结果，直接使用runnable接口就可以了，因为它不返回结果，当然啦，callable也是可以的，我们不去获取Future就可以了。</p>
<h2 id="流行的RPC框架"><a href="#流行的RPC框架" class="headerlink" title="流行的RPC框架"></a>流行的RPC框架</h2><ol>
<li>gRPC是Google最近公布的开源软件，基于最新的HTTP2.0协议，并支持常见的众多编程语言。我们知道HTTP2.0是基于二进制的HTTP协议升级版本，目前各大浏览器都在快马加鞭的加以支持。这个RPC框架是基于HTTP协议实现的，底层使用到了Netty框架的支持。下面放两个文档</li>
</ol>
<p><a target="_blank" rel="noopener" href="https://doc.oschina.net/grpc?t=56831">https://doc.oschina.net/grpc?t=56831</a></p>
<p><a target="_blank" rel="noopener" href="https://www.grpc.io/docs/">https://www.grpc.io/docs/</a></p>
<ol>
<li>Thrift是Facebook的一个开源项目，主要是一个跨语言的服务开发框架。它有一个代码生成器来对它所定义的IDL定义文件自动生成服务代码框架。用户只要在其之前进行二次开发就行，对于底层的RPC通讯等都是透明的。不过这个对于用户来说的话需要学习特定领域语言这个特性，还是有一定成本的。</li>
<li>Dubbo是阿里集团开源的一个极为出名的RPC框架，在很多互联网公司和企业应用中广泛使用。协议和序列化框架都可以插拔是及其鲜明的特色。同样 的远程接口是基于Java Interface，并且依托于spring框架方便开发。可以方便的打包成单一文件，独立进程运行，和现在的微服务概念一致。</li>
</ol>
<p><a target="_blank" rel="noopener" href="http://dubbo.apache.org/zh-cn/docs/user/quick-start.html">http://dubbo.apache.org/zh-cn/docs/user/quick-start.html</a></p>
<p>关于gRPC和Dubbo暂时可能不会写文章总结，因为文档足够详细，自己也还没看完，等看完了并且有了超出文档的理解再进行总结。</p>
<h1 id="HTTP服务"><a href="#HTTP服务" class="headerlink" title="HTTP服务"></a>HTTP服务</h1><p>其实在很久以前，我对于企业开发的模式一直定性为HTTP接口开发，也就是我们常说的RESTful风格的服务接口。的确，对于在接口不多、系统与系统交互较少的情况下，解决信息孤岛初期常使用的一种通信手段；优点就是简单、直接、开发方便。</p>
<p>利用现成的http协议进行传输。我们记得之前实习在公司做后台开发的时候，主要就是进行接口的开发，还要写一大份接口文档，严格地标明输入输出是什么？说清楚每一个接口的请求方法，以及请求参数需要注意的事项等。</p>
<p>接口可能返回一个JSON字符串或者是XML文档。然后客户端再去处理这个返回的信息，从而可以比较快速地进行开发。</p>
<p>但是对于大型企业来说，内部子系统较多、接口非常多的情况下，RPC框架的好处就显示出来了，首先就是长链接，不必每次通信都要像http一样去3次握手什么的，减少了网络开销，虽然HTTP1.1之后也可以长连接了；</p>
<p>其次就是RPC框架一般都有注册中心，有丰富的监控管理；发布、下线接口、动态扩展等，对调用方来说是无感知、统一化的操作。</p>
<h2 id="顺便总结下HTTP版本差别"><a href="#顺便总结下HTTP版本差别" class="headerlink" title="顺便总结下HTTP版本差别"></a>顺便总结下HTTP版本差别</h2><h3 id="HTTP-0-9"><a href="#HTTP-0-9" class="headerlink" title="HTTP 0.9"></a>HTTP 0.9</h3><p>HTTP 0.9 是一个最古老的版本</p>
<ul>
<li>只支持<code>GET</code>请求方式：由于不支持其他请求方式，因此客户端是没办法向服务端传输太多的信息</li>
<li>没有请求头概念：所以不能在请求中指定版本号，服务端也只具有返回 HTML字符串的能力</li>
<li>服务端相响应之后，立即关闭TCP连接</li>
</ul>
<h3 id="HTTP-1-0"><a href="#HTTP-1-0" class="headerlink" title="HTTP 1.0"></a>HTTP 1.0</h3><p>随着 HTTP 1.0 的发布，这个版本:</p>
<ul>
<li>请求方式新增了POST，DELETE，PUT，HEADER等方式</li>
<li>增添了请求头和响应头的概念，在通信中指定了 HTTP 协议版本号，以及其他的一些元信息 (比如: 状态码、权限、缓存、内容编码)</li>
<li>扩充了传输内容格式，图片、音视频资源、二进制等都可以进行传输</li>
</ul>
<p>在这个版本主要的就是对请求和响应的元信息进行了扩展，客户端和服务端有更多的获取当前请求的所有信息，进而更好更快的处理请求相关内容。</p>
<h4 id="请求头"><a href="#请求头" class="headerlink" title="请求头"></a>请求头</h4><p>一个简单请求的头信息</p>
<pre><code>GET / HTTP/1.0  
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5)  
Accept: */*  
</code></pre>
<p>可以看到在请求方法之后有 请求资源的位置 + 请求协议版本，之后是一些客户端的信息配置</p>
<h4 id="响应头"><a href="#响应头" class="headerlink" title="响应头"></a>响应头</h4><p>一个简单响应的头信息(v1.0)</p>
<pre><code>HTTP/1.0 200 OK  
Content-Type: text/plain  
Content-Length: 137582  
Expires: Thu, 05 Dec 1997 16:00:00 GMT  
Last-Modified: Wed, 5 August 1996 15:55:28 GMT  
// 这是一个空行  
...数据内容  
</code></pre>
<p>服务端的响应头第一个就是 请求协议版本，后面紧跟着是这次请求的状态码、以及状态码的描述，之后的内容是一些关于返回内容的描述。</p>
<p><strong>Content-Type</strong></p>
<p>在 HTTP 1.0 的时候，任何的资源都可以被传输，传输的格式呢也是多种多样的，客户端在收到响应体的内容的时候就是根据这个 <code>Content-Type</code><br>去进行解析的。所以服务端返回时候必须带着这个字段。</p>
<p>一些常见的 <code>Content-Type</code> 可以参考 <a target="_blank" rel="noopener" href="http://tool.oschina.net/commons/">对照表</a>。 这些<br><code>Content-Type</code> 有一个总称叫做<code>MIME type</code>。</p>
<p>关于<code>MIME type</code>，这里想播插一个小插曲:</p>
<blockquote>
<p>在 chrome 浏览器中，当跨域请求回来的数据 MIME type 同跨域标签应有的 MIME type 不匹配时，浏览器会启动 CORB<br>保护数据不被泄漏。被保护的数据有: html、xml、json。(eg: script、img 标签所支持的 MIME<br>type和他们都不一致)，所以服务端在返回资源的时候一定要对应返回正确的 <code>Content-Type</code>，以免浏览器屏蔽返回结果。</p>
</blockquote>
<h4 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h4><ul>
<li>无状态：服务器不跟踪不记录请求过的状态</li>
<li>无连接：浏览器每次请求都需要建立tcp连接</li>
</ul>
<h5 id="无状态"><a href="#无状态" class="headerlink" title="无状态"></a>无状态</h5><p>对于无状态的特性可以借助cookie&#x2F;session机制来做身份认证和状态记录</p>
<h5 id="无连接"><a href="#无连接" class="headerlink" title="无连接"></a>无连接</h5><p>无连接导致的性能缺陷有两种：</p>
<ul>
<li><p>无法复用连接<br>每次发送请求，都需要进行一次tcp连接（即3次握手4次挥手），使得网络的利用率非常低</p>
</li>
<li><p>队头阻塞<br>HTTP 1.0 规定在前一个请求响应到达之后下一个请求才能发送，如果前一个阻塞，后面的请求也给阻塞的</p>
</li>
</ul>
<h3 id="HTTP-1-1"><a href="#HTTP-1-1" class="headerlink" title="HTTP 1.1"></a>HTTP 1.1</h3><p>HTTP 1.1 是在 1.0 发布之后的半年就推出了，完善了 1.0 版本。目前也还有很多的互联网项目基于 HTTP 1.1 在向外提供服务。</p>
<h4 id="特性-1"><a href="#特性-1" class="headerlink" title="特性"></a>特性</h4><ul>
<li>长连接：新增Connection字段，可以设置keep-alive值保持连接不断开</li>
<li>管道化：基于上面长连接的基础，管道化可以不等第一个请求响应继续发送后面的请求，但响应的顺序还是按照请求的顺序返回</li>
<li>缓存处理：新增字段cache-control</li>
<li>断点传输</li>
</ul>
<h5 id="长连接"><a href="#长连接" class="headerlink" title="长连接"></a>长连接</h5><p>HTTP 1.1默认保持长连接，数据传输完成保持tcp连接不断开,继续用这个通道传输数据</p>
<h5 id="管道化"><a href="#管道化" class="headerlink" title="管道化"></a>管道化</h5><p>基于长连接的基础，我们先看没有管道化请求响应：</p>
<p>tcp没有断开，用的同一个通道</p>
<pre><code>请求1 &gt; 响应1 --&gt; 请求2 &gt; 响应2 --&gt; 请求3 &gt; 响应3  
  
</code></pre>
<p>管道化的请求响应：</p>
<pre><code>请求1 --&gt; 请求2 --&gt; 请求3 &gt; 响应1 --&gt; 响应2 --&gt; 响应3  
</code></pre>
<p>即使服务器先准备好响应2,也是按照请求顺序先返回响应1</p>
<p>虽然管道化，可以一次发送多个请求，但是响应仍是顺序返回，仍然无法解决队头阻塞的问题</p>
<h4 id="缓存处理"><a href="#缓存处理" class="headerlink" title="缓存处理"></a>缓存处理</h4><p>当浏览器请求资源时，先看是否有缓存的资源，如果有缓存，直接取，不会再发请求，如果没有缓存，则发送请求。 通过设置字段cache-control来控制缓存。</p>
<h4 id="断点传输"><a href="#断点传输" class="headerlink" title="断点传输"></a>断点传输</h4><p>在上传&#x2F;下载资源时，如果资源过大，将其分割为多个部分，分别上传&#x2F;下载，如果遇到网络故障，可以从已经上传&#x2F;下载好的地方继续请求，不用从头开始，提高效率</p>
<h3 id="HTTP-2"><a href="#HTTP-2" class="headerlink" title="HTTP 2"></a>HTTP 2</h3><p>2015 年，HTTP&#x2F;2 发布。HTTP&#x2F;2 是现行 HTTP 协议（HTTP&#x2F;1.x）的替代，但它不是重写，HTTP 方法&#x2F;状态码&#x2F;语义都与<br>HTTP&#x2F;1.x 一样。HTTP&#x2F;2 基于 SPDY3，专注于 <strong>性能</strong> ，最大的一个目标是在用户和网站间只用一个连接（connection）。</p>
<p>HTTP&#x2F;2 由两个规范（Specification）组成：</p>
<ol>
<li><p>Hypertext Transfer Protocol version 2 - RFC7540</p>
</li>
<li><p>HPACK - Header Compression for HTTP&#x2F;2 - RFC7541</p>
</li>
</ol>
<h4 id="二进制分帧"><a href="#二进制分帧" class="headerlink" title="二进制分帧"></a>二进制分帧</h4><p>HTTP&#x2F;2 采用二进制格式传输数据，而非 HTTP 1.x 的文本格式，二进制协议解析起来更高效。 HTTP &#x2F; 1<br>的请求和响应报文，都是由起始行，首部和实体正文（可选）组成，各部分之间以文本换行符分隔。 <strong>HTTP&#x2F;2<br>将请求和响应数据分割为更小的帧，并且它们采用二进制编码</strong> 。</p>
<p>接下来我们介绍几个重要的概念：</p>
<ul>
<li>流：流是连接中的一个虚拟信道，可以承载双向的消息；每个流都有一个唯一的整数标识符（1、2…N）；</li>
<li>消息：是指逻辑上的 HTTP 消息，比如请求、响应等，由一或多个帧组成。</li>
<li>帧：HTTP 2.0 通信的最小单位，每个帧包含帧首部，至少也会标识出当前帧所属的流，承载着特定类型的数据，如 HTTP 首部、负荷，等等</li>
</ul>
<p><img src="/images/HTTP2%E4%BA%8C%E8%BF%9B%E5%88%B6%E4%BC%A0%E8%BE%93.png" alt="HTTP2二进制传输"></p>
<p>HTTP&#x2F;2<br>中，同域名下所有通信都在单个连接上完成，该连接可以承载任意数量的双向数据流。每个数据流都以消息的形式发送，而消息又由一个或多个帧组成。多个帧之间可以乱序发送，根据帧首部的流标识可以重新组装。</p>
<h4 id="多路复用"><a href="#多路复用" class="headerlink" title="多路复用"></a>多路复用</h4><p>在 HTTP&#x2F;2 中引入了多路复用的技术。多路复用很好的解决了浏览器限制同一个域名下的请求数量的问题，同时也接更容易实现全速传输，毕竟新开一个 TCP<br>连接都需要慢慢提升传输速度。</p>
<p>大家可以通过 <a target="_blank" rel="noopener" href="https://http2.akamai.com/demo">该链接</a> 直观感受下 HTTP&#x2F;2 比 HTTP&#x2F;1 到底快了多少。</p>
<p><img src="/images/HTTP2%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8.gif" alt="HTTP2多路复用"></p>
<p>在 HTTP&#x2F;2 中，有了二进制分帧之后，HTTP &#x2F;2 不再依赖 TCP 链接去实现多流并行了，在 HTTP&#x2F;2 中：</p>
<ul>
<li>同域名下所有通信都在单个连接上完成。</li>
<li>单个连接可以承载任意数量的双向数据流。</li>
<li>数据流以消息的形式发送，而消息又由一个或多个帧组成，多个帧之间可以乱序发送，因为根据帧首部的流标识可以重新组装。</li>
</ul>
<p>这一特性，使性能有了极大提升：</p>
<ul>
<li>同个域名只需要占用一个 TCP 连接，使用一个连接并行发送多个请求和响应,消除了因多个 TCP 连接而带来的延时和内存消耗。</li>
<li>并行交错地发送多个请求，请求之间互不影响。</li>
<li>并行交错地发送多个响应，响应之间互不干扰。</li>
<li>在 HTTP&#x2F;2 中，每个请求都可以带一个 31bit 的优先值，0 表示最高优先级， 数值越大优先级越低。有了这个优先值，客户端和服务器就可以在处理不同的流时采取不同的策略，以最优的方式发送流、消息和帧。</li>
</ul>
<p><img src="/images/HTTP2%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8.png" alt="HTTP2多路复用"></p>
<p>如上图所示，多路复用的技术可以只通过一个 TCP 连接就可以传输所有的请求数据。</p>
<h4 id="头部压缩"><a href="#头部压缩" class="headerlink" title="头部压缩"></a>头部压缩</h4><p>在 HTTP&#x2F;1 中，我们使用文本的形式传输 header，在 header 携带 cookie 的情况下，可能每次都需要重复传输几百到几千的字节。</p>
<p>为了减少这块的资源消耗并提升性能， HTTP&#x2F;2 对这些首部采取了压缩策略：</p>
<ul>
<li>HTTP&#x2F;2 在客户端和服务器端使用“首部表”来跟踪和存储之前发送的键－值对，对于相同的数据，不再通过每次请求和响应发送；</li>
<li>首部表在 HTTP&#x2F;2 的连接存续期内始终存在，由客户端和服务器共同渐进地更新;</li>
<li>每个新的首部键－值对要么被追加到当前表的末尾，要么替换表中之前的值</li>
</ul>
<p>例如下图中的两个请求， 请求一发送了所有的头部字段，第二个请求则只需要发送差异数据，这样可以减少冗余数据，降低开销</p>
<p><img src="/images/HTTP2%E5%A4%B4%E9%83%A8%E5%8E%8B%E7%BC%A9.png" alt="HTTP2头部压缩"></p>
<h4 id="服务端推送"><a href="#服务端推送" class="headerlink" title="服务端推送"></a>服务端推送</h4><p>Server Push 即服务端能通过 push 的方式将客户端需要的内容预先推送过去，也叫“cache push”。</p>
<p>可以想象以下情况，某些资源客户端是一定会请求的，这时就可以采取服务端 push<br>的技术，提前给客户端推送必要的资源，这样就可以相对减少一点延迟时间。当然在浏览器兼容的情况下你也可以使用 prefetch。<br>例如服务端可以主动把 JS 和 CSS 文件推送给客户端，而不需要客户端解析 HTML 时再发送这些请求。</p>
<p><img src="/images/HTTP2%E6%9C%8D%E5%8A%A1%E6%8E%A8%E9%80%81.png" alt="HTTP2服务推送"></p>
<p>服务端可以主动推送，客户端也有权利选择是否接收。如果服务端推送的资源已经被浏览器缓存过，浏览器可以通过发送 RST_STREAM<br>帧来拒收。主动推送也遵守同源策略，换句话说，服务器不能随便将第三方资源推送给客户端，而必须是经过双方确认才行。</p>
<h3 id="HTTP3"><a href="#HTTP3" class="headerlink" title="HTTP3"></a>HTTP3</h3><p>虽然 HTTP&#x2F;2 解决了很多之前旧版本的问题，但是它还是存在一个巨大的问题，主要是底层支撑的 TCP 协议造成的。</p>
<p>上文提到 HTTP&#x2F;2 使用了多路复用，一般来说同一域名下只需要使用一个 TCP 连接。但当这个连接中出现了丢包的情况，那就会导致 HTTP&#x2F;2<br>的表现情况反倒不如 HTTP&#x2F;1 了。</p>
<p>因为在出现丢包的情况下，整个 TCP 都要开始等待重传，也就导致了后面的所有数据都被阻塞了。但是对于 HTTP&#x2F;1.1 来说，可以开启多个 TCP<br>连接，出现这种情况反到只会影响其中一个连接，剩余的 TCP 连接还可以正常传输数据。</p>
<p>那么可能就会有人考虑到去修改 TCP 协议，其实这已经是一件不可能完成的任务了。因为 TCP<br>存在的时间实在太长，已经充斥在各种设备中，并且这个协议是由操作系统实现的，更新起来不大现实。</p>
<p>基于这个原因， <strong>Google 就更起炉灶搞了一个基于 UDP 协议的 QUIC 协议，并且使用在了 HTTP&#x2F;3 上</strong> ，HTTP&#x2F;3 之前名为<br>HTTP-over-QUIC，从这个名字中我们也可以发现，HTTP&#x2F;3 最大的改造就是使用了 QUIC。</p>
<p>QUIC 虽然基于 UDP，但是在原本的基础上新增了很多功能，接下来我们重点介绍几个 QUIC 新功能。</p>
<h4 id="0RTT"><a href="#0RTT" class="headerlink" title="0RTT"></a>0RTT</h4><p>通过使用类似 TCP 快速打开的技术，缓存当前会话的上下文，在下次恢复会话的时候，只需要将之前的缓存传递给服务端验证通过就可以进行传输了。 <strong>0RTT<br>建连可以说是 QUIC 相比 HTTP2 最大的性能优势</strong> 。那什么是 0RTT 建连呢？</p>
<p>这里面有两层含义:</p>
<ul>
<li>传输层 0RTT 就能建立连接。</li>
<li>加密层 0RTT 就能建立加密连接。</li>
</ul>
<p><img src="/images/HTTPS%E5%92%8CQUIC%E5%BB%BA%E7%AB%8B%E8%BF%87%E7%A8%8B.png" alt="HTTPS和QUIC建立过程"></p>
<p>上图左边是 HTTPS 的一次完全握手的建连过程，需要 3 个 RTT。就算是会话复用也需要至少 2 个 RTT。</p>
<p>而 QUIC 呢？由于建立在 UDP 的基础上，同时又实现了 0RTT 的安全握手，所以在大部分情况下，只需要 0 个 RTT<br>就能实现数据发送，在实现前向加密的基础上，并且 0RTT 的成功率相比 TLS 的会话记录单要高很多。</p>
<h4 id="多路复用-1"><a href="#多路复用-1" class="headerlink" title="多路复用"></a>多路复用</h4><p>虽然 HTTP&#x2F;2 支持了多路复用，但是 TCP 协议终究是没有这个功能的。QUIC<br>原生就实现了这个功能，并且传输的单个数据流可以保证有序交付且不会影响其他的数据流，这样的技术就解决了之前 TCP 存在的问题。</p>
<p>同 HTTP2.0 一样，同一条 QUIC 连接上可以创建多个 stream，来发送多个 HTTP 请求，但是，QUIC 是基于 UDP<br>的，一个连接上的多个 stream 之间没有依赖。比如下图中 stream2 丢了一个 UDP 包，不会影响后面跟着 Stream3 和<br>Stream4，不存在 TCP 队头阻塞。虽然 stream2 的那个包需要重新传，但是 stream3、stream4 的包无需等待，就可以发给用户。</p>
<p><img src="/images/QUIC%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8.png" alt="QUIC多路复用"></p>
<p>另外 QUIC 在移动端的表现也会比 TCP 好。因为 TCP 是基于 IP 和端口去识别连接的，这种方式在多变的移动端网络环境下是很脆弱的。但是 QUIC<br>是通过 ID 的方式去识别一个连接，不管你网络环境如何变化，只要 ID 不变，就能迅速重连上。</p>
<h4 id="加密认证的报文"><a href="#加密认证的报文" class="headerlink" title="加密认证的报文"></a>加密认证的报文</h4><p>TCP<br>协议头部没有经过任何加密和认证，所以在传输过程中很容易被中间网络设备篡改，注入和窃听。比如修改序列号、滑动窗口。这些行为有可能是出于性能优化，也有可能是主动攻击。</p>
<p>但是 QUIC 的 packet 可以说是武装到了牙齿。除了个别报文比如 PUBLIC_RESET 和 CHLO，所有报文头部都是经过认证的，报文 Body<br>都是经过加密的。</p>
<p>这样只要对 QUIC 报文任何修改，接收端都能够及时发现，有效地降低了安全风险。</p>
<p><img src="/images/%E6%8A%A5%E6%96%87%E5%A4%B4%E9%83%A8.png" alt="报文头部"></p>
<p>如上图所示，红色部分是 Stream Frame 的报文头部，有认证。绿色部分是报文内容，全部经过加密。</p>
<h4 id="向前纠错机制"><a href="#向前纠错机制" class="headerlink" title="向前纠错机制"></a>向前纠错机制</h4><p>QUIC 协议有一个非常独特的特性，称为向前纠错 (Forward Error<br>Correction，FEC)，每个数据包除了它本身的内容之外，还包括了部分其他数据包的数据，因此少量的丢包可以通过其他包的冗余数据直接组装而无需重传。向前纠错牺牲了每个数据包可以发送数据的上限，但是减少了因为丢包导致的数据重传，因为数据重传将会消耗更多的时间(包括确认数据包丢失、请求重传、等待新数据包等步骤的时间消耗)</p>
<p>假如说这次我要发送三个包，那么协议会算出这三个包的异或值并单独发出一个校验包，也就是总共发出了四个包。当出现其中的非校验包丢包的情况时，可以通过另外三个包计算出丢失的数据包的内容。<br><strong>当然这种技术只能使用在丢失一个包的情况下，如果出现丢失多个包就不能使用纠错机制了，只能使用重传的方式了</strong> 。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/01/10/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="merric">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Myoboku">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Myoboku">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/01/10/hello-world/" class="post-title-link" itemprop="url">Hello World</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-01-10 22:53:43" itemprop="dateCreated datePublished" datetime="2020-01-10T22:53:43+00:00">2020-01-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E9%9A%8F%E7%AC%94/" itemprop="url" rel="index"><span itemprop="name">随笔</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>hello hexo</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="Previous page" aria-label="Previous page" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2020 – 
    <span itemprop="copyrightYear">2023</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">merric</span>
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/next-boot.js"></script>

  






  





</body>
</html>
