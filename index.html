<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.18.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":false,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="Myoboku">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Myoboku">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="merric">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Myoboku</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Myoboku</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">merric</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">20</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">22</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/05/17/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/ES%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="merric">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Myoboku">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Myoboku">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/05/17/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/ES%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86/" class="post-title-link" itemprop="url">ES索引生命周期管理(ILM)</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-05-17 22:30:00" itemprop="dateCreated datePublished" datetime="2023-05-17T22:30:00+00:00">2023-05-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">数据库与中间件</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="ES的最佳实践"><a href="#ES的最佳实践" class="headerlink" title="ES的最佳实践"></a>ES的最佳实践</h3><p>首先我们先来看下ES的最佳实践，这里列出了最核心的两点，分片大小的控制和分片数的设定</p>
<h5 id="1-单分片控制在50G以内（推荐日志场景在30G以内，搜索场景在10G以内）"><a href="#1-单分片控制在50G以内（推荐日志场景在30G以内，搜索场景在10G以内）" class="headerlink" title="1. 单分片控制在50G以内（推荐日志场景在30G以内，搜索场景在10G以内）"></a>1. 单分片控制在50G以内（推荐日志场景在30G以内，搜索场景在10G以内）</h5><p>分片大小为什么要控制呢？如果分片太大，我们在做数据迁移，reblance或者recovery的时候效率会特别低，影响集群的稳定性，同时分片太小了也不行，分片太小会导致同样数据量的情况下，集群的分片数会更多，ES的分片数越多，其实分片管理的效率会越低也会影响ES整体性能。 </p>
<h5 id="2-索引的分片数位数据节点的倍数"><a href="#2-索引的分片数位数据节点的倍数" class="headerlink" title="2. 索引的分片数位数据节点的倍数"></a>2. 索引的分片数位数据节点的倍数</h5><p>比如有3个数据节点，那最好的分片数应该是3、6、9等等</p>
<p>如果能做到以上两点，整个集群的稳定性还是有一定保障的。但其实以上这两点是很难同时做到的，这中间有个矛盾就是索引分片数没办法修改，但是一般情况下数据量都是不断增长的，最总就会导致单个分片的大小超过最佳实践的推荐值。</p>
<p> 那要如何解决索引分片数无法修改和数据持续增长的矛盾？</p>
<h3 id="理想实现"><a href="#理想实现" class="headerlink" title="理想实现"></a>理想实现</h3><p>那我们看下分布式系统中有没有这种比较理想的实现方式。</p>
<p>这边先举个例子，这里给出了一个有三个节点的数据集群，其中包含了3个shard</p>
<p><img src="/images/es_ilm/1691810296023.png" alt="1691810296023"></p>
<p>数据持续增长…</p>
<p><img src="/images/es_ilm/1691810457654.png" alt="1691810457654"></p>
<p>每个分片中的数据在不断增加，即将超过30G，这时候要怎么办呢？</p>
<h5 id="方式一-分裂"><a href="#方式一-分裂" class="headerlink" title="方式一 分裂"></a>方式一 分裂</h5><p><img src="/images/es_ilm/1691810614196.png" alt="1691810614196"></p>
<p>先把分片一分为二，再把数据平分，这样每个分片中就只存了一半的数据。如果数据不断增长，又满了，那就再次分裂。</p>
<h5 id="方式二-新增"><a href="#方式二-新增" class="headerlink" title="方式二 新增"></a>方式二 新增</h5><p><img src="/images/es_ilm/1691810780548.png" alt="1691810780548"></p>
<p>当数据满的时候，通过新增分片的方式来存储新的数据。ES中使用的方式就是这种新增的方式。</p>
<p>为什么ES没有使用方式一种的分裂方式呢？主要是因为数据的路由规则问题，ES用的是hash路由的方式来确定数据在哪个分片上，如果使用分裂的方式，每次分裂就需要重新对一半数据做reindex。（当然目前的es版本支持了split这种api，但实际上使用的并不多，因为性能较差）</p>
<h5 id="理想实现-rollover"><a href="#理想实现-rollover" class="headerlink" title="理想实现 rollover"></a>理想实现 rollover</h5><p><img src="/images/es_ilm/1691811190314.png" alt="1691811190314"></p>
<p>ES种新增的过程叫rollover，就是旧的索引（index-00001）满了之后会创建一个新的索引（index-00002）,但从整体上来讲，他们对于用户来讲属于同一个索引，index-00001和index-00002被同一个逻辑索引或者叫别名（alias）纳管。程序使用的时候是通过别名来进行读写，rollover和alias是同时使用的。如果index-00002也满了，就会继续滚动，创建index-00003，同时被别名纳管。</p>
<p>这样就实现了shard随着数据的不断增长，自身也在不断增加，同时确保每个分片的数据量保持在推荐的范围内。</p>
<h5 id="理想实现-migration"><a href="#理想实现-migration" class="headerlink" title="理想实现 migration"></a>理想实现 migration</h5><p>那实际生产中可能还有一中场景，就是随着时间的一部分数据查询频率会降低，数据价值也会降低，这时候如果如果可以把数据迁移到低配的机器上可以大大节省成本。</p>
<p><img src="/images/es_ilm/1691811697352.png" alt="1691811697352"></p>
<p>迁移</p>
<p><img src="/images/es_ilm/1691816974098.png" alt="1691816974098"></p>
<p>这样就可以更合理使用硬件资源，提升硬件使用效率。</p>
<p>再回头看最佳实践，单分片大小限制和分片数不可修改的问题就完美解决了。我们只需要根据业务情况来确定滚动周期以及数据每日增量即可确定分片数以及单分片大小，系统会根据配置自动滚动，生成新的索引。</p>
<h3 id="ES的索引生命周期"><a href="#ES的索引生命周期" class="headerlink" title="ES的索引生命周期"></a>ES的索引生命周期</h3><p>索引的生命周期可以归纳为下面四个阶段</p>
<p>Hot阶段读写频繁，使用高配服务器，Warm、Cold使用低配机器即可满足</p>
<p><img src="/images/es_ilm/1691817840919.png" alt="1691817840919"> </p>
<p>我们只需要搞清楚每个阶段做了生命操作即可</p>
<p><img src="/images/es_ilm/1691817954788.png" alt="1691817954788"></p>
<p>索引一单创建肯定是进入到Hot阶段，我们可以指定一个min_age，那两天之后就会进入到Warm阶段，然后再设置4天之后进入Cold阶段，以及23天后删除。</p>
<h5 id="Hot-Phase"><a href="#Hot-Phase" class="headerlink" title="Hot Phase"></a>Hot Phase</h5><p>Create</p>
<p>​	Index Template</p>
<p>Rollover</p>
<p>​	Index Alias</p>
<p>​	在索引文档数、大小、时间打到一定条件后，创建索引</p>
<p>​	控制Shard大小</p>
<h5 id="Warm-Phase"><a href="#Warm-Phase" class="headerlink" title="Warm Phase"></a>Warm Phase</h5><p>Allocate</p>
<p>​	Node Attribute</p>
<p>​	Index Shard Allocation</p>
<p>​		index.routing.allocation.require.*</p>
<p>Read-Only</p>
<p>​	index.blocks.read_only:true</p>
<p>Fource Merge</p>
<p>Shrink</p>
<h5 id="Cold-Phase"><a href="#Cold-Phase" class="headerlink" title="Cold Phase"></a>Cold Phase</h5><p>Allocate</p>
<p>​	Node Attribute</p>
<p>​	Index Shard Allocation</p>
<p>​		index.routing.allocation.require.*</p>
<h5 id="Delete-Phase"><a href="#Delete-Phase" class="headerlink" title="Delete Phase"></a>Delete Phase</h5><p>Delete</p>
<h3 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h3><h5 id="创建rollover策略"><a href="#创建rollover策略" class="headerlink" title="创建rollover策略"></a>创建rollover策略</h5><p>如下策略的含义为：当索引的大小达到1000GB，索引创建超过1天时，自动进行滚 动；索引创建7天后，关闭数据副本；索引创建30天后，删除该索引。</p>
<p>策略可以根据具体业务场景进行配置。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">PUT _opendistro/_ism/policies/rollover_workflow</span><br><span class="line">&#123;</span><br><span class="line">    &quot;policy&quot;:&#123;</span><br><span class="line">        &quot;description&quot;:&quot;rollover test&quot;,</span><br><span class="line">        &quot;default_state&quot;:&quot;hot&quot;,</span><br><span class="line">        &quot;states&quot;:[</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;name&quot;:&quot;hot&quot;,</span><br><span class="line">                &quot;actions&quot;:[</span><br><span class="line">                    &#123;</span><br><span class="line">                        &quot;rollover&quot;:&#123;</span><br><span class="line">                            &quot;min_size&quot;:&quot;1000gb&quot;,</span><br><span class="line">                            &quot;min_index_age&quot;:&quot;1d&quot;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                ],</span><br><span class="line">                &quot;transitions&quot;:[</span><br><span class="line">                    &#123;</span><br><span class="line">                        &quot;state_name&quot;:&quot;warm&quot;,</span><br><span class="line">                        &quot;conditions&quot;:&#123;</span><br><span class="line">                            &quot;min_index_age&quot;:&quot;7d&quot;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                ]</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;name&quot;:&quot;warm&quot;,</span><br><span class="line">                &quot;actions&quot;:[</span><br><span class="line">                    &#123;</span><br><span class="line">                        &quot;replica_count&quot;:&#123;</span><br><span class="line">                            &quot;number_of_replicas&quot;:0</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                ],</span><br><span class="line">                &quot;transitions&quot;:[</span><br><span class="line">                    &#123;</span><br><span class="line">                        &quot;state_name&quot;:&quot;delete&quot;,</span><br><span class="line">                        &quot;conditions&quot;:&#123;</span><br><span class="line">                            &quot;min_index_age&quot;:&quot;30d&quot;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                ]</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;name&quot;:&quot;delete&quot;,</span><br><span class="line">                &quot;actions&quot;:[</span><br><span class="line">                    &#123;</span><br><span class="line">                        &quot;delete&quot;:&#123;</span><br><span class="line"></span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>创建好Rollover策略之后，可以通过如下命令查询策略详情：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET _opendistro/_ism/policies/rollover_workflow</span><br></pre></td></tr></table></figure>

<h5 id="新建索引模板"><a href="#新建索引模板" class="headerlink" title="新建索引模板"></a>新建索引模板</h5><p>如下模板的含义为：对于所有test开头的索引，其自动关联上面创建的rollover策略， 并且rollover时使用log_alias作为别名。 模板可以结合具体业务场景进行调整，比如：number_of_shards、refresh_interval， 以及mapping里面的参数等。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">PUT _template/template_test</span><br><span class="line">&#123;</span><br><span class="line">    &quot;index_patterns&quot;:&quot;test*&quot;,</span><br><span class="line">    &quot;settings&quot;:&#123;</span><br><span class="line">        &quot;number_of_replicas&quot;:1,</span><br><span class="line">        &quot;number_of_shards&quot;:1,</span><br><span class="line">        &quot;opendistro.index_state_management.policy_id&quot;:&quot;rollover_workflow&quot;,</span><br><span class="line">        &quot;index.opendistro.index_state_management.rollover_alias&quot;:&quot;log_alias&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;mappings&quot;:&#123;</span><br><span class="line">        &quot;properties&quot;:&#123;</span><br><span class="line">            &quot;name&quot;:&#123;</span><br><span class="line">                &quot;type&quot;:&quot;text&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>创建好索引模板之后，可以通过如下命令查询模板详情：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET _template/template_test</span><br></pre></td></tr></table></figure>

<h5 id="创建第一个索引"><a href="#创建第一个索引" class="headerlink" title="创建第一个索引"></a>创建第一个索引</h5><p>第一个索引要指定aliases，并且需要配置is_write_index为true。</p>
<p>如下索引是&lt;test-{now&#x2F;d}-000001&gt;的URL编码，其创建时默认会带上当天的时间，比<br>如假设今天为2022.6.22，那么创建出来的索引名称为：test-2022.06.02-000001。</p>
<p>这里必须用urlencode，不然报错</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">PUT %3Ctest-%7Bnow%2Fd%7D-000001%3E</span><br><span class="line">&#123;</span><br><span class="line">    &quot;aliases&quot;:&#123;</span><br><span class="line">        &quot;log_alias&quot;:&#123;</span><br><span class="line">            &quot;is_write_index&quot;:true</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="写入或查询数据"><a href="#写入或查询数据" class="headerlink" title="写入或查询数据"></a>写入或查询数据</h5><p>写入数据或查询数据时均使用别名log_alias，其中写入时log_alias始终指向最后一个 索引：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">POST log_alias/_bulk</span><br><span class="line">&#123;&quot;index&quot;:&#123;&#125;&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;name1&quot;&#125;</span><br><span class="line">&#123;&quot;index&quot;:&#123;&#125;&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;name2&quot;&#125;</span><br><span class="line">&#123;&quot;index&quot;:&#123;&#125;&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;name3&quot;&#125;</span><br><span class="line">&#123;&quot;index&quot;:&#123;&#125;&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;name4&quot;&#125;</span><br><span class="line">&#123;&quot;index&quot;:&#123;&#125;&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;name5&quot;&#125;</span><br><span class="line">&#123;&quot;index&quot;:&#123;&#125;&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;name6&quot;&#125;</span><br></pre></td></tr></table></figure>

<p>写入数据或查询数据时均使用别名log_alias，其中查询时log_alias指向所有的历史索引：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET log_alias/_search</span><br></pre></td></tr></table></figure>

<p>查询别名关联的索引情况：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET _cat/aliases?v</span><br></pre></td></tr></table></figure>

<p>假设某个索引，其每天约产生2.4TB的数据，那么其数据在ES中的组织形态如下，其中索引别名 log-alias。 查询时指向所有test开头的索引，写入时指向最新的索引。</p>
<p><img src="/images/es_ilm/1691818897925.jpg" alt="1691818897925"></p>
<h5 id="数据更新的问题"><a href="#数据更新的问题" class="headerlink" title="数据更新的问题"></a>数据更新的问题</h5><p>在实际开发测试中发现，历史数据使用索引别名更新的时候会存在问题。</p>
<p>假设历史A索引中存在一条x数据，当前索引为B索引</p>
<p>当再次更新这个x数据的时候，不会更新A索引中的这条数据，而是会插入到B索引中，此时再去查询x数据就会查询到两条。</p>
<p>原因：Rollover策略实现自动滚动索引后，历史索引的is_write_index属性会被设置为false，当通过索引别名来PUT数据时，只会从当前索引中判断是同存在相同数据。由于数据存在历史索引中，所以会在新索引中创建记录</p>
<p>![d1aca159ba370fc83db4043922a2521](C:\Users\Ryan\AppData\Local\Temp\WeChat Files\d1aca159ba370fc83db4043922a2521.png)</p>
<p>解决方法：更新数据时先查询当前数据所在的索引，更新时带上索引</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>通过ES的索引生命周期管理，我们可以根据业务需求，设置分片数与滚动策略，不用担心索引分片数不够，或者分片容量太大的问题。合理使用分片策略可以满足大部分订单类系统查询需求。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/05/17/%E7%A0%94%E5%8F%91%E5%B7%A5%E5%85%B7/Git%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="merric">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Myoboku">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Myoboku">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/05/17/%E7%A0%94%E5%8F%91%E5%B7%A5%E5%85%B7/Git%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/" class="post-title-link" itemprop="url">Git学习总结</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-05-17 22:30:00" itemprop="dateCreated datePublished" datetime="2023-05-17T22:30:00+00:00">2023-05-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%A0%94%E5%8F%91%E5%B7%A5%E5%85%B7/" itemprop="url" rel="index"><span itemprop="name">研发工具</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="什么是git"><a href="#什么是git" class="headerlink" title="什么是git"></a>什么是git</h1><p>Git是免费、开源的 <strong>分布式版本控制</strong> 系统，可以有效、高速地处理从很小到非常大的项目版本管理。</p>
<h2 id="版本控制"><a href="#版本控制" class="headerlink" title="版本控制"></a>版本控制</h2><p>版本控制是指对软件开发过程中各种程序代码、配置文件及说明文档等文件变更的管理，是软件配置管理的核心思想之一。那些年，我们的毕业论文,其实就是版本变更的真实写照…脑洞一下，版本控制就是这些论文变更的管理</p>
<p><img src="/images/%E8%AE%BA%E6%96%87%E7%89%88%E6%9C%AC.png" alt="论文版本"></p>
<h3 id="集中化的版本控制系统"><a href="#集中化的版本控制系统" class="headerlink" title="集中化的版本控制系统"></a>集中化的版本控制系统</h3><p>那么，集中化的版本控制系统又是什么呢，说白了，就是有一个集中管理的中央服务器，保存着所有文件的修改历史版本，而协同开发者通过客户端连接到这台服务器，从服务器上同步更新或上传自己的修改。</p>
<p><img src="/images/%E9%9B%86%E4%B8%AD%E5%8C%96%E7%9A%84%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6.png" alt="集中化的版本控制"></p>
<h3 id="分布式的版本控制系统"><a href="#分布式的版本控制系统" class="headerlink" title="分布式的版本控制系统"></a>分布式的版本控制系统</h3><p>分布式版本控制系统，就是远程仓库同步所有版本信息到本地的每个用户。这里分三点阐述：</p>
<ul>
<li>用户在本地就可以查看所有的历史版本信息，但是偶尔要从远程更新一下，因为可能别的用户有文件修改提交到远程。</li>
<li>用户即使离线也可以本地提交，push推送到远程服务器才需要联网。</li>
<li>每个用户都保存了历史版本，所以只要有一个用户设备没问题，就可以恢复数据了</li>
</ul>
<p><img src="/images/%E5%88%86%E5%B8%83%E5%BC%8F%E7%9A%84%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6.png" alt="分布式的版本控制"></p>
<h1 id="Git的相关理论基础"><a href="#Git的相关理论基础" class="headerlink" title="Git的相关理论基础"></a><strong>Git的相关理论基础</strong></h1><h2 id="Git的四大工作区域"><a href="#Git的四大工作区域" class="headerlink" title="Git的四大工作区域"></a>Git的四大工作区域</h2><p>先复习Git的几个工作区域：</p>
<p><img src="/images/git%E7%9A%84%E5%9B%9B%E5%A4%A7%E5%B7%A5%E4%BD%9C%E5%8C%BA%E5%9F%9F.png" alt="git的四大工作区域"></p>
<ul>
<li><strong>Workspace</strong> ：你电脑本地看到的文件和目录，在Git的版本控制下，构成了工作区。</li>
<li><strong>Index&#x2F;Stage</strong> ：暂存区，一般存放在 .git目录下，即.git&#x2F;index,它又叫待提交更新区，用于临时存放你未提交的改动。比如，你执行git add，这些改动就添加到这个区域啦。</li>
<li><strong>Repository</strong> ：本地仓库，你执行git clone 地址，就是把远程仓库克隆到本地仓库。它是一个存放在本地的版本库，其中 <strong>HEAD指向最新放入仓库的版本</strong> 。当你执行git commit，文件改动就到本地仓库来了~</li>
<li><strong>Remote</strong> ：远程仓库，就是类似github，码云等网站所提供的仓库，可以理解为远程数据交换的仓库</li>
</ul>
<h2 id="Git的工作流程"><a href="#Git的工作流程" class="headerlink" title="Git的工作流程"></a>Git的工作流程</h2><p>上一小节介绍完Git的四大工作区域，把git的操作命令和几个工作区域结合起来，个人觉得更容易理解一些，看图：</p>
<p><img src="/images/git%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png" alt="git的工作流程"></p>
<p>git 的正向工作流程一般就这样：</p>
<ul>
<li>从远程仓库拉取文件代码回来；</li>
<li>在工作目录，增删改查文件；</li>
<li>把改动的文件放入暂存区；</li>
<li>将暂存区的文件提交本地仓库；</li>
<li>将本地仓库的文件推送到远程仓库；</li>
</ul>
<h2 id="Git文件的四种状态"><a href="#Git文件的四种状态" class="headerlink" title="Git文件的四种状态"></a>Git文件的四种状态</h2><p>根据一个文件是否已加入版本控制，可以把文件状态分为：Tracked(已跟踪)和Untracked(未跟踪)，而tracked(已跟踪)又包括三种工作状态：Unmodified，Modified，Staged</p>
<p><img src="/images/git%E6%96%87%E4%BB%B6%E7%9A%84%E5%9B%9B%E7%A7%8D%E7%8A%B6%E6%80%81.png" alt="git文件的四种状态"></p>
<ul>
<li><strong>Untracked</strong> : 文件还没有加入到git库，还没参与版本控制，即未跟踪状态。这时候的文件，通过git add 状态，可以变为Staged状态</li>
<li><strong>Unmodified</strong> ：文件已经加入git库, 但是呢，还没修改, 就是说版本库中的文件快照内容与文件夹中还完全一致。Unmodified的文件如果被修改, 就会变为Modified. 如果使用git remove移出版本库, 则成为Untracked文件。</li>
<li><strong>Modified</strong> ：文件被修改了，就进入modified状态啦，文件这个状态通过stage命令可以进入staged状态</li>
<li><strong>staged</strong> ：暂存状态. 执行git commit则将修改同步到库中, 这时库中的文件和本地文件又变为一致, 文件为Unmodified状态.</li>
</ul>
<h1 id="git的常用命令"><a href="#git的常用命令" class="headerlink" title="git的常用命令"></a>git的常用命令</h1><h2 id="日常开发中，Git的基本常用命令"><a href="#日常开发中，Git的基本常用命令" class="headerlink" title="日常开发中，Git的基本常用命令"></a><strong>日常开发中，Git的基本常用命令</strong></h2><ul>
<li>git clone</li>
<li>git checkout -b dev</li>
<li>git add</li>
<li>git commit</li>
<li>git log</li>
<li>git diff</li>
<li>git status</li>
<li>git pull&#x2F;git fetch</li>
<li>git push</li>
</ul>
<p>这个图只是模拟一下git基本命令使用的大概流程</p>
<p><img src="/images/git%E7%9A%84%E5%A4%A7%E6%A6%82%E6%B5%81%E7%A8%8B.png" alt="git的大概流程"></p>
<h3 id="git-clone"><a href="#git-clone" class="headerlink" title="git clone"></a>git clone</h3><p>当我们要进行开发，第一步就是克隆远程版本库到本地</p>
<pre><code>git clone url  克隆远程版本库  
  
</code></pre>
<h3 id="git-checkout-b-dev"><a href="#git-checkout-b-dev" class="headerlink" title="git checkout -b dev"></a>git checkout -b dev</h3><p>克隆完之后呢，开发新需求的话，我们需要新建一个开发分支，比如新建开发分支dev</p>
<p>创建分支：</p>
<pre><code>git checkout -b dev   创建开发分支dev，并切换到该分支下  
</code></pre>
<h3 id="git-add"><a href="#git-add" class="headerlink" title="git add"></a>git add</h3><p>git add的使用格式：</p>
<pre><code>git add .	添加当前目录的所有文件到暂存区  
git add [dir]	添加指定目录到暂存区，包括子目录  
git add [file1]	添加指定文件到暂存区  
</code></pre>
<p>有了开发分支dev之后，我们就可以开始开发啦，假设我们开发完HelloWorld.java，可以把它加到暂存区，命令如下</p>
<pre><code>git add Hello.java  把HelloWorld.java文件添加到暂存区去  
</code></pre>
<h3 id="git-commit"><a href="#git-commit" class="headerlink" title="git commit"></a>git commit</h3><p>git commit的使用格式：</p>
<pre><code>git commit -m [message] 提交暂存区到仓库区,message为说明信息  
git commit [file1] -m [message] 提交暂存区的指定文件到本地仓库  
git commit --amend -m [message] 使用一次新的commit，替代上一次提交  
  
</code></pre>
<p>把HelloWorld.java文件加到暂存区后，我们接着可以提交到本地仓库</p>
<pre><code>git commit -m &#39;helloworld开发&#39;  
  
</code></pre>
<h3 id="git-status"><a href="#git-status" class="headerlink" title="git status"></a>git status</h3><p>git status,表示查看工作区状态，使用命令格式：</p>
<pre><code>git status  查看当前工作区暂存区变动  
git status -s  查看当前工作区暂存区变动，概要信息  
git status  --show-stash 查询工作区中是否有stash（暂存的文件）  
</code></pre>
<p>当你忘记是否已把代码文件添加到暂存区或者是否提交到本地仓库，都可以用git status看看</p>
<h3 id="git-log"><a href="#git-log" class="headerlink" title="git log"></a>git log</h3><p>git log，这个命令用得应该比较多，表示查看提交历史&#x2F;提交日志，要回滚代码就经常用它看看提交历史。</p>
<pre><code>git log  查看提交历史  
git log --oneline 以精简模式显示查看提交历史  
git log -p &lt;file&gt; 查看指定文件的提交历史  
git blame &lt;file&gt; 一列表方式查看指定文件的提交历史  
</code></pre>
<h3 id="git-diff"><a href="#git-diff" class="headerlink" title="git diff"></a>git diff</h3><pre><code>git diff 显示暂存区和工作区的差异  
git diff filepath   filepath路径文件中，工作区与暂存区的比较差异  
git diff HEAD filepath 工作区与HEAD ( 当前工作分支)的比较差异  
git diff branchName filepath 当前分支的文件与branchName分支的文件的比较差异  
git diff commitId filepath 与某一次提交的比较差异  
</code></pre>
<p>如果你想对比一下你改了哪些内容，可以用git diff对比一下文件修改差异</p>
<h3 id="git-pull-git-fetch"><a href="#git-pull-git-fetch" class="headerlink" title="git pull&#x2F;git fetch"></a>git pull&#x2F;git fetch</h3><pre><code>git pull  拉取远程仓库所有分支更新并合并到本地分支。  
git pull origin master 将远程master分支合并到当前本地分支  
git pull origin master:master 将远程master分支合并到当前本地master分支，冒号后面表示本地分支  
git fetch --all  拉取所有远端的最新代码  
git fetch origin master 拉取远程最新master分支代码  
</code></pre>
<p>我们一般都会用git pull拉取最新代码看看的，解决一下冲突，再推送代码到远程仓库的。</p>
<blockquote>
<p>有些伙伴可能对使用git pull还是git fetch有点疑惑，其实 git pull &#x3D; git fetch+ git<br>merge。pull的话，拉取远程分支并与本地分支合并，fetch只是拉远程分支，怎么合并，可以自己再做选择。</p>
</blockquote>
<h3 id="git-push"><a href="#git-push" class="headerlink" title="git push"></a>git push</h3><p>git push 可以推送本地分支、标签到远程仓库，也可以删除远程分支。</p>
<pre><code>git push origin master 将本地分支的更新全部推送到远程仓库master分支。  
git push origin -d &lt;branchname&gt;   删除远程branchname分支  
git push --tags 推送所有标签  
</code></pre>
<p>如果我们在dev开发完，或者就想把文件推送到远程仓库，给别的伙伴看看，就可以使用git push origin dev</p>
<h3 id="git-branch"><a href="#git-branch" class="headerlink" title="git branch"></a>git branch</h3><p>git branch用处多多呢，比如新建分支、查看分支、删除分支等等</p>
<p><strong>新建分支：</strong></p>
<pre><code>git checkout -b dev2  新建一个分支，并且切换到新的分支dev2  
git branch dev2 新建一个分支，但是仍停留在原来分支  
</code></pre>
<p><strong>查看分支：</strong></p>
<pre><code>git branch    查看本地所有的分支  
git branch -r  查看所有远程的分支  
git branch -a  查看所有远程分支和本地分支  
</code></pre>
<p><strong>删除分支：</strong></p>
<pre><code>git branch -D &lt;branchname&gt;  删除本地branchname分支  
</code></pre>
<h3 id="git-checkout"><a href="#git-checkout" class="headerlink" title="git checkout"></a>git checkout</h3><p> <strong>切换分支：</strong></p>
<pre><code>git checkout master 切换到master分支  
</code></pre>
<h3 id="git-merge"><a href="#git-merge" class="headerlink" title="git merge"></a>git merge</h3><p>我们在开发分支dev开发、测试完成在发布之前，我们一般需要把开发分支dev代码合并到master，所以git merge也是程序员必备的一个命令。</p>
<pre><code>git merge master  在当前分支上合并master分支过来  
git merge --no-ff origin/dev  在当前分支上合并远程分支dev  
git merge --abort 终止本次merge，并回到merge前的状态  
</code></pre>
<p>比如，你开发完需求后，发版需要把代码合到主干master分支</p>
<h2 id="Git进阶之撤销与回退"><a href="#Git进阶之撤销与回退" class="headerlink" title="Git进阶之撤销与回退"></a><strong>Git进阶之撤销与回退</strong></h2><p>Git的撤销与回退，在日常工作中使用的比较频繁。比如我们想将某个修改后的文件撤销到上一个版本，或者想撤销某次多余的提交，都要用到git的撤销和回退操作。</p>
<p>代码在Git的每个工作区域都是用哪些命令撤销或者回退的呢，如下图所示：</p>
<p><img src="/images/git%E7%9A%84%E6%92%A4%E9%94%80%E4%B8%8E%E5%9B%9E%E9%80%80.jpg" alt="git的撤销与回退"></p>
<p>有关于Git的撤销与回退，一般就以下几个核心命令</p>
<ul>
<li>git checkout</li>
<li>git reset</li>
<li>git revert</li>
</ul>
<h3 id="git-checkout-1"><a href="#git-checkout-1" class="headerlink" title="git checkout"></a>git checkout</h3><p>如果文件还在 <strong>工作区</strong> ，还没添加到暂存区，可以使用git checkout撤销</p>
<pre><code>git checkout [file]  丢弃某个文件file  
git checkout .  丢弃所有文件  
</code></pre>
<h3 id="git-reset"><a href="#git-reset" class="headerlink" title="git reset"></a>git reset</h3><h4 id="git-reset的理解"><a href="#git-reset的理解" class="headerlink" title="git reset的理解"></a>git reset的理解</h4><blockquote>
<p>git reset的作用是修改HEAD的位置，即将HEAD指向的位置改变为之前存在的某个版本.</p>
</blockquote>
<p>为了更好地理解git reset，我们来回顾一下,Git的版本管理及HEAD的理解</p>
<blockquote>
<p>Git的所有提交，会连成一条时间轴线，这就是分支。如果当前分支是master，HEAD指针一般指向当前分支，如下：</p>
</blockquote>
<p><img src="/images/reset1.png" alt="reset1"></p>
<p>假设执行git reset，回退到版本二之后，版本三不见了,如下：</p>
<p><img src="/images/reset2.png" alt="reset2"></p>
<h4 id="git-reset的使用"><a href="#git-reset的使用" class="headerlink" title="git reset的使用"></a>git reset的使用</h4><p>Git Reset的几种使用模式</p>
<p><img src="/images/reset%E7%9A%84%E5%87%A0%E7%A7%8D%E4%BD%BF%E7%94%A8%E6%A8%A1%E5%BC%8F.png" alt="reset的几种使用模式"></p>
<pre><code>git reset HEAD --file回退暂存区里的某个文件，回退到当前版本工作区状态  
git reset –-soft 目标版本号 可以把版本库上的提交回退到暂存区，修改记录保留  
git reset –-mixed 目标版本号 可以把版本库上的提交回退到工作区，修改记录保留  
git reset –-hard  可以把版本库上的提交彻底回退，修改的记录全部revert。  
</code></pre>
<p>先看一个栗子demo吧，代码 <strong>git add到暂存区，并未commit提交</strong> ,可以酱紫回退，如下：</p>
<pre><code>git reset HEAD file 取消暂存  
git checkout file 撤销修改  
</code></pre>
<p>再看另外一个栗子吧，代码已经git commit了，但是还没有push：</p>
<pre><code>git log  获取到想要回退的commit_id  
git reset --hard commit_id  想回到过去，回到过去的commit_id  
</code></pre>
<p>如果代码已经push到远程仓库了呢，也可以使用reset回滚</p>
<pre><code>git log  
git reset --hard commit_id  
git push origin HEAD --force  
</code></pre>
<h3 id="git-revert"><a href="#git-revert" class="headerlink" title="git revert"></a>git revert</h3><blockquote>
<p>与git reset不同的是，revert复制了那个想要回退到的历史版本，将它加在当前分支的最前端。</p>
</blockquote>
<p><strong>revert之前：</strong></p>
<p><img src="/images/revert%E4%B9%8B%E5%89%8D.png" alt="revert之前"></p>
<p><strong>revert 之后：</strong></p>
<p><img src="/images/revert%E4%B9%8B%E5%90%8E.png" alt="revert之后"></p>
<p>当然，如果代码已经推送到远程的话，还可以考虑revert回滚</p>
<pre><code>git log  得到你需要回退一次提交的commit id  
git revert -n &lt;commit_id&gt;  撤销指定的版本，撤销也会作为一次提交进行保存  
</code></pre>
<h3 id="git-rebase"><a href="#git-rebase" class="headerlink" title="git rebase"></a>git rebase</h3><p>rebase又称为衍合，是合并的另外一种选择。</p>
<p>假设有两个分支master和test</p>
<pre><code>     D---E test        
    /  
A---B---C---F--- master  
  
</code></pre>
<p>执行 git merge test得到的结果</p>
<pre><code>      D--------E      
     /          \  
A---B---C---F----G---   test, master  
  
</code></pre>
<p>执行git rebase test，得到的结果</p>
<pre><code>A---B---D---E---C‘---F‘---   test, master  
  
</code></pre>
<p><strong>rebase好处是：</strong> 获得更优雅的提交树，可以线性的看到每一次提交，并且没有增加提交节点。所以很多时候，看到有些伙伴都是这个命令拉代码：git<br>pull –rebase，就是因为想更优雅，哈哈</p>
<h3 id="git-stash"><a href="#git-stash" class="headerlink" title="git stash"></a>git stash</h3><p>stash命令可用于临时保存和恢复修改</p>
<pre><code>git stash  把当前的工作隐藏起来 等以后恢复现场后继续工作  
git stash list 显示保存的工作进度列表  
git stash pop stash@&#123;num&#125; 恢复工作进度到工作区  
git stash show ：显示做了哪些改动  
git stash drop stash@&#123;num&#125; ：删除一条保存的工作进度  
git stash clear 删除所有缓存的stash。  
  
</code></pre>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/05/17/jvm/%E5%A4%9A%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="merric">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Myoboku">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Myoboku">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/05/17/jvm/%E5%A4%9A%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B/" class="post-title-link" itemprop="url">多线程与多进程</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-05-17 22:30:00" itemprop="dateCreated datePublished" datetime="2023-05-17T22:30:00+00:00">2023-05-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="线程和进程"><a href="#线程和进程" class="headerlink" title="线程和进程"></a>线程和进程</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动,进程是系统进行资源分配和调度的一个独立单位.</p>
<p>线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源.</p>
<p>一个线程可以创建和撤销另一个线程;同一个进程中的多个线程之间可以并发执行.</p>
<p>相对进程而言，线程是一个更加接近于执行体的概念，它可以与同进程中的其他线程共享数据，但拥有自己的栈空间，拥有独立的执行序列。</p>
<p>在串行程序基础上引入线程和进程是为了提高程序的并发度，从而提高程序运行效率和响应时间。</p>
<h2 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h2><p>进程和线程的主要差别在于它们是不同的操作系统资源管理方式。进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。<br><strong>但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。</strong></p>
<ol>
<li><strong>简而言之,一个程序至少有一个进程,一个进程至少有一个线程.</strong></li>
<li>线程的划分尺度小于进程，使得多线程程序的并发性高。</li>
<li>另外，进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率。</li>
<li>线程在执行过程中与进程还是有区别的。每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口。 <strong>但是线程不能够独立执行，</strong> 必须依存在应用程序中，由应用程序提供多个线程执行控制。</li>
<li>从逻辑角度来看，多线程的意义在于一个应用程序中，有多个执行部分可以同时执行。但操作系统并没有将多个线程看做多个独立的应用，来实现进程的调度和管理以及资源分配。 <strong>这就是进程和线程的重要区别。</strong></li>
</ol>
<h1 id="多线程和多进程"><a href="#多线程和多进程" class="headerlink" title="多线程和多进程"></a>多线程和多进程</h1><table>
<thead>
<tr>
<th><strong>对比维度</strong></th>
<th><strong>多进程</strong></th>
<th><strong>多线程</strong></th>
<th><strong>总结</strong></th>
</tr>
</thead>
<tbody><tr>
<td>数据共享、同步</td>
<td>数据共享复杂，需要用IPC；数据是分开的，同步简单</td>
<td>因为共享进程数据，数据共享简单，但也是因为这个原因导致同步复杂</td>
<td>各有优势</td>
</tr>
<tr>
<td>内存、CPU</td>
<td>占用内存多，切换复杂，CPU利用率低</td>
<td>占用内存少，切换简单，CPU利用率高</td>
<td>线程占优</td>
</tr>
<tr>
<td>创建销毁、切换</td>
<td>创建销毁、切换复杂，速度慢</td>
<td>创建销毁、切换简单，速度很快</td>
<td>线程占优</td>
</tr>
<tr>
<td>编程、调试</td>
<td>编程简单，调试简单</td>
<td>编程复杂，调试复杂</td>
<td>进程占优</td>
</tr>
<tr>
<td>可靠性</td>
<td>进程间不会互相影响</td>
<td>一个线程挂掉将导致整个进程挂掉</td>
<td>进程占优</td>
</tr>
<tr>
<td>分布式</td>
<td>适应于多核、多机分布式；如果一台机器不够，扩展到多台机器比较简单</td>
<td>适应于多核分布式</td>
<td>进程占优</td>
</tr>
</tbody></table>
<p>使用进程和线程一般根据以上的不同情况进行不同的选择，一般以业务逻辑划分进程，内部再细分线程</p>
<h1 id="进程间通信"><a href="#进程间通信" class="headerlink" title="进程间通信"></a>进程间通信</h1><h2 id="进程间通信的目的"><a href="#进程间通信的目的" class="headerlink" title="进程间通信的目的"></a>进程间通信的目的</h2><ul>
<li><p><strong>数据传输</strong><br>一个进程需要将它的数据发送给另一个进程，发送的数据量在一个字节到几M字节之间</p>
</li>
<li><p><strong>共享数据</strong><br>多个进程想要操作共享数据，一个进程对共享数据</p>
</li>
<li><p><strong>通知事</strong><br>一个进程需要向另一个或一组进程发送消息，通知它（它们）发生了某种事件（如进程终止时要通知父进程）。</p>
</li>
<li><p><strong>资源共享</strong><br>多个进程之间共享同样的资源。为了作到这一点，需要内核提供锁和同步机制。</p>
</li>
<li><p><strong>进程控制</strong><br>有些进程希望完全控制另一个进程的执行（如Debug进程），此时控制进程希望能够拦截另一个进程的所有陷入和异常，并能够及时知道它的状态改变。</p>
</li>
</ul>
<h2 id="linux进程间通信的方式"><a href="#linux进程间通信的方式" class="headerlink" title="linux进程间通信的方式"></a>linux进程间通信的方式</h2><h3 id="管道（pipe）"><a href="#管道（pipe）" class="headerlink" title="管道（pipe）"></a>管道（pipe）</h3><ul>
<li>管道是半双工的，数据只能向一个方向流动；需要双方通信时，需要建立起两个管道。</li>
<li>只能用于父子进程或者兄弟进程之间(具有亲缘关系的进程);</li>
<li>单独构成一种独立的文件系统：管道对于管道两端的进程而言，就是一个文件，但它不是普通的文件，它不属于某种文件系统，而是自立门户，单独构成一种文件系统，并且只存在与内存中。</li>
<li>数据的读出和写入：一个进程向管道中写的内容被管道另一端的进程读出。写入的内容每次都添加在管道缓冲区的末尾，并且每次都是从缓冲区的头部读出数据。</li>
</ul>
<p><img src="/images/%E7%AE%A1%E9%81%93.png" alt="管道"></p>
<p>常见的Linux命令 “|” 其实就是匿名管道，表示把一个进程的输出传输到另外一个进程，如：</p>
<pre><code>echo &quot;Happyjava&quot; | awk -F &#39;j&#39; &#39;&#123;print $2&#125;&#39;  
# 输出 ava  
  
</code></pre>
<p>—|—  </p>
<p><strong>管道的实质：</strong></p>
<ul>
<li>管道的实质是一个内核缓冲区，进程以先进先出的方式从缓冲区存取数据，管道一端的进程顺序的将数据写入缓冲区，另一端的进程则顺序的读出数据。</li>
<li>该缓冲区可以看做是一个循环队列，读和写的位置都是自动增长的，不能随意改变，一个数据只能被读一次，读出来以后在缓冲区就不复存在了。</li>
<li>当缓冲区读空或者写满时，有一定的规则控制相应的读进程或者写进程进入等待队列，当空的缓冲区有新数据写入或者满的缓冲区有数据读出来时，就唤醒等待队列中的进程继续读写。</li>
</ul>
<p><strong>管道的局限：</strong><br>管道的主要局限性正体现在它的特点上：</p>
<ul>
<li>只支持单向数据流；</li>
<li>只能用于具有亲缘关系的进程之间；</li>
<li>没有名字；</li>
<li>管道的缓冲区是有限的（管道制存在于内存中，在管道创建时，为缓冲区分配一个页面大小）；</li>
<li>管道所传送的是无格式字节流，这就要求管道的读出方和写入方必须事先约定好数据的格式，比如多少字节算作一个消息（或命令、或记录）等等；</li>
</ul>
<h3 id="有名管道（FIFO）"><a href="#有名管道（FIFO）" class="headerlink" title="有名管道（FIFO）"></a>有名管道（FIFO）</h3><p>匿名管道，由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道(FIFO)。<br>有名管道不同于匿名管道之处在于它提供了一个路径名与之关联， <strong>以有名管道的文件形式存在于文件系统中</strong> ，这样，<br><strong>即使与有名管道的创建进程不存在亲缘关系的进程，只要可以访问该路径，就能够彼此通过有名管道相互通信</strong><br>，因此，通过有名管道不相关的进程也能交换数据。值的注意的是，有名管道严格遵循 <strong>先进先出(first in first out)</strong><br>,对匿名管道及有名管道的读总是从开始处返回数据，对它们的写则把数据添加到末尾。它们不支持诸如lseek()等文件定位操作。<br><strong>有名管道的名字存在于文件系统中，内容存放在内存中。</strong></p>
<p><strong>匿名管道和有名管道总结：</strong><br>（1）管道是特殊类型的文件，在满足先入先出的原则条件下可以进行读写，但不能进行定位读写。<br>（2）匿名管道是单向的，只能在有亲缘关系的进程间通信；有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。<br>（3） <strong>无名管道阻塞问题：</strong><br>无名管道无需显示打开，创建时直接返回文件描述符，在读写时需要确定对方的存在，否则将退出。如果当前进程向无名管道的一端写数据，必须确定另一端有某一进程。如果写入无名管道的数据超过其最大值，写操作将阻塞，如果管道中没有数据，读操作将阻塞，如果管道发现另一端断开，将自动退出。<br>（4） <strong>有名管道阻塞问题：</strong><br>有名管道在打开时需要确实对方的存在，否则将阻塞。即以读方式打开某管道，在此之前必须一个进程以写方式打开管道，否则阻塞。此外，可以以读写（O_RDWR）模式打开有名管道，即当前进程读，当前进程写，不会阻塞。</p>
<h3 id="信号（-Signal-）"><a href="#信号（-Signal-）" class="headerlink" title="信号（ Signal ）"></a>信号（ <strong>Signal</strong> ）</h3><ul>
<li>信号是Linux系统中用于进程间互相通信或者操作的一种机制，信号可以在任何时候发给某一进程，而无需知道该进程的状态。</li>
<li>如果该进程当前并未处于执行状态，则该信号就有内核保存起来，直到该进程回复执行并传递给它为止。</li>
<li>如果一个信号被进程设置为阻塞，则该信号的传递被延迟，直到其阻塞被取消是才被传递给进程。</li>
</ul>
<p><strong>信号来源</strong></p>
<p>信号是软件层次上对中断机制的一种模拟，是一种异步通信方式，，信号可以在用户空间进程和内核之间直接交互，内核可以利用信号来通知用户空间的进程发生了哪些系统事件，信号事件主要有两个来源：</p>
<ul>
<li>硬件来源：用户按键输入<code>Ctrl+C</code>退出、硬件异常如无效的存储访问等。</li>
<li>软件终止：终止进程信号、其他进程调用kill函数、软件异常产生信号。</li>
</ul>
<p><strong>信号生命周期和处理流程</strong></p>
<ol>
<li><p>信号被某个进程产生，并设置此信号传递的对象（一般为对应进程的pid），然后传递给操作系统；</p>
</li>
<li><p>操作系统根据接收进程的设置（是否阻塞）而选择性的发送给接收者，如果接收者阻塞该信号（且该信号是可以阻塞的），操作系统将暂时保留该信号，而不传递，直到该进程解除了对此信号的阻塞（如果对应进程已经退出，则丢弃此信号），如果对应进程没有阻塞，操作系统将传递此信号。</p>
</li>
<li><p>目的进程接收到此信号后，将根据当前进程对此信号设置的预处理方式，暂时终止当前代码的执行，保护上下文（主要包括临时寄存器数据，当前程序位置以及当前CPU的状态）、转而执行中断服务程序，执行完成后在回复到中断的位置。当然，对于抢占式内核，在中断返回时还将引发新的调度。</p>
</li>
</ol>
<h3 id="消息队列（-Message-）"><a href="#消息队列（-Message-）" class="headerlink" title="消息队列（ Message ）"></a>消息队列（ <strong>Message</strong> ）</h3><p>注意，此消息队列不是我们常用的MQ，如kafka，rabbitmq，rocketmq等。</p>
<ul>
<li>消息队列是存放在内存中的消息链表，每个消息队列由消息队列标识符表示。</li>
<li>与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显示地删除一个消息队列时，该消息队列才会被真正的删除。</li>
<li>另外与管道不同的是，消息队列在某个进程往一个队列写入消息之前，并不需要另外某个进程在该队列上等待消息的到达</li>
</ul>
<p><strong>消息队列特点总结：</strong></p>
<ol>
<li>消息队列是消息的链表,具有特定的格式,存放在内存中并由消息队列标识符标识.</li>
<li>消息队列允许一个或多个进程向它写入与读取消息.</li>
<li>管道和消息队列的通信数据都是先进先出的原则。</li>
<li>消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比FIFO更有优势。</li>
<li>消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺。</li>
<li>目前主要有两种类型的消息队列：POSIX消息队列以及System V消息队列，系统V消息队列目前被大量使用。系统V消息队列是随内核持续的，只有在内核重起或者人工删除时，该消息队列才会被删除。</li>
</ol>
<h3 id="共享内存-（share-memory）"><a href="#共享内存-（share-memory）" class="headerlink" title="共享内存 （share memory）"></a>共享内存 <strong>（share memory）</strong></h3><ul>
<li>使得多个进程可以直接读写同一块内存空间，是最快的可用IPC形式。是针对其他通信机制运行效率较低而设计的。</li>
<li>为了在多个进程间交换信息，内核专门留出了一块内存区，可以由需要访问的进程将其映射到自己的私有地址空间。进程就可以直接读写这一块内存而不需要进行数据的拷贝，从而大大提高效率。</li>
<li>由于多个进程共享一段内存，因此需要依靠某种同步机制（如信号量）来达到进程间的同步及互斥。</li>
</ul>
<p><img src="/images/%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98.png" alt="共享内存"></p>
<h3 id="信号量（-semaphore-）"><a href="#信号量（-semaphore-）" class="headerlink" title="信号量（ semaphore ）"></a>信号量（ <strong>semaphore</strong> ）</h3><p>信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。<br>为了获得共享资源，进程需要执行下列操作：<br>（1） <strong>创建一个信号量</strong> ：这要求调用者指定初始值，对于二值信号量来说，它通常是1，也可是0。<br>（2） <strong>等待一个信号量</strong> ：该操作会测试这个信号量的值，如果小于0，就阻塞。也称为P操作。<br>（3） <strong>挂出一个信号量</strong> ：该操作将信号量的值加1，也称为V操作。</p>
<p>为了正确地实现信号量，信号量值的测试及减1操作应当是原子操作。为此，信号量通常是在内核中实现的。Linux环境中，有三种类型：<br><strong>Posix（<a target="_blank" rel="noopener" href="https://link.jianshu.com/?t=http://baike.baidu.com/link?url=hYEo6ngm9MlqsQHT3h28baIDxEooeSPX6wr_FdGF-F8mf7wDp2xJWIDtQWGEDxthtPNiJtlsw460g1_N0txJYa">可移植性操作系统接口</a>）有名信号量（使用Posix<br>IPC名字标识）</strong>、 <strong>Posix基于内存的信号量（存放在共享内存区中）</strong> 、 <strong>System V信号量（在内核中维护）</strong><br>。这三种信号量都可用于进程间或线程间的同步。</p>
<p><img src="/images/%E4%B8%A4%E4%B8%AA%E8%BF%9B%E7%A8%8B%E4%BD%BF%E7%94%A8%E4%B8%80%E4%B8%AA%E4%BA%8C%E5%80%BC%E4%BF%A1%E5%8F%B7%E9%87%8F.png" alt="两个进程使用一个二值信号量"></p>
<p><img src="/images/%E4%B8%A4%E4%B8%AA%E8%BF%9B%E7%A8%8B%E6%89%80%E4%BB%A5%E7%94%A8%E4%B8%80%E4%B8%AAPosix%E6%9C%89%E5%90%8D%E4%BA%8C%E5%80%BC%E4%BF%A1%E5%8F%B7%E9%87%8F.png" alt="两个进程所以用一个Posix有名二值信号量"></p>
<p><img src="/images/%E4%B8%80%E4%B8%AA%E8%BF%9B%E7%A8%8B%E4%B8%A4%E4%B8%AA%E7%BA%BF%E7%A8%8B%E5%85%B1%E4%BA%AB%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AD%98%E7%9A%84%E4%BF%A1%E5%8F%B7%E9%87%8F.png" alt="一个进程两个线程共享基于内存的信号量"></p>
<p><strong>信号量与普通整型变量的区别：</strong></p>
<ol>
<li>信号量是非负整型变量，除了初始化之外，它只能通过两个标准原子操作：wait(semap) , signal(semap) ; 来进行访问；</li>
<li>操作也被成为PV原语（P来源于荷兰语proberen”测试”，V来源于荷兰语verhogen”增加”，P表示通过的意思，V表示释放的意思），而普通整型变量则可以在任何语句块中被访问；</li>
</ol>
<p><strong>信号量与互斥量之间的区别：</strong></p>
<ol>
<li>互斥量用于线程的互斥，信号量用于线程的同步。这是互斥量和信号量的根本区别，也就是互斥和同步之间的区别。</li>
</ol>
<p><strong>互斥：</strong> 是指某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，即访问是无序的。<br><strong>同步：</strong> 是指在互斥的基础上（大多数情况），通过其它机制实现访问者对资源的有序访问。<br>在大多数情况下，同步已经实现了互斥，特别是所有写入资源的情况必定是互斥的。少数情况是指可以允许多个访问者同时访问资源</p>
<ol start="2">
<li><p>互斥量值只能为0&#x2F;1，信号量值可以为非负整数。<br>也就是说，一个互斥量只能用于一个资源的互斥访问，它不能实现多个资源的多线程互斥问题。信号量可以实现多个同类资源的多线程互斥和同步。当信号量为单值信号量是，也可以完成一个资源的互斥访问。</p>
</li>
<li><p>互斥量的加锁和解锁必须由同一线程分别对应使用，信号量可以由一个线程释放，另一个线程得到。</p>
</li>
</ol>
<h3 id="套接字（-socket-）"><a href="#套接字（-socket-）" class="headerlink" title="套接字（ socket ）"></a>套接字（ <strong>socket</strong> ）</h3><p>套接字是一种通信机制，凭借这种机制，客户&#x2F;服务器（即要进行通信的进程）系统的开发工作既可以在本地单机上进行，也可以跨网络进行。也就是说它可以让不在同一台计算机但通过网络连接计算机上的进程进行通信。</p>
<p>套接字是支持TCP&#x2F;IP的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。</p>
<p><strong>套接字特性</strong><br>套接字的特性由3个属性确定，它们分别是：域、端口号、协议类型。</p>
<ol>
<li><p>套接字的域**<br>它指定套接字通信中使用的网络介质，最常见的套接字域有两种：<br><strong>一是AF_INET，它指的是Internet网络。</strong><br>当客户使用套接字进行跨网络的连接时，它就需要用到服务器计算机的IP地址和端口来指定一台联网机器上的某个特定服务，所以在使用socket作为通信的终点，服务器应用程序必须在开始通信之前绑定一个端口，服务器在指定的端口等待客户的连接。<br><strong>另一个域AF_UNIX，表示UNIX文件系统，</strong> 它就是文件输入&#x2F;输出，而它的地址就是文件名。</p>
</li>
<li><p>套接字的端口号<br>每一个基于TCP&#x2F;IP网络通讯的程序(进程)都被赋予了唯一的端口和端口号，端口是一个信息缓冲区，用于保留Socket中的输入&#x2F;输出信息，端口号是一个16位无符号整数，范围是0-65535，以区别主机上的每一个程序（端口号就像房屋中的房间号），低于256的端口号保留给标准应用程序，比如pop3的端口号就是110，每一个套接字都组合进了IP地址、端口，这样形成的整体就可以区别每一个套接字。</p>
</li>
<li><p>套接字协议类型<br>因特网提供三种通信机制，<br><strong>一是流套接字，</strong><br>流套接字在域中通过TCP&#x2F;IP连接实现，同时也是AF_UNIX中常用的套接字类型。流套接字提供的是一个有序、可靠、双向字节流的连接，因此发送的数据可以确保不会丢失、重复或乱序到达，而且它还有一定的出错后重新发送的机制。<br><strong>二个是数据报套接字，</strong><br>它不需要建立连接和维持一个连接，它们在域中通常是通过UDP&#x2F;IP协议实现的。它对可以发送的数据的长度有限制，数据报作为一个单独的网络消息被传输,它可能会丢失、复制或错乱到达，UDP不是一个可靠的协议，但是它的速度比较高，因为它并一需要总是要建立和维持一个连接。<br><strong>三是原始套接字，</strong> 原始套接字允许对较低层次的协议直接访问，比如IP、<br>ICMP协议，它常用于检验新的协议实现，或者访问现有服务中配置的新设备，因为RAW<br>SOCKET可以自如地控制Windows下的多种协议，能够对网络底层的传输机制进行控制，所以可以应用原始套接字来操纵网络层和传输层应用。比如，我们可以通过RAW<br>SOCKET来接收发向本机的ICMP、IGMP协议包，或者接收TCP&#x2F;IP栈不能够处理的IP包，也可以用来发送一些自定包头或自定协议的IP包。网络监听技术很大程度上依赖于SOCKET_RAW。</p>
</li>
</ol>
<blockquote>
<p><strong>原始套接字与标准套接字的区别在于：</strong>  </p>
<p>原始套接字可以读写内核没有处理的IP数据包，而流套接字只能读取TCP协议的数据，数据报套接字只能读取UDP协议的数据。因此，如果要访问其他协议发送数据必须使用原始套接字。</p>
</blockquote>
<p><strong>服务器端</strong></p>
<ol>
<li><p>首先服务器应用程序用系统调用socket来创建一个套接字，它是系统分配给该服务器进程的类似文件描述符的资源，它不能与其他的进程共享。</p>
</li>
<li><p>然后，服务器进程会给套接字起个名字，我们使用系统调用bind来给套接字命名。然后服务器进程就开始等待客户连接到这个套接字。</p>
</li>
<li><p>接下来，系统调用listen来创建一个队列并将其用于存放来自客户的进入连接。</p>
</li>
<li><p>最后，服务器通过系统调用accept来接受客户的连接。它会创建一个与原有的命名套接不同的新套接字，这个套接字只用于与这个特定客户端进行通信，而命名套接字（即原先的套接字）则被保留下来继续处理来自其他客户的连接（建立客户端和服务端的用于通信的流，进行通信）。</p>
</li>
</ol>
<p><strong>客户端</strong></p>
<ol>
<li>客户应用程序首先调用socket来创建一个未命名的套接字，然后将服务器的命名套接字作为一个地址来调用connect与服务器建立连接。</li>
<li>一旦连接建立，我们就可以像使用底层的文件描述符那样用套接字来实现双向数据的通信（通过流进行数据传输）。</li>
</ol>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>各种通信方式的比较和优缺点</p>
<ol>
<li>管道：速度慢，容量有限，只有父子进程能通讯</li>
<li>FIFO：任何进程间都能通讯，但速度慢</li>
<li>消息队列：容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题</li>
<li>信号量：不能传递复杂消息，只能用来同步</li>
<li>共享内存区：能够很容易控制容量，速度快，但要保持同步，比如一个进程在写的时候，另一个进程要注意读写的问题，相当于线程中的线程安全，当然，共享内存区同样可以用作线程间通讯，不过没这个必要，线程间本来就已经共享了同一进程内的一块内存</li>
</ol>
<h1 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h1><p>所谓死锁，是指多个进程循环等待它方占有的资源而无限期地僵持下去的局面。</p>
<h2 id="死锁的产生"><a href="#死锁的产生" class="headerlink" title="死锁的产生"></a>死锁的产生</h2><p>如果在计算机系统中同时具备下面四个必要条件时，那麽会发生死锁。换句话说，只要下面四个条件有一个不具备，系统就不会出现死锁。</p>
<ol>
<li><p>互斥条件。即某个资源在一段时间内只能由一个进程占有，不能同时被两个或两个以上的进程占有。这种独占资源如CD-ROM驱动器，打印机等等，必须在占有该资源的进程主动释放它之后，其它进程才能占有该资源。这是由资源本身的属性所决定的。如独木桥就是一种独占资源，两方的人不能同时过桥。</p>
</li>
<li><p>不可抢占条件。进程所获得的资源在未使用完毕之前，资源申请者不能强行地从资源占有者手中夺取资源，而只能由该资源的占有者进程自行释放。如过独木桥的人不能强迫对方后退，也不能非法地将对方推下桥，必须是桥上的人自己过桥后空出桥面（即主动释放占有资源），对方的人才能过桥。</p>
</li>
<li><p>占有且申请条件。进程至少已经占有一个资源，但又申请新的资源；由于该资源已被另外进程占有，此时该进程阻塞；但是，它在等待新资源之时，仍继续占用已占有的资源。还以过独木桥为例，甲乙两人在桥上相遇。甲走过一段桥面（即占有了一些资源），还需要走其余的桥面（申请新的资源），但那部分桥面被乙占有（乙走过一段桥面）。甲过不去，前进不能，又不后退；乙也处于同样的状况。</p>
</li>
<li><p>循环等待条件。存在一个进程等待序列{P1，P2，…，Pn}，其中P1等待P2所占有的某一资源，P2等待P3所占有的某一源，……，而Pn等待P1所占有的的某一资源，形成一个进程循环等待环。就像前面的过独木桥问题，甲等待乙占有的桥面，而乙又等待甲占有的桥面，从而彼此循环等待。</p>
</li>
</ol>
<p>上面我们提到的这四个条件在死锁时会同时发生。也就是说，只要有一个必要条件不满足，则死锁就可以排除。</p>
<h2 id="死锁的预防"><a href="#死锁的预防" class="headerlink" title="死锁的预防"></a>死锁的预防</h2><p>前面介绍了死锁发生时的四个必要条件，只要破坏这四个必要条件中的任意一个条件，死锁就不会发生。这就为我们解决死锁问题提供了可能。一般地，解决死锁的方法分为死锁的预防，避免，检测与恢复三种（注意：死锁的检测与恢复是一个方法）。我们将在下面分别加以介绍。</p>
<p>死锁的预防是保证系统不进入死锁状态的一种策略。它的基本思想是要求进程申请资源时遵循某种协议，从而打破产生死锁的四个必要条件中的一个或几个，保证系统不会进入死锁状态。</p>
<ol>
<li>打破互斥条件。即允许进程同时访问某些资源。但是，有的资源是不允许被同时访问的，像打印机等等，这是由资源本身的属性所决定的。所以，这种办法并无实用价值。</li>
<li>打破不可抢占条件。即允许进程强行从占有者那里夺取某些资源。就是说，当一个进程已占有了某些资源，它又申请新的资源，但不能立即被满足时，它必须释放所占有的全部资源，以后再重新申请。它所释放的资源可以分配给其它进程。这就相当于该进程占有的资源被隐蔽地强占了。这种预防死锁的方法实现起来困难，会降低系统性能。 </li>
<li>打破占有且申请条件。可以实行资源预先分配策略。即进程在运行前一次性地向系统申请它所需要的全部资源。如果某个进程所需的全部资源得不到满足，则不分配任何资源，此进程暂不运行。只有当系统能够满足当前进程的全部资源需求时，才一次性地将所申请的资源全部分配给该进程。由于运行的进程已占有了它所需的全部资源，所以不会发生占有资源又申请资源的现象，因此不会发生死锁。但是，这种策略也有如下缺点：</li>
</ol>
<ul>
<li>在许多情况下，一个进程在执行之前不可能知道它所需要的全部资源。这是由于进程在执行时是动态的，不可预测的；</li>
<li>资源利用率低。无论所分资源何时用到，一个进程只有在占有所需的全部资源后才能执行。即使有些资源最后才被该进程用到一次，但该进程在生存期间却一直占有它们，造成长期占着不用的状况。这显然是一种极大的资源浪费；</li>
<li>降低了进程的并发性。因为资源有限，又加上存在浪费，能分配到所需全部资源的进程个数就必然少了。</li>
</ul>
<ol start="4">
<li>打破循环等待条件，实行资源有序分配策略。采用这种策略，即把资源事先分类编号，按号分配，使进程在申请，占用资源时不会形成环路。所有进程对资源的请求必须严格按资源序号递增的顺序提出。进程占用了小号资源，才能申请大号资源，就不会产生环路，从而预防了死锁。这种策略与前面的策略相比，资源的利用率和系统吞吐量都有很大提高，但是也存在以下缺点：</li>
</ol>
<ul>
<li>限制了进程对资源的请求，同时给系统中所有资源合理编号也是件困难事，并增加了系统开销；</li>
<li>为了遵循按编号申请的次序，暂不使用的资源也需要提前申请，从而增加了进程对资源的占用时间。</li>
</ul>
<h2 id="死锁的避免"><a href="#死锁的避免" class="headerlink" title="死锁的避免"></a>死锁的避免</h2><p>上面我们讲到的死锁预防是排除死锁的静态策略，它使产生死锁的四个必要条件不能同时具备，从而对进程申请资源的活动加以限制，以保证死锁不会发生。下面我们介绍排除死锁的动态策略–死锁的避免，它不限制进程有关申请资源的命令，而是对进程所发出的每一个申请资源命令加以动态地检查，并根据检查结果决定是否进行资源分配。就是说，在资源分配过程中若预测有发生死锁的可能性，则加以避免。这种方法的关键是确定资源分配的安全性。</p>
<ol>
<li>安全序列</li>
</ol>
<p>我们首先引入安全序列的定义：所谓系统是安全的，是指系统中的所有进程能够按照某一种次序分配资源，并且依次地运行完毕，这种进程序列{P1，P2，…，Pn}就是安全序列。如果存在这样一个安全序列，则系统是安全的；如果系统不存在这样一个安全序列，则系统是不安全的。</p>
<p>安全序列{P1，P2，…，Pn}是这样组成的：若对于每一个进程Pi，它需要的附加资源可以被系统中当前可用资源加上所有进程Pj当前占有资源之和所满足，则{P1，P2，…，Pn}为一个安全序列，这时系统处于安全状态，不会进入死锁状态。</p>
<p>虽然存在安全序列时一定不会有死锁发生，但是系统进入不安全状态（四个死锁的必要条件同时发生）也未必会产生死锁。当然，产生死锁后，系统一定处于不安全状态。</p>
<ol start="2">
<li>银行家算法</li>
</ol>
<p>这是一个著名的避免死锁的算法，是由Dijstra首先提出来并加以解决的。</p>
<p>当一个进程申请使用资源的时候，银行家算法通过先 <strong>试探</strong><br>分配给该进程资源，然后通过安全性算法判断分配后的系统是否处于安全状态，若不安全则试探分配作废，让该进程继续等待。</p>
<p><img src="/images/%E9%93%B6%E8%A1%8C%E5%AE%B6%E7%AE%97%E6%B3%95.jpeg" alt="银行家算法"></p>
<h2 id="死锁的检查与恢复"><a href="#死锁的检查与恢复" class="headerlink" title="死锁的检查与恢复"></a>死锁的检查与恢复</h2><h3 id="死锁的检查"><a href="#死锁的检查" class="headerlink" title="死锁的检查"></a>死锁的检查</h3><p>检查死锁的办法就是检查系统中由进程和资源构成的有向图是否构成一个或多个环路，若是，则存在死锁，否则不存在。<br>由于死锁是系统中的恶性小概率事件，死锁检测程序的多次执行往往都不会调用一次死锁解除程序，而这却增加了系统开销，因此在设计操作系统时需要权衡检测精度与时间开销。</p>
<h3 id="死锁的恢复"><a href="#死锁的恢复" class="headerlink" title="死锁的恢复"></a>死锁的恢复</h3><p>一旦在死锁检测时发现了死锁，就要消除死锁，使系统从死锁状态中恢复过来。</p>
<ol>
<li>最简单，最常用的方法就是进行系统的重新启动，不过这种方法代价很大，它意味着在这之前所有的进程已经完成的计算工作都将付之东流，包括参与死锁的那些进程，以及未参与死锁的进程。</li>
<li>撤消进程，剥夺资源。终止参与死锁的进程，收回它们占有的资源，从而解除死锁。这时又分两种情况：一次性撤消参与死锁的全部进程，剥夺全部资源；或者逐步撤消参与死锁的进程，逐步收回死锁进程占有的资源。一般来说，选择逐步撤消的进程时要按照一定的原则进行，目的是撤消那些代价最小的进程，比如按进程的优先级确定进程的代价；考虑进程运行时的代价和与此进程相关的外部作业的代价等因素。</li>
</ol>
<p>此外，还有进程回退策略，即让参与死锁的进程回退到没有发生死锁前某一点处，并由此点处继续执行，以求再次执行时不再发生死锁。虽然这是个较理想的办法，但是操作起来系统开销极大，要有堆栈这样的机构记录进程的每一步变化，以便今后的回退，有时这是无法做到的。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/05/17/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/Elasticsearch%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="merric">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Myoboku">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Myoboku">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/05/17/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/Elasticsearch%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/" class="post-title-link" itemprop="url">ES索引生命周期管理(ILM)</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-05-17 22:30:00" itemprop="dateCreated datePublished" datetime="2023-05-17T22:30:00+00:00">2023-05-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">数据库与中间件</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><code>ES</code>是使用 <code>Java</code> 编写的一种开源搜索引擎，它在内部使用 <code>Lucene</code>做索引与搜索，通过对<br><code>Lucene</code>的封装，隐藏了<code>Lucene</code>的复杂性，取而代之的提供一套简单一致的 <code>RESTful API</code><br>然而，<code>Elasticsearch</code> 不仅仅是 <code>Lucene</code>，并且也不仅仅只是一个全文搜索引擎。</p>
<p>它可以被下面这样准确的形容：</p>
<ul>
<li>一个分布式的<code>实时</code>文档存储，每个字段可以被索引与搜索。</li>
<li>一个分布式实时分析搜索引擎。</li>
<li>能胜任上百个服务节点的扩展，并支持 PB 级别的结构化或者非结构化数据。</li>
</ul>
<p>官网对 <code>Elasticsearch</code> 的介绍是 <code>Elasticsearch</code> 是一个分布式、可扩展、近实时的搜索与数据分析引擎。</p>
<p>其中主要有如下几个核心术语需要理解：</p>
<ul>
<li>词条（<code>Term</code>）： 索引里面最小的存储和查询单元，对于英文来说是一个单词，对于中文来说一般指分词后的一个词。</li>
<li>词典（<code>Term Dictionary</code>）： 或字典，是词条 <code>Term</code> 的集合。搜索引擎的通常索引单位是<code>单词</code>，单词词典是由文档集合中出现过的所有单词构成的字符串集合，单词词典内每条索引项记载单词本身的一些信息以及指向<code>倒排列表</code>的指针。</li>
<li>倒排表（<code>Post list</code>）：一个文档通常由多个词组成，倒排表记录的是某个词在哪些文档里出现过以及出现的位置。每条记录称为一个倒排项（<code>Posting</code>）。倒排表记录的不仅是文档编号，还存储了词频等信息。</li>
<li>倒排文件（<code>Inverted File</code>）： 所有单词的倒排列表往往顺序地存储在磁盘的某个文件里，这个文件被称之为<code>倒排文件</code>，倒排文件是存储倒排索引的物理文件<br>**<code>由属性值来确定记录的位置的结构就是倒排索引</code>**。带有倒排索引的文件称为<code>倒排文件</code></li>
</ul>
<p><code>词典</code>和<code>倒排表</code>是 <code>Lucene</code><br>中很重要的两种数据结构，是实现快速检索的重要基石。<code>词典</code>和<code>倒排文件</code>是分两部分存储的，<code>词典在内存中</code>而<code>倒排文件存储在磁盘</code>上</p>
<h2 id="分片，副本，映射"><a href="#分片，副本，映射" class="headerlink" title="分片，副本，映射"></a>分片，副本，映射</h2><h3 id="分片（Shards）"><a href="#分片（Shards）" class="headerlink" title="分片（Shards）"></a>分片（Shards）</h3><p><code>ES</code> 支持 <code>PB</code> 级全文搜索，当索引上的数据量太大的时候，<code>ES</code><br>通过水平拆分的方式将一个索引上的数据拆分出来分配到不同的数据块上，拆分出来的数据库块称之为一个分片。<br>这类似于 <code>MySQL</code> 的分库分表，只不过 <code>MySQL</code> 分库分表需要借助第三方组件而 <code>ES</code> 内部自身实现了此功能。</p>
<p>在一个多分片的索引中写入数据时，通过路由来确定具体写入哪一个分片中，所以在创建索引的时候需要指定分片的数量，并且分片的数量一旦确定就不能修改。<br>分片的数量和下面介绍的副本数量都是可以通过创建索引时的 <code>Settings</code> 来配置，<code>ES</code> 默认为一个索引创建 5 个主分片,<br>并分别为每个分片创建一个副本。</p>
<pre><code>PUT /myIndex    
&#123;    
   &quot;settings&quot; : &#123;    
      &quot;number_of_shards&quot; : 5,    
      &quot;number_of_replicas&quot; : 1    
   &#125;    
&#125;    
  
</code></pre>
<p><code>ES</code> 通过分片的功能使得索引在规模上和性能上都得到提升，每个分片都是 <code>Lucene</code><br>中的一个索引文件，每个分片必须有一个<code>主分片</code>和<code>零到多个副本</code>。</p>
<h3 id="副本（Replicas）"><a href="#副本（Replicas）" class="headerlink" title="副本（Replicas）"></a>副本（Replicas）</h3><p><code>副本</code>就是对分片的 <code>Copy</code>，每个主分片都有一个或多个副本分片，当主分片异常时，副本可以提供数据的查询等操作。<br>主分片和对应的副本分片是不会在同一个节点上的，所以副本分片数的最大值是 N-1（其中 N 为节点数）。<br>对文档的新建、索引和删除请求都是写操作，必须在主分片上面完成之后才能被复制到相关的副本分片。</p>
<p><code>ES</code> 为了提高写入的能力这个过程是并发写的，同时为了解决并发写的过程中数据冲突的问题，<code>ES</code> 通过乐观锁的方式控制，每个文档都有一个<br><code>_version （版本）</code>号，当文档被修改时版本号递增。<br>一旦所有的副本分片都报告写成功才会向协调节点报告成功，协调节点向客户端报告成功</p>
<p><img src="/images/ES%E9%9B%86%E7%BE%A4.png" alt="ES集群"></p>
<p>从上图可以看出为了达到高可用，<code>Master</code> 节点会避免将主分片和副本分片放在同一个节点上。</p>
<p>假设这时节点 <code>Node1</code> 服务宕机了或者网络不可用了，那么主节点上主分片 S0 也就不可用了。幸运的是还存在另外两个节点能正常工作，这时 <code>ES</code><br>会重新选举新的主节点，而且这两个节点上存在我们所需要的 <code>S0</code> 的所有数据。我们会将 <code>S0</code><br>的副本分片提升为主分片，这个提升主分片的过程是瞬间发生的。此时集群的状态将会为 <code>Yellow</code>。</p>
<p>为什么我们集群状态是 <code>Yellow</code> 而不是 <code>Green</code> 呢？虽然我们拥有所有的 2<br>个主分片，但是同时设置了每个主分片需要对应两份副本分片，而此时只存在一份副本分片。所以集群不能为 <code>Green</code> 的状态。<br>如果我们同样关闭了 <code>Node2</code> ，我们的程序依然可以保持在不丢失任何数据的情况下运行，因为 <code>Node3</code> 为每一个分片都保留着一份副本。<br>如果我们重新启动 <code>Node1</code> ，集群可以将缺失的副本分片再次进行分配，那么集群的状态又将恢复到原来的正常状态。<br>如果 <code>Node1</code> 依然拥有着之前的分片，它将尝试去重用它们，只不过这时 <code>Node1</code><br>节点上的分片不再是主分片而是副本分片了，如果期间有更改的数据只需要从主分片上复制修改的数据文件即可。</p>
<p>小结：</p>
<ul>
<li>将数据分片是为了提高可处理数据的容量和易于进行水平扩展，为分片做副本是为了提高集群的稳定性和提高并发量。</li>
<li>副本是乘法，越多消耗越大，但也越保险。分片是除法，分片越多，单分片数据就越少也越分散。</li>
<li>副本越多，集群的可用性就越高，但是由于每个分片都相当于一个 Lucene 的索引文件，会占用一定的文件句柄、内存及 CPU。并且分片间的数据同步也会占用一定的网络带宽，所以索引的分片数和副本数也不是越多越好。</li>
</ul>
<h3 id="映射（Mapping）"><a href="#映射（Mapping）" class="headerlink" title="映射（Mapping）"></a>映射（Mapping）</h3><p><code>映射</code>是用于定义 <code>ES</code> 对索引中字段的存储类型、分词方式和是否存储等信息，就像数据库中的<code>Schema</code><br>，描述了文档可能具有的字段或属性、每个字段的数据类型。<br>只不过关系型数据库建表时必须指定字段类型，而 <code>ES</code> 对于字段类型可以不指定然后动态对字段类型猜测，也可以在创建索引时具体指定字段的类型。<br>对字段类型根据数据格式自动识别的映射称之为动态映射（<code>Dynamic Mapping</code>），我们创建索引时具体定义字段类型的映射称之为静态映射或显示映射（<code>Explicit Mapping</code>）。</p>
<p>在讲解动态映射和静态映射的使用前，我们先来了解下 ES 中的数据有哪些字段类型？之后我们再讲解为什么我们创建索引时需要建立静态映射而不使用动态映射。</p>
<p><code>ES（v6.8）</code>中字段数据类型主要有以下几类：</p>
<table>
<thead>
<tr>
<th>类别</th>
<th>数据类型</th>
</tr>
</thead>
<tbody><tr>
<td>核心类型</td>
<td>text，keywords，long，integer，short，double，data，boolean</td>
</tr>
<tr>
<td>复杂类型</td>
<td>Object，Nested</td>
</tr>
<tr>
<td>地理类型</td>
<td>geo_point，geo_shape</td>
</tr>
<tr>
<td>特殊类型</td>
<td>ip，completion，token_count，join</td>
</tr>
</tbody></table>
<p><code>Text</code> 用于索引全文值的字段，例如电子邮件正文或产品说明。这些字段是被分词的，它们通过分词器传递<br>，以在被索引之前将字符串转换为单个术语的列表。分析过程允许 <code>Elasticsearch</code><br>搜索单个单词中每个完整的文本字段。文本字段不用于排序，很少用于聚合。<br><code>Keyword</code> 用于索引结构化内容的字段，例如电子邮件地址，主机名，状态代码，邮政编码或标签。它们通常用于过滤，排序，和聚合。Keyword<br>字段只能按其确切值进行搜索。</p>
<p>通过对字段类型的了解我们知道有些字段需要明确定义的，例如某个字段是 Text 类型还是 Keyword<br>类型差别是很大的，时间字段也许我们需要指定它的时间格式，还有一些字段我们需要指定特定的分词器等等。</p>
<p>如果采用动态映射是不能精确做到这些的，自动识别常常会与我们期望的有些差异。所以创建索引的时候一个完整的格式应该是指定<code>分片和副本数以及 Mapping</code>的定义，如下：</p>
<pre><code>PUT my_index     
&#123;    
   &quot;settings&quot; : &#123;    
      &quot;number_of_shards&quot; : 5,    
      &quot;number_of_replicas&quot; : 1    
   &#125;    
  &quot;mappings&quot;: &#123;    
    &quot;_doc&quot;: &#123;     
      &quot;properties&quot;: &#123;     
        &quot;title&quot;:    &#123; &quot;type&quot;: &quot;text&quot;  &#125;,     
        &quot;name&quot;:     &#123; &quot;type&quot;: &quot;text&quot;  &#125;,     
        &quot;age&quot;:      &#123; &quot;type&quot;: &quot;integer&quot; &#125;,      
        &quot;created&quot;:  &#123;    
          &quot;type&quot;:   &quot;date&quot;,     
          &quot;format&quot;: &quot;strict_date_optional_time||epoch_millis&quot;    
        &#125;    
      &#125;    
    &#125;    
  &#125;    
&#125;    
  
</code></pre>
<h2 id="ES机制原理"><a href="#ES机制原理" class="headerlink" title="ES机制原理"></a>ES机制原理</h2><h3 id="写索引原理"><a href="#写索引原理" class="headerlink" title="写索引原理"></a>写索引原理</h3><p>下图描述了 3 个节点的集群，共拥有 12 个分片，其中有 4 个主分片（S0、S1、S2、S3）和 8<br>个副本分片（R0、R1、R2、R3），每个主分片对应两个副本分片，节点 1 是主节点（Master 节点）负责整个集群的状态。</p>
<p><img src="/images/3%E4%B8%AA%E8%8A%82%E7%82%B9%E7%9A%84ES%E9%9B%86%E7%BE%A4.png" alt="3个节点的ES集群"></p>
<p><code>写索引</code>是<code>只能写在主分片</code>上，然后同步到副本分片。这里有四个主分片，一条数据 <code>ES</code> 是根据什么规则写到特定分片上的呢？<br>这条索引数据为什么被写到 S0 上而不写到 S1 或 S2 上？那条数据为什么又被写到 S3 上而不写到 S0 上了？</p>
<p>首先这肯定不会是随机的，否则将来要获取文档的时候我们就不知道从何处寻找了。实际上，这个过程是根据下面这个公式决定的：</p>
<pre><code>shard = hash(routing) % number_of_primary_shards    
  
</code></pre>
<p><code>Routing</code> 是一个可变值，默认是文档的 <code>_id</code> ，也可以设置成一个自定义的值。<br><code>Routing</code> 通过 <code>Hash</code> 函数生成一个数字，然后这个数字再除以 <code>number_of_primary_shards</code><br>（主分片的数量）后得到余数。这个在 <code>0</code> 到 <code>number_of_primary_shards-1</code> 之间的余数，就是我们所寻求的文档所在分片的位置。</p>
<p>这就解释了为什么我们要在创建索引的时候就确定好主分片的数量并且永远不会改变这个数量：**<code>因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了</code>**</p>
<p>由于在 <code>ES</code> 集群中每个节点通过上面的计算公式都知道集群中的文档的存放位置，所以每个节点都有处理读写请求的能力。<br>在一个写请求被发送到某个节点后，该节点即为前面说过的<code>协调节点</code>，<code>协调节点</code>会根据路由公式计算出需要写到哪个分片上，再将请求转发到该分片的主分片节点上</p>
<p><img src="/images/%E5%86%99%E8%AF%B7%E6%B1%82.png" alt="写请求"></p>
<p>假如此时数据通过路由计算公式取余后得到的值是</p>
<pre><code>shard=hash(routing)%4=0  
  
</code></pre>
<p>则具体流程如下：</p>
<ul>
<li>客户端向 <code>ES1</code> 节点（协调节点）发送写请求，通过路由计算公式得到值为 0，则当前数据应被写到主分片 S0 上。</li>
<li><code>ES1</code> 节点将请求转发到 <code>S0</code> 主分片所在的节点 ES3，ES3 接受请求并写入到磁盘。</li>
<li>并发将数据复制到两个副本分片 <code>R0</code> 上，其中通过乐观并发控制数据的冲突。一旦所有的副本分片都报告成功，则节点 <code>ES3</code> 将向协调节点报告成功，协调节点向客户端报告成功。</li>
</ul>
<h3 id="存储原理"><a href="#存储原理" class="headerlink" title="存储原理"></a>存储原理</h3><p>上面介绍了在 <code>ES</code> 内部索引的写处理流程，这个流程是在 <code>ES</code><br>的<code>内存</code>中执行的，数据被分配到特定的<code>分片</code>和<code>副本</code>上之后，最终是存储到磁盘上的，这样在断电的时候就不会丢失数据。<br>具体的存储路径可在配置文件 <code>../config/elasticsearch.yml</code> 中进行设置，默认存储在安装目录的 <code>Data</code> 文件夹下。<br>建议不要使用默认值，因为若 <code>ES</code> 进行了升级，则有可能导致数据全部丢失：</p>
<pre><code>path.data: /path/to/data  //索引数据    
path.logs: /path/to/logs  //日志记录    
  
</code></pre>
<h4 id="分段存储"><a href="#分段存储" class="headerlink" title="分段存储"></a>分段存储</h4><p>索引文档以<code>段</code>的形式存储在磁盘上，索引文件被拆分为多个<code>子文件</code>，则每个<code>子文件</code>叫作<code>段</code>，每一个段本身都是一个<code>倒排索引</code>，并且段具有不变性，一旦索引的数据被写入硬盘，就不可再修改。</p>
<p>在底层采用了<code>分段存储模式</code>，使它在读写时几乎完全避免了锁的出现，大大提升了读写性能。<br>段被写入到磁盘后会生成一个<code>提交点</code>，<code>提交点</code>是一个用来记录所有提交后段信息的文件。</p>
<p><strong><code>一个段一旦拥有了提交点，就说明这个段只有读的权限，失去了写的权限</code></strong> 。相反，<br>**<code>当段在内存中时，就只有写的权限，而不具备读数据的权限，意味着不能被检索</code>**。</p>
<p>段的概念提出主要是因为：在早期全文检索中为整个文档集合建立了一个很大的倒排索引，并将其写入磁盘中。如果索引有更新，就需要重新全量创建一个索引来替换原来的索引。这种方式在数据量很大时效率很低，并且由于创建一次索引的成本很高，所以对数据的更新不能过于频繁，也就不能保证时效性。</p>
<p>索引文件分段存储并且不可修改，那么新增、更新和删除如何处理呢？</p>
<ul>
<li><code>新增</code>，新增很好处理，由于数据是新的，所以只需要对当前文档新增一个段就可以了。</li>
<li><code>删除</code>，由于不可修改，所以对于删除操作，不会把文档从旧的段中移除而是通过新增一个 <code>.del</code> 文件，文件中会列出这些被删除文档的段信息。这个被标记删除的文档仍然可以被查询匹配到， 但它会在最终结果被返回前从结果集中移除。</li>
<li><code>更新</code>，不能修改旧的段来进行反映文档的更新，其实更新相当于是<code>删除</code>和<code>新增</code>这两个动作组成。会将旧的文档在 <code>.del</code> 文件中标记删除，然后文档的新版本被索引到一个新的段中。可能两个版本的文档都会被一个查询匹配到，但被删除的那个旧版本文档在结果集返回前就会被移除。</li>
</ul>
<p>段被设定为不可修改具有一定的优势也有一定的缺点，优势主要表现在：</p>
<ul>
<li>不需要锁，如果从来不更新索引，那就不需要担心多进程同时修改数据的问题。</li>
<li>一旦索引被读入内核的文件系统缓存，便会留在哪里，由于其不变性。只要文件系统缓存中还有足够的空间，那么大部分读请求会直接请求内存，而不会命中磁盘。这提供了很大的性能提升。</li>
<li>其它缓存(像 <code>Filter</code> 缓存)，在索引的生命周期内始终有效。它们不需要在每次数据改变时被重建，因为数据不会变化。</li>
<li>写入单个大的倒排索引允许数据被压缩，减少磁盘 <code>I/O</code> 和需要被缓存到内存的索引的使用量。</li>
</ul>
<p>段的不变性的缺点如下：</p>
<ul>
<li>当对旧数据进行删除时，旧数据不会马上被删除，而是在 <code>.del</code> 文件中被标记为删除。而旧数据只能等到段更新时才能被移除，这样会造成大量的空间浪费。</li>
<li>若有一条数据频繁的更新，每次更新都是新增新的标记旧的，则会有大量的空间浪费。</li>
<li>每次新增数据时都需要新增一个段来存储数据。当段的数量太多时，对服务器的资源例如文件句柄的消耗会非常大。</li>
<li>在查询的结果中包含所有的结果集，需要排除被标记删除的旧数据，这增加了查询的负担。</li>
</ul>
<h4 id="延迟写策略"><a href="#延迟写策略" class="headerlink" title="延迟写策略"></a>延迟写策略</h4><p>介绍完了存储的形式，那么索引写入到磁盘的过程是怎样的？是否是直接调 <code>Fsync</code>物理性地写入磁盘？<br>答案是显而易见的，如果是直接写入到磁盘上，磁盘的 <code>I/O</code> 消耗上会严重影响性能。那么当写数据量大的时候会造成 <code>ES</code><br>停顿卡死，查询也无法做到快速响应。如果真是这样 <code>ES</code> 也就不会称之为近实时全文搜索引擎了。</p>
<p>为了提升写的性能，<code>ES</code><br>并没有每新增一条数据就增加一个段到磁盘上，而是采用延迟写的策略。每当有新增的数据时，就将其先写入到内存中，在<code>内存</code>和<code>磁盘</code>之间是<code>文件系统缓存</code>。<br>当达到默认的时间（1 秒钟）或者内存的数据达到一定量时，会触发一次刷新（<code>Refresh</code>），将内存中的数据生成到一个新的段上并缓存到文件缓存系统<br>上，稍后再被刷新到磁盘中并生成提交点。<br>这里的<code>内存</code>使用的是 <code>ES</code> 的 <code>JVM</code> 内存，而文件缓存系统使用的是操作系统的内存。</p>
<p>新的数据会继续的被写入内存，但内存中的数据并不是以段的形式存储的，因此不能提供检索功能。由<code>内存</code>刷新到文件缓存系统的时候会生成新的段，并<code>将段打开</code>以供<code>搜索使用</code>，而不需要等到被刷新到磁盘。</p>
<p>在 <code>Elasticsearch</code> 中，写入和打开一个新段的轻量的过程叫做 <code>Refresh</code><br>（即内存刷新到文件缓存系统）。默认情况下每个分片会每秒自动刷新一次。这就是为什么我们说 <code>Elasticsearch</code><br>是<code>近实时搜索</code>，因为文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。<br>我们也可以手动触发 <code>Refresh</code>，<code>POST /_refresh</code> 刷新所有索引，<code>POST /nba/_refresh</code> 刷新指定的索引。</p>
<p><code>注意</code>：尽管刷新是比提交轻量很多的操作，它还是会有性能开销。当写测试的时候，<br>手动刷新很有用，但是不要在生产环境下每次索引一个文档都去手动刷新。而且并不是所有的情况都需要每秒刷新。</p>
<p>假如正在使用 <code>Elasticsearch</code> 索引大量的日志文件， 想优化索引速度而不是近实时搜索。这时可以在创建索引时在 <code>Settings</code> 中通过调大<br><code>refresh_interval = &quot;30s&quot;</code> 的值 ， 降低每个索引的刷新频率，设值时需要注意后面带上时间单位，否则默认是毫秒。当<br><code>refresh_interval=-1</code> 时表示关闭索引的自动刷新。</p>
<p>虽然通过延时写的策略可以减少数据往磁盘上写的次数并提升了整体的写入能力，但是我们知道文件缓存系统也是内存空间，属于操作系统的内存，只要是内存都存在断电或异常情况下丢失数据的危险。<br>为了避免丢失数据，<code>Elasticsearch</code> 添加了事务日志（<code>Translog</code>），事务日志记录了所有还没有持久化到磁盘的数据</p>
<p><img src="/images/%E4%BA%8B%E5%8A%A1%E6%97%A5%E5%BF%97%E5%90%8E%E5%86%99%E7%B4%A2%E5%BC%95%E7%9A%84%E6%B5%81%E7%A8%8B.png" alt="事务日志后写索引的流程"></p>
<p>添加了事务日志后整个写索引的流程如上图所示：</p>
<ul>
<li>一个新文档被索引之后，先被写入到内存中，但是为了防止数据的丢失，会追加一份数据到事务日志中。</li>
<li>不断有新的文档被写入到内存，同时也都会记录到事务日志中。这时新数据还不能被检索和查询。</li>
<li>当达到默认的刷新时间或内存中的数据达到一定量后，会触发一次 <code>Refresh</code>，将内存中的数据以一个新段形式刷新到文件缓存系统中并清空内存。这时虽然新段未被提交到磁盘，但是可以提供文档的检索功能且不能被修改。</li>
<li>随着新文档索引不断被写入，当日志数据大小超过 <code>512M</code> 或者时间超过 30 分钟时，会触发一次 <code>Flush</code></li>
<li>内存中的数据被写入到一个新段同时被写入到文件缓存系统，文件系统缓存中数据通过 <code>Fsync</code> 刷新到磁盘中，生成提交点，日志文件被删除，创建一个空的新日志。</li>
</ul>
<p>通过这种方式当断电或需要重启时，<code>ES</code> 不仅要根据提交点去加载已经持久化过的段，还需要工具 <code>Translog</code><br>里的记录，把未持久化的数据重新持久化到磁盘上，避免了数据丢失的可能。</p>
<h4 id="段合并"><a href="#段合并" class="headerlink" title="段合并"></a>段合并</h4><p>由于自动刷新流程每秒会创建一个新的段 ，这样会导致短时间内的段数量暴增。而段数目太多会带来较大的麻烦。每一个段都会消耗文件句柄、内存和 CPU<br>运行周期。更重要的是，每个搜索请求都必须轮流检查每个段然后合并查询结果，所以段越多，搜索也就越慢。</p>
<p><code>Elasticsearch</code> 通过在后台定期进行段合并来解决这个问题。小的段被合并到大的段，然后这些大的段再被合并到更大的段。</p>
<p>段合并的时候会将那些旧的已删除文档从文件系统中清除。被删除的文档不会被拷贝到新的大段中。合并的过程中不会中断索引和搜索。</p>
<p><img src="/images/%E6%AE%B5%E5%90%88%E5%B9%B6.png" alt="段合并"></p>
<p>段合并在进行索引和搜索时会自动进行，合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中，**<code>这些段既可以是未提交的也可以是已提交的</code>**<br>合并结束后老的段会被删除，新的段被 <code>Flush</code> 到磁盘，同时写入一个包含新段且排除旧的和较小的段的新提交点，新的段被打开可以用来搜索。</p>
<p>段合并的计算量庞大， 而且还要吃掉大量磁盘 I&#x2F;O，段合并会拖累写入速率，如果任其发展会影响搜索性能。<br><code>Elasticsearch</code> 在默认情况下会对合并流程进行资源限制，所以搜索仍然有足够的资源很好地执行。</p>
<h2 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h2><h3 id="存储设备"><a href="#存储设备" class="headerlink" title="存储设备"></a>存储设备</h3><p>磁盘在现代服务器上通常都是瓶颈。<code>Elasticsearch</code> 重度使用磁盘，磁盘能处理的吞吐量越大，节点就越稳定。</p>
<p>这里有一些优化磁盘 I&#x2F;O 的技巧：</p>
<ul>
<li>使用 SSD。比机械磁盘优秀多了。</li>
<li>使用 RAID 0。条带化 RAID 会提高磁盘 I&#x2F;O，代价显然就是当一块硬盘故障时整个就故障了。不要使用镜像或者奇偶校验 RAID 因为副本已经提供了这个功能。</li>
<li>使用多块硬盘，并允许 <code>Elasticsearch</code> 通过多个 <code>path.data</code> 目录配置把数据条带化分配到它们上面。</li>
<li>不要使用远程挂载的存储，比如 NFS 或者 SMB&#x2F;CIFS。这个引入的延迟对性能来说完全是背道而驰的。</li>
</ul>
<h3 id="内部索引优化"><a href="#内部索引优化" class="headerlink" title="内部索引优化"></a>内部索引优化</h3><p><code>Elasticsearch</code> 为了能快速找到某个 <code>Term</code>，先将所有的 <code>Term</code> 排个序，然后根据二分法查找 <code>Term</code>，时间复杂度为<br><code>logN</code>，就像通过字典查找一样，这就是 <code>Term Dictionary</code>。<br>现在再看起来，似乎和传统数据库通过 <code>B-Tree</code> 的方式类似。但是如果 Term 太多，<code>Term Dictionary</code><br>也会很大，放内存不现实，于是有了 <code>Term Index</code>。<br>就像字典里的索引页一样，A 开头的有哪些 Term，分别在哪页，可以理解 <code>Term Index</code>是一棵树。这棵树不会包含所有的 <code>Term</code>，它包含的是<br><code>Term</code> 的一些前缀。通过 <code>Term Index</code> 可以快速地定位到 <code>Term Dictionary</code> 的某个<br><code>Offset</code>，然后从这个位置再往后顺序查找。</p>
<p>在内存中用 <code>FST</code> 方式压缩 <code>Term Index</code>，<code>FST</code> 以字节的方式存储所有的 <code>Term</code>，这种压缩方式可以有效的缩减存储空间，使得<br><code>Term Index</code> 足以放进内存，但这种方式也会导致查找时需要更多的 CPU 资源。</p>
<p>对于存储在磁盘上的倒排表同样也采用了压缩技术减少存储所占用的空间。</p>
<p><img src="/images/FST.jpeg" alt="FST"></p>
<h3 id="调整配置参数"><a href="#调整配置参数" class="headerlink" title="调整配置参数"></a>调整配置参数</h3><p>调整配置参数建议如下：</p>
<ul>
<li>给每个文档指定有序的具有压缩良好的序列模式 ID，避免随机的 <code>UUID-4</code>这样的 ID，这样的 ID 压缩比很低，会明显拖慢 Lucene。</li>
<li>对于那些不需要聚合和排序的索引字段禁用 <code>Doc values</code>。<code>Doc Values</code> 是有序的基于 <code>document=&gt;field value</code> 的映射列表。</li>
<li>不需要做模糊检索的字段使用 <code>Keyword</code> 类型代替 Text 类型，这样可以避免在建立索引前对这些文本进行分词。</li>
<li>如果搜索结果不需要近实时的准确度，考虑把每个索引的 <code>index.refresh_interval</code> 改到 <code>30s</code></li>
<li>如果在做大批量导入，导入期间可以通过设置这个值为 <code>-1</code> 关掉刷新，还可以通过设置 <code>index.number_of_replicas: 0</code> 关闭副本。别忘记在完工的时候重新开启它。</li>
<li>避免深度分页查询建议使用 <code>Scroll</code> 进行分页查询。普通分页查询时，会创建一个 <code>from+size</code> 的空优先队列，每个分片会返回 <code>from+size</code> 条数据，默认只包含文档 ID 和得分 Score 给协调节点。</li>
<li>如果有 N 个分片，则协调节点再对<code>（from+size）×n</code>条数据进行二次排序，然后选择需要被取回的文档。当 <code>from</code> 很大时，排序过程会变得很沉重，占用 CPU 资源严重。</li>
<li>减少映射字段，只提供需要检索，聚合或排序的字段。其他字段可存在其他存储设备上，例如 Hbase，在 ES 中得到结果后再去 Hbase 查询这些字段。</li>
<li>创建索引和查询时指定路由 <code>Routing</code> 值，这样可以精确到具体的分片查询，提升查询效率。路由的选择需要注意数据的分布均衡。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/05/17/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/HIVE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="merric">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Myoboku">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Myoboku">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/05/17/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/HIVE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">Hive学习笔记</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-05-17 22:30:00" itemprop="dateCreated datePublished" datetime="2023-05-17T22:30:00+00:00">2023-05-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">数据库与中间件</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>因为工作中用到了通过Hive从公司数据仓库拉取数据，而之前也没有接触过大数据相关知识，了解了一下Hadoop相关原理，并没有实际使用Hadoop做过什么，或者实现Hive直接功能实现，所以这篇总结可能也很皮毛</p>
<h1 id="Hadoop是什么"><a href="#Hadoop是什么" class="headerlink" title="Hadoop是什么"></a>Hadoop是什么</h1><p>自己了解Hive之前先读了一遍《Hadoop权威指南》，里面的基本下载启动是照着做了，不过有的代码编写没做，Hadoop的总结写到这里吧，毕竟刚入门，能总结的东西也不是很多很深入。</p>
<p><img src="/images/hadoop%E6%9E%B6%E6%9E%84.png" alt="hadoop架构"></p>
<p>我们遇到的问题很简单：在硬盘存储容量多年不断提升的同时，访问速度（硬盘数据读取速度）却没有与时俱进。1990年，一个普通硬盘可以存储1370MB的数据，传输速度为4.4MB&#x2F;S,因此只需要5分钟就可以读完整个硬盘中的数据。20年过了，1TB的硬盘已然成为主流，氮气数据传输速度为100MB&#x2F;S,读完整个硬盘中的数据至少得花2.5个小时。</p>
<p>读完整个硬盘中的数据需要更长时间。写入数据就更别提了。一个很简单的，减少读取时间的办法是同时从多个硬盘上读数据。试想，如果我们有100个硬盘。每个硬盘存储1%的数据，并行读取，那么不到两分钟就可以读完所有数据。</p>
<p>仅使用硬盘容量的1%似乎很浪费，但是我们可以存储100个数据集，每个数据集1TB。并实现共享硬盘的读取。可以想象，用户肯定很乐于通过硬盘共享来缩短数据分析时间；并且，从统计角度来看，用户的分析工作都是在不同时间点进行的，所以彼此之间的干扰并不大。</p>
<p>虽然如此，但要对多个硬盘中的数据并行进行读写数据，还有更多问题要解决。第一个需要解决的是硬件故障问题，一旦开始使用多个硬件，其中个别硬件就很有可能发生故障。为了避免数据丢失，最常用的做法是复制：系统保存数据的复本。一旦有系统发生故障，就可以使用另外保存的复本。例如，冗余硬盘阵列（RAID）就是按这个原理实现的，另外，Hadoop文件系统（HDFS，Hadoop<br>Distributed[分布式的] File System）也是一类，不过它采用的方法稍有不同，这个在后面会详细说明。</p>
<p>第二个问题是大多数分析任务需要以某种方式结合大部分数据来共同完成分析，即从一个硬盘读取的数据可能需要与从另外99个硬盘中读取的数据结合使用，各种分布式系统允许结合不同来源的数据进行分析，但保证其正确性是一个非常大的挑战。MapReduce提出一个编程模型，该模型抽象出这些硬盘读写问题并将其转化为对一个数据集（由键值对组成）的计算。后面会详细讨论这个模型，这样的计算由map和reduce两部分组成，而且只有这两部分提供对外的接口。与HDFS类似，MapReduce自身也有很高的可靠性。</p>
<p>简而言之，Hadoop为我们提供了一个可靠的共享存储和分析系统，HDFS实现数据的存储，MapReduce实现数据的分析和处理。虽然Hadoop还有其他功能，但HDFS和MapReduce是它的核心价值。</p>
<p>MapReduce看似采用一种蛮力方法。每个查询需要处理整个数据集或至少一个数据集的绝大部分。但反过来想，这也正是它的能力。MapReduce是一个批量查询处理器，能够在合理的时间范围内处理针对整个数据集的动态查询【这里指查询的内容是动态的，Hadoop并不能处理动态的数据，处理动态的数据用Spark】。它改变了我们队数据的传统看法，解放了以前只是保存在磁带和硬盘上的数据。它让我们有机会对数据进行创新。以前需要很长时间处理才能获得结果的问题，到现在变得顷刻之间就迎刃而解，同时还可以引发新的问题和新的见解。</p>
<p>1.3.1关系型数据库管理系统（简称RDBMS r&#x3D;relationnal关系 db&#x3D;database数据库 m&#x3D;management管理<br>s&#x3D;system系统）</p>
<p>为什么不能用数据库来对大量硬盘上的大规模数据进行批量分析呢？我们为什么需要MapReduce?</p>
<p>这两个问题的答案来自于计算机硬盘的另一个发展趋势，寻址时间的提升远远不低敌于传输速率的提升。寻址是将磁头移动到特定硬盘位置进行读写操作的过程。它是导致磁盘操作延迟的主要原因，而传输速率取决于硬盘的贷款。</p>
<p>如果数据访问模式中包含大量的硬盘寻址，那么读取大量数据集j就必然会花更长的时间（相较于流数据读取模式，流读取主要取决于传输速率）。另一方面，如果数据库系统只更新一小部分记录，那么传统的B树就更有优势（关系型数据库中使用的一种数据结构，受限于寻址的比例）。但数据库系统如果有大量数据更新时，B树的效率就明显落后于MapReduce，因为需要使用“排序&#x2F;合并”(sort&#x2F;merge:合并)来重建数据库。</p>
<p>在许多情况下，可以将MapReduce视为关系型数据库管理系统的补充。两个系统之间的差异如表：<br><img src="/images/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8CMapReduce%E5%B7%AE%E5%BC%82.jpg" alt="关系型数据库和MapReduce差异"></p>
<p>MapReduce比较适合批处理方式处理需要分析整个数据集的问题，尤其是动态分析。RDBMS适用于点查询和更新，数据集被索引之后，数据库系统能够提供延迟的数据检索和快速的少量数据更新。MapReduce适合一次写入、多次读取数据的应用，关系型数据库则更适合持续更新的数据集。</p>
<p>MapReduce和关系型数据库之间的另一个区别在于它们所操作的数据集的机构化程度。结构化程度是具有既定格式的实体化数据，如XML文档或满足特定格式的数据库表。这是RDBMS包括的内容。另一方面，半结构化数据比较松散，虽然可能有格式，但经常被忽略，所以它只能作为对数据结构的一般性指导。例如电子表格，它在结构上是由单元格组成的网格，但是每个单元格内可以保证任何形式的数据。非结构化数据没有什么特别的内部结构，例如纯文本或图像数据。MapReduce对非结构化或半结构化数据非常有效，因为它是在处理数据时才对数据进行解释。换句话说，MapReduce输入的键和值并不是数据固有的属性，而是分析数据的人来选的。</p>
<p>关系型数据往往是规范的，以保证其数据的完整性且不含冗余。规范给MapReduce带来了问题，因为它使记录读取成为非本地操作，而MapReduce的核心假设之一偏偏就是可以进行（高速的）流读写操作。</p>
<p>Web服务器日志是典型非规范化数据记录（例如，每次都需要记录客户端主机全名，只会导致同一客户端的全名多次出现），这也是MapReduce非常适用于分析各种日志文件的原因之一。</p>
<p>MapReduce是一种线性的可伸缩编程模型。程序员要写两个函数，分别为map函数和reduce函数，每个函数定义从一个键值对集合到另一个键值对集合的映射，这些函数不必关注数据集及其所用集群的大小，可以原封不动地应用于小规模数据集或大规模的数据集。更重要的是，如果输入的数据量是原来的两倍，那么运行的时间也需要两倍，但如果集群是原来的两倍，作业的运行速度却仍然与原来一样快。SQL查询一般不具备该特性。</p>
<p>但是，在不久的将来，关系型数据库和MapReduce系统之间的差异很可能变得模糊。关系型数据库都开始吸收MapReduce的一些思路m另一方面，基于MapReduce的高级查询语言使传统数据库的程序员更容易接受MapReduce系统。</p>
<h1 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h1><p>MapReduce是一种 <strong>适合处理大量数据的编程模型</strong><br>。Hadoop能够运行用各种语言编写的MapReduce程序：Java，Ruby，Python和C++。 <strong>MapReduce程序本质上是并行的</strong><br>，因此对于使用群集中的多台机器执行大规模数据分析非常有用。</p>
<h2 id="处理流程"><a href="#处理流程" class="headerlink" title="处理流程"></a>处理流程</h2><p>MapReduce 处理数据过程主要分成 <strong>Map</strong> 和 <strong>Reduce</strong> 两个阶段。首先执行 Map 阶段，再执行 Reduce 阶段。Map 和<br>Reduce 的处理逻辑由用户自定义实现，但要符合 MapReduce 框架的约定。处理流程如下所示：</p>
<ol>
<li>在正式执行 Map 前，需要将输入数据进行 <strong>分片</strong> 。所谓分片，就是将输入数据切分为大小相等的数据块，每一块作为单个 Map Task 的输入被处理，以便于多个 Map Task 同时工作。</li>
<li>分片完毕后，多个 Map Task 便可同时工作。每个 Map Task 在读入各自的数据后，进行计算处理，最终输出给 Reduce。Map Task 在输出数据时，需要为每一条输出数据指定一个 Key，这个 Key 值决定了这条数据将会被发送给哪一个 Reduce Task。 <strong>Key 值和 Reduce Task 是多对一的关系</strong> ，具有相同 Key 的数据会被发送给同一个 Reduce Task，单个 Reduce Task 有可能会接收到多个 Key 值的数据。</li>
<li>在进入 Reduce 阶段之前，MapReduce 框架会对数据按照 Key 值 <strong>排序</strong> ，使得具有相同 Key 的数据彼此相邻。如果指定了 <strong>合并操作（Combiner）</strong> ，框架会调用 Combiner，它负责对中间过程的输出具有相同 Key 的数据进行本地的聚集，这会有助于降低从Mapper到 Reducer数据传输量。Combiner 的逻辑可以自定义实现。这部分的处理通常也叫做 <strong>洗牌（Shuffle）</strong> 。</li>
<li>接下来进入 Reduce 阶段。相同 Key 的数据会到达同一个 Reduce Task。同一个 Reduce Task 会接收来自多个 Map Task 的数据。每个 Reduce Task 会对 Key 相同的多个数据进行 Reduce 操作。最后，一个 Key 的多条数据经过 Reduce 的作用后，将变成一个值。</li>
</ol>
<p><img src="/images/Map%E4%BB%BB%E5%8A%A1%E5%A4%84%E7%90%86.jpg" alt="Map任务处理"></p>
<p><img src="/images/reduce%E4%BB%BB%E5%8A%A1%E5%A4%84%E7%90%86.jpg" alt="reduce任务处理"></p>
<h2 id="MapReduce运行过程的深入了解"><a href="#MapReduce运行过程的深入了解" class="headerlink" title="MapReduce运行过程的深入了解"></a>MapReduce运行过程的深入了解</h2><p>从前面的WordCount可以看出， 一个MapReduce作业经过了input,map,combine,reduce,output<br>五个阶段,其中combine阶段并不一定发生， map输出的中间结果被分发到reducer的过程被称为shuffle （数据混洗）。</p>
<h5 id="从输入到输出的状态"><a href="#从输入到输出的状态" class="headerlink" title="从输入到输出的状态"></a>从输入到输出的状态</h5><p><img src="/images/Mapreduce%E8%BF%90%E8%A1%8C%E8%BF%87%E7%A8%8B.png" alt="Mapreduce运行过程"></p>
<p>在shuffle阶段还会发生copy（复制）和sort（排序)。<br>在MapReduce<br>的过程中，一个作业被分成Map和Reduce计算两个阶段，它们分别由两个或者多个Map任务和Reduce任务组成，这个在前面已经说过了。Reduce任务默认会在Map任务数量完成5%后才开始启动。</p>
<p>Map任务的执行过程可概括为：</p>
<ol>
<li>首先通过用户指定的Inputformat类中的getSplits方法和next方法将输入文件切片并解析成键值对作为map函数的输入。</li>
<li>然后map函数经过处理之后输出并将中间结果交给指定的Partitioner处理，确保中间结果分发到指定的Reduce任务处理，此时如果用户指定了Combiner，将执行combine操作。</li>
<li>最后map函数将中间结果保存到本地。</li>
</ol>
<p>Reduce 任务的执行过程可概括为：</p>
<p>首先需要将已经完成的Map任务的中问结果复制到Reduce任务所在的节点，待数据复制完成后，再以key进行排序，通过排序，将所有key相同的数据交给reduce函数处理，处理完成后，结果直接输出到HDFS上。</p>
<hr>
<p>。。。这里更详细的有看到，但是没仔细看，又到了源码部分，暂时先了解这么多。</p>
<hr>
<h2 id="mapReduce的局限性"><a href="#mapReduce的局限性" class="headerlink" title="mapReduce的局限性"></a>mapReduce的局限性</h2><ol>
<li><p>从MapReduce 的特点可以看出MapReduce 的优点非常明显，但是MapReduce 也有其局限性，井不是处理海量数据的普适方法。它的局限性主要体现在以下几点：<br>MapReduce<br>的执行速度慢。一个普通的MapReduce作业一般在分钟级别完成，复杂的作业或者数据量更大的情况下，也可能花费一小时或者更多，好在离线计算对于时间远没有OLTP那么敏感。所以MapReduce<br>现在不是，以后也不会是关系型数据库的终结者。MapReduce的慢主要是由于磁盘I&#x2F;0 , MapReduce<br>作业通常都是数据密集型作业，大量的中间结果需要写到磁盘上并通过网络进行传输，这耗去了大量的时间。</p>
</li>
<li><p>MapReduce过于底层。与SQL相比，MapReduce显得过于底层。对于普通的查询，一般人是不会希望写一个map 函数和reduce函数的。对于习惯于关系型数据库的用户，或者数据分析师来说，编写map 函数和reduce 函数无疑是一件头疼的事情。好在Hive的出现，大大改善了这种状况。</p>
</li>
<li><p>不是所有算法都能用MapReduce 实现。这意味着，不是所有算法都能实现并行。例如机器学习的模型训练， 这些算法需要状态共享或者参数间有依赖，且需要集中维护和更新。</p>
</li>
</ol>
<h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><p>HDFS是Hadoop项目的核心子项目，是分布式计算中数据存储管理的基础，是基于流数据模式访问和处理超大文件的需求而开发的，可以运行于廉价的商用服务器上。它所具有的高容错、高可靠性、高可扩展性、高获得性、高吞吐率等特征为海量数据提供了不怕故障的存储，为超大数据集（Large<br>Data Set）的应用处理带来了很多便利。</p>
<p>这里重点介绍其中涉及到的几个概念：（1） <strong>超大文件</strong> 。目前的hadoop集群能够存储几百TB甚至PB级的数据。（2） <strong>流式数据访问</strong><br>。HDFS的访问模式是： <strong>一次写入，多次读取</strong> ，更加关注的是读取整个数据集的整体时间。（3） <strong>商用硬件。</strong><br>HDFS集群的设备不需要多么昂贵和特殊，只要是一些日常使用的普通硬件即可，正因为如此，hdfs节点故障的可能性还是很高的，所以<br><strong>必须要有机制来处理这种单点故障</strong> ，保证数据的可靠。（4） <strong>不支持低时间延迟的数据访问</strong><br>。hdfs关心的是高数据吞吐量，不适合那些要求低时间延迟数据访问的应用。（5） <strong>单用户写入，不支持任意修改。</strong><br>hdfs的数据以读为主，只支持单个写入者，并且写操作总是以添加的形式在文末追加，不支持在任意位置进行修改。</p>
<h2 id="HDFS数据块"><a href="#HDFS数据块" class="headerlink" title="HDFS数据块"></a>HDFS数据块</h2><p>每个磁盘都有默认的数据块大小，这是文件系统进行数据读写的最小单位。这涉及到磁盘的相应知识，这里我们不多讲，后面整理一篇博客来记录一下磁盘的相应知识。</p>
<p>HDFS同样也有数据块的概念，默认一个块（block）的大小为128MB（HDFS的块这么大主要是为了最小化寻址开销），要在HDFS中存储的文件可以划分为多个分块，每个分块可以成为一个独立的存储单元。与本地磁盘不同的是，HDFS中小于一个块大小的文件并不会占据整个HDFS数据块。</p>
<p>对HDFS存储进行分块有很多好处：</p>
<ul>
<li>一个文件的大小可以大于网络中任意一个磁盘的容量，文件的块可以利用集群中的任意一个磁盘进行存储。</li>
<li>使用抽象的块，而不是整个文件作为存储单元，可以简化存储管理，使得文件的元数据可以单独管理。</li>
<li>冗余备份。数据块非常适合用于数据备份，进而可以提供数据容错能力和提高可用性。每个块可以有多个备份（默认为三个），分别保存到相互独立的机器上去，这样就可以保证单点故障不会导致数据丢失。</li>
</ul>
<h2 id="namenode和datanode"><a href="#namenode和datanode" class="headerlink" title="namenode和datanode"></a>namenode和datanode</h2><p>HDFS集群的节点分为两类：namenode和datanode，以管理节点-<br>工作节点的模式运行，即一个namenode和多个datanode，理解这两类节点对理解HDFS工作机制非常重要。</p>
<p>namenode作为管理节点，它负责整个文件系统的命名空间，并且维护着文件系统树和整棵树内所有的文件和目录，这些信息以两个文件的形式（命名空间镜像文件和编辑日志文件）永久存储在namenode<br>的本地磁盘上。除此之外，同时，namenode也记录每个文件中各个块所在的数据节点信息，但是不永久存储块的位置信息，因为块的信息可以在系统启动时重新构建。</p>
<p>datanode作为文件系统的工作节点，根据需要存储并检索数据块，定期向namenode发送他们所存储的块的列表。</p>
<p><img src="/images/nameNode%E5%92%8CdateNode.png" alt="nameNode和dateNode"></p>
<p>由此可见，namenode作为管理节点，它的地位是非同寻常的，一旦namenode宕机，那么所有文件都会丢失，因为namenode是唯一存储了元数据、文件与数据块之间对应关系的节点，所有文件信息都保存在这里，namenode毁坏后无法重建文件。因此，必须高度重视namenode的容错性。</p>
<p>为了使得namenode更加可靠，hadoop提供了两种机制：</p>
<ul>
<li><p>第一种机制是备份那些组成文件系统元数据持久状态的文件，比如：将文件系统的信息写入本地磁盘的同时，也写入一个远程挂载的网络文件系统（NFS），这些写操作实时同步并且保证原子性。</p>
</li>
<li><p>第二种机制是运行一个辅助namenode，用以保存命名空间镜像的副本，在namenode发生故障时启用。（也可以使用热备份namenode代替辅助namenode）。</p>
</li>
</ul>
<p><img src="/images/nameNode%E5%92%8CdataNode.png" alt="nameNode和dataNode"></p>
<h2 id="块缓存"><a href="#块缓存" class="headerlink" title="块缓存"></a>块缓存</h2><p>数据通常情况下都保存在磁盘，但是对于访问频繁的文件，其对应的数据块可能被显式的缓存到datanode的内存中，以堆外缓存的方式存在，一些计算任务（比如mapreduce）可以在缓存了数据的datanode上运行，利用块的缓存优势提高读操作的性能。</p>
<h2 id="联邦HDFS"><a href="#联邦HDFS" class="headerlink" title="联邦HDFS"></a>联邦HDFS</h2><p>namenode在内存中保存了文件系统中每个文件和每个数据块的引用关系，这意味着，当文件足够多时，namenode的内存将成为限制系统横向扩展的瓶颈。hadoop2.0引入了联邦HDFS允许系统通过添加namenode的方式实现扩展，每个namenode管理文件系统命名空间中的一部分，比如：一个namenode管理&#x2F;usr下的文件，另外一个namenode管理&#x2F;share目录下的文件。</p>
<h2 id="HDFS的高可用性"><a href="#HDFS的高可用性" class="headerlink" title="HDFS的高可用性"></a>HDFS的高可用性</h2><p>通过备份namenode存储的文件信息或者运行辅助namenode可以防止数据丢失，但是依旧没有保证了系统的高可用性。一旦namenode发生了单点失效，那么必须能够快速的启动一个拥有文件系统信息副本的新namenode，而这个过程需要以下几步：（1）将命名空间的副本映像导入内存<br>（2）重新编辑日志 （3）接收足够多来自datanode的数据块报告，从而重建起数据块与位置的对应关系。</p>
<p>上述实际上就是一个namenode的冷启动过程，但是在数据量足够大的情况下，这个冷启动可能需要30分钟以上的时间，这是无法忍受的。</p>
<p>Hadoop2.0开始，增加了对高可用性的支持。采用了双机热备份的方式。同时使用一对活动-<br>备用namenode，当活动namenode失效后，备用namenode可以迅速接管它的任务，这中间不会有任何的中断，以至于使得用户根本无法察觉。</p>
<p>为了实现这种双机热备份，HDFS架构需要作出以下几个改变：</p>
<ul>
<li>两个namenode之间要通过高可用共享存储来实现编辑日志的共享</li>
<li>datanode要同时向两个namenode发送数据块的报告信息</li>
<li>客户端要使用特定机制来处理namenode的失效问题</li>
<li>备用namenode要为活动namenode设置周期性的检查点，从中判断活动namenode是否失效</li>
</ul>
<p>HDFS系统中运行着一个故障转移控制器，管理着将活动namenode转移为备用namenode的转换过程。同时，每一个namenode也运行着一个轻量级的故障转移控制器，主要目的就是监视宿主namenode是否失效，并在失效时实现迅速切换。</p>
<h1 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h1><p><strong>传统mysql无法处理大数据，而大数据文件系统HDFS不能使用SQL，Hive就是一种可以用类SQL语句对大数据文件系统中的结构化数据进行操作的工具</strong></p>
<h2 id="Hive的系统架构"><a href="#Hive的系统架构" class="headerlink" title="Hive的系统架构"></a>Hive的系统架构</h2><p><img src="/images/hive%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84.png" alt="hive的系统架构"></p>
<ul>
<li>用户接口，包括CLI，JDBC&#x2F;ODBC，WebUI</li>
<li>metastore，Hive将元数据存储在数据库中(metastore)，目前只支持 mysql、derby(Derby引擎的缺点：一次只能打开一个会话。使用Mysql作为外置存储引擎，多用户同时访问)。Hive 中的元数据包括表名、列、分区及其属性、表的属性（是否为外部表等）、表数据所在目录等</li>
<li>Driver 解释器、编译器、优化器完成 HQL 查询语句从词法分析、语法分析、编译、优化以及查询计划（plan）的生成。生成的查询计划存储在 <strong>HDFS</strong> 中，并在随后有 MapReduce 调用执行</li>
<li>Hive的数据存储在HDFS中，大部分的查询由MapReduce完成（包含 * 的查询，比如select * from tb不会生成MapReduce任务）</li>
</ul>
<h2 id="Hive和普通数据库的异同"><a href="#Hive和普通数据库的异同" class="headerlink" title="Hive和普通数据库的异同"></a>Hive和普通数据库的异同</h2><ol>
<li><strong>查询语言</strong> 。由于SQL被广泛的应用在数据仓库中，因此，专门针对Hive的特性设计了类SQL的查询语言HQL。熟悉SQL开发就很容易入手Hive开发。</li>
<li><strong>数据仓库位置</strong> 。Hive是建立在Hadoop之上的，所有Hive的数据都是存储在HDFS中的。而数据库则可以将数据保存在块设备或者本地文件系统中。</li>
<li><strong>数据格式</strong> 。 Hive中没有定义专门的数据格式，数据格式可以由用户指定，用户定义数据格式需要指定三个属性，列分隔符（通常为空格）、行分隔符（“\n”）以及读取文件数据的方法（Hive中默认有三个文件格式TextFile,SequenceFile以及RCFile）。由于在加载数据的过程中，不需要从用户数据格式到Hive定义的数据格式的转换，因此，Hive在加载的过程中不会对数据本身进行任何修改，而只是将数据内容复制或者移动到相应的HDFS目录中。</li>
<li><strong>数据更新</strong> 。由于Hive是针对数据仓库应用设计的，而数据仓库的内容是读多写少的。因此， <strong>Hive中不支持对数据的改写和添加</strong> ，所有的数据都是在加载的时候中确定好的。而数据库中的数据通常是需要经常进行修改的，因此可以使用 INSERT INTO … VALUES 添加数据，使用 UPDATE … SET修改数据。</li>
<li><strong>索引</strong> 。Hive在加载数据的过程中不会对数据进行任何处理，甚至不会对数据进行扫描，因此也没有对数据中的某些Key建立索引。Hive要访问数据中满足条件的特定值时，需要暴力扫描整个数据，因此访问延迟较高。由于 MapReduce 的引入， Hive 可以并行访问数据，因此即使没有索引，对于大数据量的访问，Hive 仍然可以体现出优势。数据库中，通常会针对一个或者几个列建立索引，因此对于少量的特定条件的数据的访问，数据库可以有很高的效率，较低的延迟。由于数据的访问延迟较高，决定了 Hive 不适合在线数据查询。</li>
<li><strong>执行</strong> 。Hive中大多数查询的执行是通过 Hadoop 提供的 MapReduce 来实现的（类似 select * from tbl的查询不需要MapReduce）。而数据库通常有自己的执行引擎。</li>
<li><strong>执行延迟</strong> 。Hive 在查询数据的时候，由于没有索引，需要扫描整个表，因此延迟较高。另外一个导致 Hive 执行延迟高的因素是 MapReduce框架。由于MapReduce 本身具有较高的延迟，因此在利用MapReduce 执行Hive查询时，也会有较高的延迟。相对的，数据库的执行延迟较低。当然，这个低是有条件的，即数据规模较小，当数据规模大到超过数据库的处理能力的时 候，Hive的并行计算显然能体现出优势。</li>
<li><strong>可扩展性</strong> 。由于Hive是建立在Hadoop之上的，因此Hive的可扩展性是和Hadoop的可扩展性是一致的。而数据库由于 ACID 语义的严格限制，扩展行非常有限。目前最先进的并行数据库 Oracle 在理论上的扩展能力也只有100台左右。</li>
<li><strong>规模</strong> 。由于Hive建立在集群上并可以利用MapReduce进行并行计算，因此可以支持很大规模的数据；对应的，数据库可以支持的数据规模较小。</li>
</ol>
<h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><p>在对Hive进行操作之前，首先要明白Hive数据类型有哪些。</p>
<ul>
<li>tinyint&#x2F;smallint&#x2F;int&#x2F;bigint</li>
<li>float&#x2F;double</li>
<li>boolean</li>
<li>DECIMAL －用户可以指定范围和小数点位数</li>
<li>STRING －在特定的字符集中的一个字符串序列</li>
<li>VARCHAR －在特定的字符集中的一个有最大长度限制的字符串序列</li>
<li>CHAR －在特定的字符集中的一个指定长度的字符串序列</li>
<li>BINARY －一个二进制位序列</li>
<li>结构体类型（Stuct): 使用点（.)来访问类型内部的元素。例如，有一列c，它是一个结构体类型{a INT; b INT}，字段a可以使用表达式c.a来访问。</li>
<li>Map(key-value键值对)：使用[‘元素名’]来访问元素。例如，有一个MapM，包含’group’-&gt;gid的映射，则gid的值可以使用M[‘group’]来访问。</li>
<li>数组：数组中的元素是相同的类型。可以使用[n]来访问数组元素，n是数组下标，以0开始。例如有一个数组A，有元素[‘a’,’b’,’c’]，则A[1]返回’b’。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/05/17/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/zk%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="merric">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Myoboku">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Myoboku">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/05/17/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/zk%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">zk学习笔记</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-05-17 22:30:00" itemprop="dateCreated datePublished" datetime="2023-05-17T22:30:00+00:00">2023-05-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">数据库与中间件</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>ZooKeeper之前也是Hadoop下的一个子项目，在读《Hadoop权威指南》时也有简单的介绍，感觉ZooKeeper还是在很多大公司属于经常用的基础，现在公司有用到但是自己接触的比较少，所以也正好网上查查相关资料做一个大概的总结。</p>
<h1 id="分布式协调技术"><a href="#分布式协调技术" class="headerlink" title="分布式协调技术"></a><strong>分布式协调技术</strong></h1><p>在介绍ZooKeeper之前先来给大家介绍一种技术——分布式协调技术。那么什么是分布式协调技术？其实分布式协调技术主要用来解决分布式环境当中多个进程之间的同步控制，让他们有序的去访问某种临界资源，防止造成”脏数据”的后果。这时，有人可能会说这个简单，写一个调度算法就轻松解决了。说这句话的人，可能对分布式系统不是很了解，所以才会出现这种误解。如果这些进程全部是跑在一台机上的话，相对来说确实就好办了，问题就在于他是在一个分布式的环境下，这时问题又来了，那什么是分布式呢？来咱们看一下这张图</p>
<p><img src="/images/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%9B%BE.png" alt="分布式系统图"></p>
<p>在这图中有三台机器，每台机器各跑一个应用程序。然后我们将这三台机器通过网络将其连接起来，构成一个系统来为用户提供服务，对用户来说这个系统的架构是透明的，他感觉不到我这个系统是一个什么样的架构。那么我们就可以把这种系统称作一个<br><strong>分布式系统</strong> 。</p>
<p>那我们接下来再分析一下，在这个分布式系统中如何对进程进行调度，我假设在第一台机器上挂载了一个资源，然后这三个物理分布的进程都要竞争这个资源，但我们又不希望他们同时进行访问，这时候我们就需要一个<br><strong>协调器</strong> ，来让他们有序的来访问这个资源。这个协调器就是我们经常提到的那个 <strong>锁</strong><br>，比如说”进程-1”在使用该资源的时候，会先去获得锁，”进程1”获得锁以后会对该资源保持 <strong>独占</strong><br>，这样其他进程就无法访问该资源，”进程1”用完该资源以后就将锁释放掉，让其他进程来获得锁，那么通过这个锁机制，我们就能保证了分布式系统中多个进程能够有序的访问该临界资源。那么我们把这个分布式环境下的这个锁叫作<br><strong>分布式锁</strong> 。这个分布式锁也就是我们 <strong>分布式协调技术</strong> 实现的核心内容，那么如何实现这个分布式呢，那就是我们后面要讲的内容。</p>
<p>好我们知道，为了防止分布式系统中的多个进程之间相互干扰，我们需要一种分布式协调技术来对这些进程进行调度。而这个分布式协调技术的核心就是来实现这个分<br><strong>布式锁</strong> 。那么这个锁怎么实现呢？这实现起来确实相对来说比较困难的。</p>
<p>有人可能会感觉这不是很难。无非是将原来在同一台机器上对进程调度的原语，通过网络实现在分布式环境中。是的，表面上是可以这么说。但是问题就在网络这，在分布式系统中，所有在同一台机器上的假设都不存在：因为网络是不可靠的。</p>
<p>比如，在同一台机器上，你对一个服务的调用如果成功，那就是成功，如果调用失败，比如抛出异常那就是调用失败。但是在分布式环境中，由于网络的不可靠，你对一个服务的调用失败了并不表示一定是失败的，可能是执行成功了，但是响应返回的时候失败了。还有，A和B都去调用C服务，在时间上<br>A还先调用一些，B后调用，那么最后的结果是不是一定A的请求就先于B到达呢？<br>这些在同一台机器上的种种假设，我们都要重新思考，我们还要思考这些问题给我们的设计和编码带来了哪些影响。还有，在分布式环境中为了提升可靠性，我们往往会部署多套服务，但是如何在多套服务中达到一致性，这在同一台机器上多个进程之间的同步相对来说比较容易办到，但在分布式环境中确实一个大难题。</p>
<p>所以分布式协调远比在同一台机器上对多个进程的调度要难得多，而且如果为每一个分布式应用都开发一个独立的协调程序。一方面，协调程序的反复编写浪费，且难以形成通用、伸缩性好的协调器。另一方面，协调程序开销比较大，会影响系统原有的性能。所以，急需一种高可靠、高可用的通用协调机制来用以协调分布式应用。</p>
<p>目前，在分布式协调技术方面做得比较好的就是Google的Chubby还有Apache的ZooKeeper他们都是分布式锁的实现者。有人会问既然有了Chubby为什么还要弄一个ZooKeeper，难道Chubby做得不够好吗？不是这样的，主要是Chbby是非开源的，Google自家用。后来雅虎模仿Chubby开发出了ZooKeeper，也实现了类似的分布式锁的功能，并且将ZooKeeper作为一种开源的程序捐献给了Apache，那么这样就可以使用ZooKeeper所提供锁服务。而且在分布式领域久经考验，它的可靠性，可用性都是经过理论和实践的验证的。所以我们在构建一些分布式系统的时候，就可以以这类系统为起点来构建我们的系统，这将节省不少成本，而且bug也<br>将更少。</p>
<h1 id="什么是ZooKeeper"><a href="#什么是ZooKeeper" class="headerlink" title="什么是ZooKeeper"></a>什么是ZooKeeper</h1><p>从本质上来说，Zookeeper就是一种分布式协调服务，在分布式环境中协调和管理服务是一个复杂的过程。ZooKeeper通过其简单的架构和API解决了这个问题。<br>ZooKeeper允许开发人员专注于核心应用程序逻辑，而不必担心应用程序的分布式特性。Zookeeper最早的应用是在Hadoop生态中，Apache<br>HBase使用ZooKeeper跟踪分布式数据的状态。</p>
<p>实际上从它的名字上就很好理解，Zoo - 动物园，Keeper -<br>管理员，动物园中有很多种动物，这里的动物就可以比作分布式环境下多种多样的服务，而Zookeeper做的就是管理这些服务。</p>
<p><strong>ZooKeeper 的设计目标是将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用。</strong></p>
<blockquote>
<p>原语：<br>操作系统或计算机网络用语范畴。是由若干条指令组成的，用于完成一定功能的一个过程。具有不可分割性·即原语的执行必须是连续的，在执行过程中不允许被中断。</p>
</blockquote>
<p><strong>Zookeeper提供服务主要就是通过：数据结构 + 原语集 + watcher机制达到的。</strong></p>
<p>分布式应用程序结合Zookeeper可以实现诸如<br><strong>数据发布&#x2F;订阅、负载均衡、命名服务、分布式协调&#x2F;通知、集群管理、Master选举、分布式锁和分布式队列</strong> 等功能。</p>
<h1 id="ZooKeeper的数据模型"><a href="#ZooKeeper的数据模型" class="headerlink" title="ZooKeeper的数据模型"></a>ZooKeeper的数据模型</h1><p><img src="/images/ZooKeeper%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B.png" alt="ZooKeeper数据模型"></p>
<p>从上图可以看到，Zookeeper的数据模型和Unix的文件系统目录树很类似，拥有一个层次的命名空间。这里面的每一个节点都被称为 - ZNode，<br>节点可以拥有子节点，同时也允许少量数据节点存储在该节点之下。（可以理解成一个允许一个文件也可以是一个目录的文件系统）</p>
<h2 id="节点引用方式"><a href="#节点引用方式" class="headerlink" title="节点引用方式"></a>节点引用方式</h2><p>ZNode通过路径引用，如同Unix中的文件路径。路径必须是绝对的，因此他们必须有斜杠字符<code>/</code>来开头,除此之外，路径名必须是唯一的，且不能更改。</p>
<h2 id="ZNode结构"><a href="#ZNode结构" class="headerlink" title="ZNode结构"></a>ZNode结构</h2><p>Node兼具文件和目录两种特点，既像文件一样维护着数据、元信息、ACL、时间戳等数据结构，又像目录一样可以作为路径标识的一部分。</p>
<p>ZNode由以下几部分组成：</p>
<ol>
<li>Stat数据结构</li>
</ol>
<pre><code>* 操作控制列表（ACL） - 每个节点都有一个ACL来做节点的操作控制，这个列表规定了用户的权限，限定了特定用户对目标节点的操作

  * CREATE - 创建子节点的权限
  * READ - 获取节点数据和子节点列表的权限
  * WRITE - 更新节点数据的权限
  * DELETE - 删除子节点的权限
  * ADMIN - 设置节点ACL的权限
* 版本 - ZNode有三个数据版本

  * **version** \- 当前ZNode的版本
  * **cversion** \- 当前ZNode子节点的版本
  * **aversion** \- 当前ACL列表的版本
* Zxid

  * 可以理解成Zookeeper中 **时间戳的一种表现形式** ，也可以理解成 **事务ID** 的概念

  * 如果Zxid1的值小于Zxid2的值，那么Zxid1所对应的事件发生在Zxid2所对应的事件之前。

  * ZooKeeper的每个节点维护着三个Zxid值，分别为：cZxid、mZxid、pZxid。

    * **cZxid** ：节点创建时间 create
    * **mZxid** ：节点最近一次修改时间 modify
    * **pZxid** ：该节点的子节点列表最后一次被修改时的时间，子节点内容变更不会变更pZxid
</code></pre>
<ol start="2">
<li><p>data域</p>
</li>
<li><p>children节点</p>
</li>
</ol>
<p>其中，</p>
<p>Stat。是状态信息&#x2F;节点属性；</p>
<p>Data域，Zookeeper中每个节点存储的数据要被 <strong>原子性的操作</strong><br>，也就是说读操作将获取与节点相关的所有数据，写操作也将替换掉节点的所有数据。值得注意的是，Zookeeper虽然可以存储数据，但是<br><strong>从设计目的上，并不是为了做数据库或者大数据存储，相反，它是用来管理调度数据，比如分布式应用中的配置文件信息、状态信息、汇集位置等</strong><br>，这些数据通常是很小的数据，KB为大小单位。ZNode对数据大小也有限制，至多1M。实际上从这里，就可以推导出Zookeeper用于分布式配置中心的可行性。</p>
<p>Zxid，在ZooKeeper中，<br><strong>能改变ZooKeeper服务器状态的操作称为事务操作。一般包括数据节点创建与删除、数据内容更新和客户端会话创建与失效等操作</strong><br>。对应每一个事务请求，ZooKeeper都会为其分配一个全局唯一的 <strong>事务ID</strong> ，用Zxid表示。Zxid是一个64位的数字。 <strong>前32位</strong><br>叫做epoch，用来 <strong>标识Zookeeper 集群中的<code>Leader</code>节点，当<code>Leader</code>节点更换时，就会有一个新的epoch</strong>。<br><strong>后32位</strong> 则为递增序列。从这些Zxid中可以间接地识别出ZooKeeper处理这些事务操作请求的全局顺序。</p>
<h2 id="节点类型"><a href="#节点类型" class="headerlink" title="节点类型"></a>节点类型</h2><p>ZNode节点类型严格来说有四种： <strong>持久节点、临时节点、持久顺序节点、临时顺序节点</strong></p>
<ul>
<li><strong>PERSISTENT 持久节点</strong> - 该节点的生命周期不依赖于session，创建之后客户端断开连接，节点依旧存在，只有客户端执行删除操作，节点才能被删除；</li>
<li><strong>EPHEMERAL 临时节点</strong> - 该节点的声明周期依赖于session，客户端断开连接，临时节点就会自动删除。另外， <strong>临时节点不允许有子节点。</strong></li>
<li><strong>SEQUENTIAL 顺序节点</strong> - 当选择创建顺序节点时，ZooKeeper通过将10位的序列号附加到原始名称来设置znode的路径。例如，如果将具有路径 <code>/myapp</code> 的znode创建为顺序节点，则ZooKeeper会将路径更改为 <code>/myapp0000000001</code> ，并将下一个序列号设置为<code>0000000002</code>。如果两个顺序节点是同时创建的，那么ZooKeeper不会对每个znode使用相同的数字。 <strong>顺序节点在锁定和同步中起重要作用。</strong> 这个计数 <strong>对于此节点的父节点来说</strong> 是唯一的，它的格式为”%10d”(10位数字，没有数值的数位用0补充，例如”0000000001”)。当计数值大于2^32-1时，计数器将溢出。</li>
</ul>
<h2 id="节点属性"><a href="#节点属性" class="headerlink" title="节点属性"></a>节点属性</h2><p><img src="/images/znode%E8%8A%82%E7%82%B9%E5%B1%9E%E6%80%A7.png" alt="znode节点属性"></p>
<h2 id="观察"><a href="#观察" class="headerlink" title="观察"></a>观察</h2><p>客户端可以在节点上设置watch，我们称之为 <strong>监视器</strong><br>。当节点状态发生改变时(Znode的增、删、改)将会触发watch所对应的操作。当watch被触发时，ZooKeeper将会向客户端发送且仅发送一条通知，因为watch只能被触发一次，这样可以减少网络流量。</p>
<h1 id="Zookeeper服务基本操作"><a href="#Zookeeper服务基本操作" class="headerlink" title="Zookeeper服务基本操作"></a>Zookeeper服务基本操作</h1><p><img src="/images/ZooKeeper%E6%9C%8D%E5%8A%A1%E4%B8%AD%E6%93%8D%E4%BD%9C.png" alt="ZooKeeper服务中操作"></p>
<p>更新ZooKeeper操作是有限制的。delete或setData必须明确要更新的Znode的版本号，我们可以调用exists找到。如果版本号不匹配，更新将会失败。</p>
<p>更新ZooKeeper操作是非阻塞式的。因此客户端如果失去了一个更新(由于另一个进程在同时更新这个Znode)，他可以在不阻塞其他进程执行的情况下，选择重新尝试或进行其他操作。</p>
<p>尽管ZooKeeper可以被看做是一个文件系统，但是处于便利，摒弃了一些文件系统地操作原语。因为文件非常的小并且使整体读写的，所以不需要打开、关闭或是寻地的操作。</p>
<h1 id="Sessions"><a href="#Sessions" class="headerlink" title="Sessions"></a>Sessions</h1><p>在 ZooKeeper 中，一个客户端连接是指客户端和服务器之间的一个 <strong>TCP 长连接</strong> 。客户端启动的时候，首先会与服务器建立一个 TCP<br>连接，从第一次连接建立开始，客户端会话的生命周期也开始了。<br><strong>通过这个连接，客户端能够通过心跳检测与服务器保持有效的会话，也能够向Zookeeper服务器发送请求并接受响应，同时还能够通过该连接接收来自服务器的Watch事件通知。</strong></p>
<p>客户端以特定的时间间隔发送心跳以保持会话有效。如果ZooKeeper Server<br>Ensembles在超过服务器开启时指定的期间（会话超时）都没有从客户端接收到心跳，则它会判定客户端死机。</p>
<p>会话超时通常以毫秒为单位。当会话由于任何原因结束时，在该会话期间创建的临时节点也会被删除。</p>
<h1 id="Watches"><a href="#Watches" class="headerlink" title="Watches"></a>Watches</h1><p> <strong>Watches - 监听事件</strong> ，是Zookeeper中一个很重要的特性，也是实现Zookeeper大多数功能的核心特性之一。简单来说，<br><strong>Zookeeper允许Client端在指定节点上注册Watches，在某些特定事件触发的时候，Zookeeper服务端会将事件异步通知到感兴趣（即注册了Watches）的客户端上去</strong><br>。可以理解成一个订阅&#x2F;发布系统，是不是。</p>
<p>Znode更改是与znode相关的数据的修改或znode的子项中的更改。只触发一次watches。如果客户端想要再次通知，则必须通过另一个读取操作来完成。当连接会话过期时，客户端将与服务器断开连接，相关的watches也将被删除。</p>
<p>下面说完简单的，来说点复杂的部分。</p>
<p>几个特性先了解下：</p>
<ul>
<li><strong>One-time trigger</strong> 一次watch时间只会被触发一遍，如果节点再次发生变化，除非之前有重新设置过watches，不然会收到通知；</li>
<li><strong>Sent to Client</strong> 当watch的对象状态发生改变时，将会触发此对象上watch所对应的事件。watch事件将被异步地发送给客户端，并且ZooKeeper为watch机制提供了**有序的一致性保证(Ordering guarantee)**。</li>
<li><strong>The data for which the watch was set</strong> 发送给客户端的数据信息，实际上就是你这个watch监视的类型，见下文介绍</li>
</ul>
<p>Zookeeper的Watches 分为两种， <strong>数据监听器（Data Watches）和子节点监听器（Children Watches）</strong><br>。即你可以对某个节点的Data设置watches，也可以对某个子节点设置watches。</p>
<p>可以看下Zookeeper Java 客户端 <code>Zkclient</code> 中的设置watches的代码:</p>
<pre><code>// listener 监听器  
// path 节点路径  
  
// 子节点监听器  
private List&lt;String&gt; addTargetChildListener(String path, IZkChildListener listener) &#123;  
    return client.subscribeChildChanges(path, listener);  
&#125;  
  
// 节点数据的监听器  
public void addChildDataListener(String path, IZkDataListener listener) &#123;  
    try &#123;  
        // 递归创建节点  
        client.subscribeDataChanges(path, listener);  
    &#125; catch (ZkNodeExistsException e) &#123;  
    &#125;  
&#125;  
  
</code></pre>
<p>作为开发者，需要知道监控节点的什么操作会触发你设置的watches。</p>
<ol>
<li>一个成功的setData操作将触发Znode的数据watches</li>
<li>一个成功的create操作将触发Znode的数据watches以及子节点watches</li>
<li>一个成功的delete操作将触发Znode的数据watches和子节点watches</li>
</ol>
<p>再看下ZkClient中的数据监听器接口<code>IZkDataListener</code></p>
<pre><code>public interface IZkDataListener &#123;  
    // 监控节点数据更新的时候会触发 这段逻辑  
    public void handleDataChange(String dataPath, Object data) throws Exception;  
    // 监控节点被删除的时候会触发 这段逻辑  
    public void handleDataDeleted(String dataPath) throws Exception;  
&#125;  
  
</code></pre>
<p>再看下ZkClient中的子节点监听器接口<code>IZkChildListener</code></p>
<pre><code>public interface IZkChildListener &#123;  
  
    /**  
     * Called when the children of the given path changed.  
     * 监控节点的子节点列表改变时会触发这段逻辑  
     *   
     * @param parentPath  
     *            The parent path  
     * @param currentChilds  
     *            The children or null if the root node (parent path) was deleted.  
     * @throws Exception  
     */  
    public void handleChildChange(String parentPath, List&lt;String&gt; currentChilds) throws Exception;  
&#125;  
</code></pre>
<p>实际上看到这就能联想到，Zookeeper是可以当做分布式配置中心来使用的，只不过你需要自己扩展他异步通知节点数据变化之后的逻辑，更新你的配置。</p>
<p><strong>(1) watch概述</strong></p>
<p>ZooKeeper可以为所有的 <strong>读操作</strong><br>设置watch，这些读操作包括：exists()、getChildren()及getData()。watch事件是 <strong>一次性的触发器</strong><br>，当watch的对象状态发生改变时，将会触发此对象上watch所对应的事件。watch事件将被 <strong>异步</strong><br>地发送给客户端，并且ZooKeeper为watch机制提供了有序的 <strong>一致性保证</strong><br>。理论上，客户端接收watch事件的时间要快于其看到watch对象状态变化的时间。</p>
<p><strong>(2) watch类型</strong></p>
<p>ZooKeeper所管理的watch可以分为两类：</p>
<p><strong>①</strong> 数据watch(data watches)： <strong>getData</strong> 和 <strong>exists</strong> 负责设置数据watch<br> <strong>②</strong> 孩子watch(child watches)： <strong>getChildren</strong> 负责设置孩子watch</p>
<p>我们可以通过操作 <strong>返回的数据</strong> 来设置不同的watch：</p>
<p><strong>① getData和exists：</strong> 返回关于节点的数据信息<br> <strong>② getChildren：</strong> 返回孩子列表</p>
<p>因此</p>
<p><strong>①</strong> 一个成功的 <strong>setData操作</strong> 将触发Znode的数据watch</p>
<p><strong>②</strong> 一个成功的 <strong>create操作</strong> 将触发Znode的数据watch以及孩子watch</p>
<p><strong>③</strong> 一个成功的 <strong>delete操作</strong> 将触发Znode的数据watch以及孩子watch</p>
<p><strong>(3) watch注册与处触发</strong></p>
<p><img src="/images/watch%E8%AE%BE%E7%BD%AE%E6%93%8D%E4%BD%9C%E5%8F%8A%E7%9B%B8%E5%BA%94%E7%9A%84%E8%A7%A6%E5%8F%91%E5%99%A8.png" alt="watch设置操作及相应的触发器"></p>
<p><strong>①</strong> exists操作上的watch，在被监视的Znode <strong>创建</strong> 、 <strong>删除</strong> 或 <strong>数据更新</strong> 时被触发。<br> <strong>②</strong> getData操作上的watch，在被监视的Znode <strong>删除</strong> 或 <strong>数据更新</strong><br>时被触发。在被创建时不能被触发，因为只有Znode一定存在，getData操作才会成功。<br> <strong>③</strong> getChildren操作上的watch，在被监视的Znode的子节点 <strong>创建</strong> 或 <strong>删除</strong> ，或是这个Znode自身被<br><strong>删除</strong><br>时被触发。可以通过查看watch事件类型来区分是Znode，还是他的子节点被删除：NodeDelete表示Znode被删除，NodeDeletedChanged表示子节点被删除。</p>
<p>Watch由客户端所连接的ZooKeeper服务器在本地维护，因此watch可以非常容易地设置、管理和分派。当客户端连接到一个新的服务器时，任何的会话事件都将可能触发watch。另外，当从服务器断开连接的时候，watch将不会被接收。但是，当一个客户端重新建立连接的时候，任何先前注册过的watch都会被重新注册。</p>
<p><strong>(4) 需要注意的几点</strong></p>
<p><strong>Zookeeper的watch实际上要处理两类事件：</strong></p>
<p><strong>① 连接状态事件</strong> (type&#x3D;None, path&#x3D;null)</p>
<p>这类事件不需要注册，也不需要我们连续触发，我们只要处理就行了。</p>
<p><strong>② 节点事件</strong></p>
<p>节点的建立，删除，数据的修改。它是one time trigger，我们需要不停的注册触发，还可能发生事件丢失的情况。</p>
<p>上面2类事件都在Watch中处理，也就是重载的 <strong>process(Event event)</strong></p>
<p><strong>节点事件的触发，通过函数exists，getData或getChildren来处理这类函数，有双重作用：</strong></p>
<p><strong>① 注册触发事件</strong></p>
<p><strong>② 函数本身的功能</strong></p>
<p>函数的本身的功能又可以用异步的回调函数来实现,重载processResult()过程中处理函数本身的的功能。</p>
<h1 id="Zookeeper特性总结"><a href="#Zookeeper特性总结" class="headerlink" title="Zookeeper特性总结"></a>Zookeeper特性总结</h1><p>现在我们再回过头来看看Zookeeper的特性：</p>
<blockquote>
<p>① 顺序一致性 从同一个客户端发起的事务请求，最终将会严格按照其发起顺序被应用到ZooKeeper中。</p>
</blockquote>
<blockquote>
<p>② 原子性<br>所有事务请求的结果在集群中所有机器上的应用情况是一致的，也就是说要么整个集群所有集群都成功应用了某一个事务，要么都没有应用，一定不会出现集群中部分机器应用了该事务，而另外一部分没有应用的情况。</p>
</blockquote>
<blockquote>
<p>③ 单一视图 无论客户端连接的是哪个ZooKeeper服务器，其看到的服务端数据模型都是一致的。</p>
</blockquote>
<blockquote>
<p>④ 可靠性 一旦服务端成功地应用了一个事务，并完成对客户端的响应，那么该事务所引起的服务端状态变更将会被一直保留下来，除非有另一个事务又对其进行了变更。</p>
</blockquote>
<blockquote>
<p>⑤ 实时性<br>通常人们看到实时性的第一反应是，一旦一个事务被成功应用，那么客户端能够立即从服务端上读取到这个事务变更后的最新数据状态。这里需要注意的是，ZooKeeper仅仅保证在一定的时间段内，客户端最终一定能够从服务端上读取到最新的数据状态。</p>
</blockquote>
<p><strong>顺序一致性</strong> 是通过ZXid来实现的，全局唯一，顺序递增，同一个session中请求是FIFO的； <strong>可靠性</strong><br>的描述也可以通过今天的知识进行理解，一次事务的应用，服务端状态的变更会以Zxid、Znode数据版本、数据、节点路径的形式保存下来。剩下的几种特性是怎么实现的，后面会进行介绍</p>
<h1 id="Zookeeper运行模式"><a href="#Zookeeper运行模式" class="headerlink" title="Zookeeper运行模式"></a>Zookeeper运行模式</h1><p>Zookeeper 有两种运行模式， <strong>单点模式</strong> 和 <strong>集群模式</strong> 。</p>
<ul>
<li><p>单点模式（standalone mode）- Zookeeper 只运行在单个服务器上，常用于开发测试阶段，这种模式比较简单，但是不能保证Zookeeper服务的高可用性和恢复性。</p>
</li>
<li><p>集群模式（replicated mode）- 英文原文这种模式叫做“复制模式”；这个模式下，Zookeeper运行于一个集群上，适合生产环境。</p>
</li>
</ul>
<p>同一个集群下的server节点被称为 <em>quorum</em> ，翻译过来就是“一个正式会议的法定人数”，如果你看完下一章介绍的 <strong>ZAB协议的两种模式</strong><br>之后，应该会觉得这个比喻实际上很形象。</p>
<blockquote>
<p>NOTE:<br>在集群模式下，最少需要三个server节点。并且官方推荐你使用奇数数量的server节点来组成集群。至于为什么，和Zookeeper的读写策略和一致性协议有关，在后面的章节会介绍。</p>
</blockquote>
<h1 id="Zookeeper的集群架构"><a href="#Zookeeper的集群架构" class="headerlink" title="Zookeeper的集群架构"></a>Zookeeper的集群架构</h1><p><img src="/images/Zookeeper%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84.png" alt="Zookeeper集群架构"></p>
<h2 id="Zookeeper集群中的角色"><a href="#Zookeeper集群中的角色" class="headerlink" title="Zookeeper集群中的角色"></a>Zookeeper集群中的角色</h2><blockquote>
<p>Zookeeper中，<br><strong>能改变ZooKeeper服务器状态的操作称为事务操作。一般包括数据节点创建与删除、数据内容更新和客户端会话创建与失效等操作</strong> 。</p>
</blockquote>
<ul>
<li><strong>Leader 领导者</strong> ：Leader 节点负责Zookeeper集群内部投票的发起和决议（一次事务操作），更新系统的状态；同时它也能接收并且响应Client端发送的请求。</li>
<li>Learner 学习者<ul>
<li><strong>Follower 跟随者</strong> ： Follower 节点用于接收并且响应Client端的请求，如果是事务操作，会将请求转发给Leader节点，发起投票，参与集群的内部投票，</li>
<li><strong>Observer 观察者</strong> ：Observer 节点功能和Follower相同，只是Observer 节点不参与投票过程，只会同步Leader节点的状态。</li>
</ul>
</li>
<li><strong>Client 客户端</strong></li>
</ul>
<p>Zookeeper 通过 <strong>复制</strong> 来实现 <strong>高可用</strong> 。在上面提到的集群模式（replicated<br>mode）下，以<code>Leader</code>节点为准，Zookeeper的<code>ZNode</code>树上面的每一个修改都会被同步（复制）到其他的Server 节点上面。</p>
<blockquote>
<p>上面实际上只是一个概念性的简单叙述，在看完下文的 <strong>读写机制</strong> 和 <strong>ZAB协议的两种模式</strong> 之后，你就会对这几种角色有一个更加深刻的认识。</p>
</blockquote>
<h2 id="Zookeeper-读写机制"><a href="#Zookeeper-读写机制" class="headerlink" title="Zookeeper 读写机制"></a>Zookeeper 读写机制</h2><p>下图就是集群模式下一个Zookeeper Server节点提供读写服务的一个流程。</p>
<p><img src="/images/%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B.png" alt="读写流程"></p>
<p>如上图所示，每个Zookeeper<br>Server节点除了包含一个请求处理器来处理请求以外，都会有一个**内存数据库(ReplicatedDatabase)**用于持久化数据。ReplicatedDatabase<br>包含了整个Data Tree。</p>
<p>来自于Client的读服务（Read Requst），是直接由对应Server的本地副本来进行服务的。</p>
<p>至于来自于Client的写服务（Write<br>Requst），因为Zookeeper要保证每台Server的本地副本是一致的（单一系统映像），需要通过一致性协议（后文提到的ZAB协议）来处理，成功处理的写请求（数据更新）会先序列化到每个Server节点的本地磁盘（为了再次启动的数据恢复）再保存到内存数据库中。</p>
<p>集群模式下，Zookeeper使用简单的同步策略，通过以下三条基本保证来实现 <strong>数据的一致性</strong> ：</p>
<ul>
<li>全局 <strong>串行化</strong> 所有的 <strong>写操作</strong></li>
</ul>
<blockquote>
<p>串行化可以把变量包括对象,转化成连续bytes数据. 你可以将串行化后的变量存在一个文件里或在网络上传输. 然后再反串行化还原为原来的数据。</p>
</blockquote>
<ul>
<li>保证 <strong>同一客户</strong> 端的指令被FIFO执行（以及消息通知的FIFO）</li>
</ul>
<blockquote>
<p>FIFO -先入先出</p>
</blockquote>
<ul>
<li>自定义的原子性消息协议</li>
</ul>
<p>简单来说，对数据的写请求，都会被转发到Leader节点来处理，Leader节点会对这次的更新发起投票，并且发送提议消息给集群中的其他节点，当半数以上的Follower节点将本次修改持久化之后，Leader<br>节点会认为这次写请求处理成功了，提交本次的事务。</p>
<h3 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a>乐观锁</h3><p>Zookeeper 的核心思想就是，提供一个 <strong>非锁机制的Wait Free 的用于分布式系统同步的核心服务</strong> 。其核心对于文件、数据的读写服务，并<br><strong>不提供加锁互斥的服务</strong> 。</p>
<p>但是由于Zookeeper的每次更新操作都会更新ZNode的版本，也就是客户端可以自己基于版本的对比，来实现更新数据时的加锁逻辑。例如下图。</p>
<p><img src="/images/zookeeper%E6%B5%81%E7%A8%8B.png" alt="zookeeper流程"></p>
<p>就像我们更新数据库时，会新增一个version字段，通过更新前后的版本对比来实现乐观锁。</p>
<h1 id="ZAB协议"><a href="#ZAB协议" class="headerlink" title="ZAB协议"></a>ZAB协议</h1><p>ZAB 协议是为分布式协调服务ZooKeeper专门设计的一种 <strong>支持崩溃恢复</strong> 的 <strong>一致性协议</strong><br>，这个机制保证了各个server之间的同步。全称 Zookeeper Atomic Broadcast Protocol - Zookeeper<br>原子广播协议。</p>
<h2 id="两种模式"><a href="#两种模式" class="headerlink" title="两种模式"></a>两种模式</h2><p>Zab协议有两种模式，它们分别是 <strong>恢复模式</strong> 和 <strong>广播模式</strong> 。</p>
<h3 id="广播模式"><a href="#广播模式" class="headerlink" title="广播模式"></a>广播模式</h3><p>广播模式类似于分布式事务中的 Two-phase commit<br>（两阶段式提交），因为Zookeeper中一次写操作就是被当做一个事务，所以这实际上本质是相同的。</p>
<p>在 <strong>广播模式</strong> ，一次写请求要经历以下的步骤</p>
<ol>
<li>ZooKeeper Server接受到Client的写请求</li>
<li>写请求都被转发给<code>Leader</code>节点</li>
<li><code>Leader</code>节点先将更新持久化到本地</li>
<li><code>Leader</code>节点将此次更新提议(propose)给<code>Followers</code>，进入收集选票的流程</li>
<li><code>Follower</code>节点接收请求，成功将修改持久化到本地，发送一个ACK给<code>Leader</code></li>
<li><code>Leader</code>接收到半数以上的ACK时，<code>Leader</code>将广播commit消息并在本地deliver该消息。</li>
<li>当收到<code>Leader</code>发来的commit消息时，<code>Follower</code>也会deliver该消息。</li>
</ol>
<p>广播协议在所有的通讯过程中使用TCP的FIFO信道，通过使用该信道，使保持有序性变得非常的容易。通过FIFO信道，消息被有序的deliver。只要收到的消息一被处理，其顺序就会被保存下来。</p>
<p>但是这种模式下，如果<code>Leader</code>自身发生了故障，Zookeeper的集群不就提供不了写服务了吗？这就引入了下面的恢复模式。</p>
<h3 id="恢复模式"><a href="#恢复模式" class="headerlink" title="恢复模式"></a>恢复模式</h3><p>简单点来说，当集群中的<code>Leader</code> <strong>故障</strong> 或者 <strong>服务启动</strong><br>的时候，ZAB就会进入恢复模式，其中包括<code>Leader</code>选举和完成其他Server和<code>Leader</code>之间的 <strong>状态同步</strong> 。</p>
<h4 id="单点故障"><a href="#单点故障" class="headerlink" title="单点故障"></a>单点故障</h4><p>在分布式锁服务中，有一种最典型应用场景，就是通过对集群进行 <strong>Master选举</strong> ，来解决分布式系统中的 <strong>单点故障</strong><br>。什么是分布式系统中的单点故障：通常分布式系统采用主从模式，就是一个主控机连接多个处理节点。主节点负责分发任务，从节点负责处理任务，当我们的主节点发生故障时，那么整个系统就都瘫痪了，那么我们把这种故障叫作单点故障。</p>
<p><img src="/images/%E4%B8%BB%E4%BB%8E%E6%A8%A1%E5%BC%8F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F.png" alt="主从模式分布式系统"><img src="/images/%E5%8D%95%E7%82%B9%E6%95%85%E9%9A%9C1.png" alt="单点故障1"></p>
<h4 id="传统解决方案"><a href="#传统解决方案" class="headerlink" title="传统解决方案"></a>传统解决方案</h4><p>传统方式是采用一个备用节点，这个备用节点定期给当前主节点发送ping包，主节点收到ping包以后向备用节点发送回复Ack，当备用节点收到回复的时候就会认为当前主节点还活着，让他继续提供服务。</p>
<p><img src="/images/%E4%BC%A0%E7%BB%9F%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.png" alt="传统解决方案"></p>
<p>当主节点挂了，这时候备用节点收不到回复了，然后他就认为主节点挂了接替他成为主节点</p>
<p><img src="/images/%E4%BC%A0%E7%BB%9F%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%881.png" alt="传统解决方案1"></p>
<p>但是这种方式就是有一个隐患，就是网络问题，来看一看网络问题会造成什么后果</p>
<p><img src="/images/%E7%BD%91%E7%BB%9C%E6%95%85%E9%9A%9C.png" alt="网络故障"></p>
<p>也就是说我们的主节点的并没有挂，只是在回复的时候网络发生故障，这样我们的备用节点同样收不到回复，就会认为主节点挂了，然后备用节点将他的Master实例启动起来，这样我们的分布式系统当中就有了两个主节点也就是—<br><strong>双Master</strong><br>，出现Master以后我们的从节点就会将它所做的事一部分汇报给了主节点，一部分汇报给了从节点，这样服务就全乱了。为了防止出现这种情况，我们引入了ZooKeeper，它虽然不能避免网络故障，但它能够保证每时每刻只有一个Master。我么来看一下ZooKeeper是如何实现的。</p>
<h4 id="zookeeper解决方案"><a href="#zookeeper解决方案" class="headerlink" title="zookeeper解决方案"></a>zookeeper解决方案</h4><p>首先每个Server在工作过程中有四种状态：<br>LOOKING：竞选状态，当前Server不知道leader是谁，正在搜寻。<br>LEADING：领导者状态，表明当前服务器角色是leader。<br>FOLLOWING：随从状态，表明当前服务器角色是follower，同步leader状态，参与投票。<br>OBSERVING，观察状态，表明当前服务器角色是observer，同步leader状态，不参与投票。</p>
<p><img src="/images/%E9%80%89%E4%B8%BE%E6%B5%81%E7%A8%8B.png" alt="选举流程"></p>
<p>假设我们目前有一个3个节点构成的ZooKeeper集群，myid的编号分别是0,1,2，又因为集群当前是一个空的集群，所以<br><strong>每个节点的ZXID初始都为0</strong> ，该集群启动的时候Leader的选举流程如下：</p>
<ol>
<li><p>我们首先启动myid为0的服务，但是目前只有一台ZooKeeper服务，所以是无法完成Leader选举的，ZooKeeper集群要求Leader进行投票选举条件是至少有2台服务才行，不然都没法进行通信投票。</p>
</li>
<li><p>启动myid为1的服务，第二台启动了以后，这两台ZooKeeper就可以相互通信了，接下来就可以进行投票选举了。</p>
</li>
<li><p>2台ZooKeeper进行投票选举的时候，第一次都是推荐自己为Leader，投票包含的信息是：服务器本身的myid和ZXID。比如第一台投自己的话，它会发送给第二台机器的投票是(0,0)，第一个0代表的是机器的myid，第二个0代表是的ZXID。故两台机器收到的投票情况如下：</p>
</li>
</ol>
<p>第一台：(1,0)</p>
<p>第二台：(0,0)</p>
<ol start="4">
<li>两台服务器在接收到投票后，将别人的票和自己的投票进行PK。PK的是规则是：</li>
</ol>
<p>（a）优先对比ZXID，ZXID大的优先作为Leader（ZXID大的表示数据多）</p>
<p>（b）如果ZXID一样的话，那么就比较myid，让myid大的作为Leader服务器。</p>
<p>那根据这个规则的话，第一台服务器，接受到的投票是(1,0)，跟自己的投票（0,0）比，ZXID是一样的，但是myid比接收到的投票的小，所以第一台原先是推荐自己投票为(0,0),现在进行了PK以后，投票修改为(1,0)。第二台服务器，接受到的投票是(0,0),跟自己的投票(1,0)比，ZXID是一样的，但是myid是比接受到的投票的大，所以坚持自己的投票(1,0)。两台服务器再次进行投票。</p>
<ol start="5">
<li>每次投票以后，服务器都会统计所有的投票，只要过半的机器投了相同的机器，那么Leader就选举成功了，上面的两台服务器进行第二次投票之后，两台服务器都会收到相同的投票(1,0)。那么此时myid为1的服务器就是Leader了。</li>
</ol>
<p>如上的Leader选举其实在集群启动的过程中只需要几毫秒就完成了，所以如果有搭建ZooKeeper集群经验的同学会发现，我们如果按顺序启动服务的话，启动到第二台机器的时候，Leader就已经选出来了，所以大家会看到一般第二台就是Leader。第三台启动的时候就作为Follower。</p>
<p>上面我们描述的是集群在初始化过程中Leader的选举流程，如果集群在运行的过程中Follower节点宕机了，对Leader节点是不影响的，如果集群在运行的过程中Leader节点宕机了，就会进行重新选举，重新选举的流程跟上述一致。</p>
<p><img src="/images/leader%E9%80%89%E4%B8%BE%E6%B5%81%E7%A8%8B.jpeg" alt="leader选举流程"></p>
<h1 id="关于Zookeeper-集群的一些其他讨论"><a href="#关于Zookeeper-集群的一些其他讨论" class="headerlink" title="关于Zookeeper 集群的一些其他讨论"></a>关于Zookeeper 集群的一些其他讨论</h1><h2 id="Zookeeper（读性能）可伸缩性-和-Observer节点"><a href="#Zookeeper（读性能）可伸缩性-和-Observer节点" class="headerlink" title="Zookeeper（读性能）可伸缩性 和 Observer节点"></a>Zookeeper（读性能）可伸缩性 和 Observer节点</h2><p>一个集群的可伸缩性即可以引入更多的集群节点，来提升某种性能。Zookeeper实际上就是提供读服务和写服务。在最早的时候，Zookeeper是通过引入<code>Follower</code>节点来提升<br><strong>读服务</strong> 的性能。但是根据我们之前学习过的读写机制和ZAB协议的内容，引入新的<code>Follower</code>节点，会造成Zookeeper<br>写服务的下降，因为<code>Leader</code>发起的投票是要半数以上的<code>Follower</code>节点响应才会成功，你<code>Follower</code>多了，就增加了协议中投票过程的压力，可能会拖慢整个投票响应的速度。结果就是，**<code>Follower</code>节点增加，集群的写操作吞吐会下降**。</p>
<p>在这种情况下，Zookeeper<br>在3.3.3版本之后，在集群架构中引入了<code>Observer</code>角色，和<code>Follower</code>唯一的区别的就是不参与投票不参与选主。这样既提升了读性能，又不会影响写性能。</p>
<p>另外提一句，Zookeeper的写性能是不能被扩展的，这也是他不适合当做服务注册发现中心的一个原因之一，在服务发现和健康监测场景下，随着服务规模的增大，无论是应用频繁发布时的服务注册带来的写请求，还是刷毫秒级的服务健康状态带来的写请求，都会Zookeeper带来很大的写压力，因为它本身的写性能是无法扩展的。后文引的文章会详细介绍。</p>
<h2 id="Zookeeper-与-CAP-理论"><a href="#Zookeeper-与-CAP-理论" class="headerlink" title="Zookeeper 与 CAP 理论"></a>Zookeeper 与 CAP 理论</h2><p>分布式领域中存在CAP理论：</p>
<ul>
<li><strong>C：Consistency</strong> ，一致性，数据一致更新，所有数据变动都是同步的。</li>
<li><strong>A：Availability</strong> ，可用性，系统具有好的响应性能。</li>
<li><strong>P：Partition tolerance</strong> ，分区容错性。以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择，也就是说无论任何消息丢失，系统都可用。</li>
</ul>
<blockquote>
<p><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blog/2018/07/cap.html">CAP 定理的含义 – 阮一峰</a></p>
</blockquote>
<p>该理论已被 <strong>证明</strong> ：任何分布式系统只可同时满足两点，无法三者兼顾。<br>因此，将精力浪费在思考如何设计能满足三者的完美系统上是愚钝的，应该根据应用场景进行适当取舍。</p>
<p>根据我们前面学习过的读写机制和ZAB协议的内容，Zookeeper本质应该是一个偏向CP的分布式系统。因为广播协议本质上是牺牲了系统的响应性能的。另外从它的以下几个特点也可以看出。也就是在第一章最后提出的几个特点。</p>
<blockquote>
<p>① 顺序一致性 从同一个客户端发起的事务请求，最终将会严格按照其发起顺序被应用到ZooKeeper中。</p>
</blockquote>
<blockquote>
<p>② 原子性<br>所有事务请求的结果在集群中所有机器上的应用情况是一致的，也就是说要么整个集群所有集群都成功应用了某一个事务，要么都没有应用，一定不会出现集群中部分机器应用了该事务，而另外一部分没有应用的情况。</p>
</blockquote>
<blockquote>
<p>③ 单一视图 无论客户端连接的是哪个ZooKeeper服务器，其看到的服务端数据模型都是一致的。</p>
</blockquote>
<blockquote>
<p>④ 可靠性 一旦服务端成功地应用了一个事务，并完成对客户端的响应，那么该事务所引起的服务端状态变更将会被一直保留下来，除非有另一个事务又对其进行了变更。</p>
</blockquote>
<h2 id="Zookeeper-作为-服务注册中心的局限性"><a href="#Zookeeper-作为-服务注册中心的局限性" class="headerlink" title="Zookeeper 作为 服务注册中心的局限性"></a>Zookeeper 作为 服务注册中心的局限性</h2><p>直接引一篇阿里中间件的文章吧，讲的比我好。实际在生产情况下，大多数公司没有达到像大公司那样的微服务量级，Zookeeper是完全能满足服务注册中心的需求的。</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/599997">阿里巴巴为什么不用 ZooKeeper 做服务发现？</a></p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/05/17/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/%E5%88%9D%E8%A7%81TiDB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="merric">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Myoboku">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Myoboku">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/05/17/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/%E5%88%9D%E8%A7%81TiDB/" class="post-title-link" itemprop="url">初见TiDB</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-05-17 22:30:00" itemprop="dateCreated datePublished" datetime="2023-05-17T22:30:00+00:00">2023-05-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">数据库与中间件</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>首先放TiDB的gitbook，里面对于tidb的大部分内容都有详细的介绍：<a target="_blank" rel="noopener" href="https://book.tidb.io/">https://book.tidb.io/</a></p>
<p>其次实际的应用当然需要PingCAP的官方文档：<a target="_blank" rel="noopener" href="https://docs.pingcap.com/zh/tidb/stable/overview%EF%BC%8C%E5%9B%A0%E4%B8%BA%E8%87%AA%E5%B7%B1%E5%8F%AA%E6%98%AF%E6%83%B3%E4%BA%86%E8%A7%A3%E4%B8%8BTiDB%EF%BC%8C%E6%84%9F%E8%A7%89%E8%BF%99%E4%B8%AA%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9C%89%E7%82%B9%E7%81%AB%EF%BC%8C%E5%A4%A7%E8%87%B4%E4%BA%86%E8%A7%A3%E4%B8%80%E4%B8%8B%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%EF%BC%8C%E8%87%AA%E5%B7%B1%E5%9C%A8%E4%B8%8A%E4%B8%80%E5%AE%B6%E5%85%AC%E5%8F%B8%E6%9C%89%E5%AE%9E%E9%99%85%E4%BD%BF%E7%94%A8%E6%8E%A5%E8%A7%A6%E8%BF%87%EF%BC%8C%E4%BD%86%E6%98%AF%E5%9B%A0%E4%B8%BA%E5%BD%93%E6%97%B6%E8%87%AA%E5%B7%B1%E7%BB%8F%E9%AA%8C%E4%B8%8D%E8%B6%B3%EF%BC%8C%E4%B8%8D%E8%A7%89%E5%BE%97%E4%BB%96%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E5%88%AB%E6%88%96%E8%80%85%E4%B8%8D%E5%90%8C%EF%BC%8C%E5%B0%B1%E6%B2%A1%E6%9C%89%E8%BF%87%E5%A4%9A%E4%BA%86%E8%A7%A3%E3%80%82%E7%8E%B0%E5%9C%A8%E5%9C%A8%E7%BE%8E%E5%9B%A2%E5%85%AC%E5%8F%B8%E5%86%85%E9%83%A8%E6%9C%89%E8%87%AA%E5%B7%B1%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%8C%E4%BD%86%E6%98%AF%E6%88%91%E8%B4%9F%E8%B4%A3%E7%9A%84%E4%B8%9A%E5%8A%A1%E5%9C%BA%E6%99%AF%E5%AE%9E%E9%99%85%E7%94%A8%E4%B8%8D%E5%88%B0%EF%BC%8C%E8%BF%98%E6%98%AF%E4%BB%A5Mysql%E4%B8%BA%E4%B8%BB%EF%BC%8C%E6%89%80%E4%BB%A5%E5%9C%A8%E8%BF%99%E9%87%8C%E6%A0%B9%E6%8D%AE%E7%BD%91%E7%BB%9C%E4%B8%8A%E7%9A%84%E8%BF%99%E4%BA%9B%E8%B5%84%E6%96%99%EF%BC%8C%E5%AF%B9TiDB%E5%81%9A%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%80%BB%E7%BB%93%E3%80%82">https://docs.pingcap.com/zh/tidb/stable/overview，因为自己只是想了解下TiDB，感觉这个数据库有点火，大致了解一下工作原理，自己在上一家公司有实际使用接触过，但是因为当时自己经验不足，不觉得他有什么特别或者不同，就没有过多了解。现在在美团公司内部有自己的分布式数据库，但是我负责的业务场景实际用不到，还是以Mysql为主，所以在这里根据网络上的这些资料，对TiDB做一个简单的学习和总结。</a></p>
<h2 id="TiDB简介"><a href="#TiDB简介" class="headerlink" title="TiDB简介"></a>TiDB简介</h2><p><a target="_blank" rel="noopener" href="https://github.com/pingcap/tidb">TiDB</a> 是 [PingCAP](<a target="_blank" rel="noopener" href="https://pingcap.com/about-">https://pingcap.com/about-</a><br>cn&#x2F;) 公司自主设计、研发的开源分布式关系型数据库，是一款同时支持在线事务处理与在线分析处理 (Hybrid Transactional and<br>Analytical Processing, HTAP) 的融合型分布式数据库产品，具备水平扩容或者缩容、金融级高可用、实时<br>HTAP、云原生的分布式数据库、兼容 MySQL 5.7 协议和 MySQL 生态等重要特性。目标是为用户提供一站式 OLTP (Online<br>Transactional Processing)、OLAP (Online Analytical Processing)、HTAP 解决方案。TiDB<br>适合高可用、强一致要求较高、数据规模较大等各种应用场景。</p>
<h3 id="五大核心特性"><a href="#五大核心特性" class="headerlink" title="五大核心特性"></a>五大核心特性</h3><ul>
<li>一键水平扩容或者缩容</li>
</ul>
<p>得益于 TiDB 存储计算分离的架构的设计，可按需对计算、存储分别进行在线扩容或者缩容，扩容或者缩容过程中对应用运维人员透明。</p>
<ul>
<li>金融级高可用</li>
</ul>
<p>数据采用多副本存储，数据副本通过 Multi-Raft<br>协议同步事务日志，多数派写入成功事务才能提交，确保数据强一致性且少数副本发生故障时不影响数据的可用性。可按需配置副本地理位置、副本数量等策略满足不同容灾级别的要求。</p>
<ul>
<li>实时 HTAP</li>
</ul>
<p>提供行存储引擎 <a target="_blank" rel="noopener" href="https://docs.pingcap.com/zh/tidb/stable/tikv-overview">TiKV</a>、列存储引擎<br><a target="_blank" rel="noopener" href="https://docs.pingcap.com/zh/tidb/stable/tiflash-overview">TiFlash</a><br>两款存储引擎，TiFlash 通过 Multi-Raft Learner 协议实时从 TiKV 复制数据，确保行存储引擎 TiKV 和列存储引擎<br>TiFlash 之间的数据强一致。TiKV、TiFlash 可按需部署在不同的机器，解决 HTAP 资源隔离的问题。</p>
<ul>
<li>云原生的分布式数据库</li>
</ul>
<p>专为云而设计的分布式数据库，通过 [TiDB Operator](<a target="_blank" rel="noopener" href="https://docs.pingcap.com/zh/tidb-in-">https://docs.pingcap.com/zh/tidb-in-</a><br>kubernetes&#x2F;stable&#x2F;tidb-operator-overview) 可在公有云、私有云、混合云中实现部署工具化、自动化。</p>
<ul>
<li>兼容 MySQL 5.7 协议和 MySQL 生态</li>
</ul>
<p>兼容 MySQL 5.7 协议、MySQL 常用的功能、MySQL 生态，应用无需或者修改少量代码即可从 MySQL 迁移到<br>TiDB。提供丰富的[数据迁移工具](<a target="_blank" rel="noopener" href="https://docs.pingcap.com/zh/tidb/stable/ecosystem-tool-">https://docs.pingcap.com/zh/tidb/stable/ecosystem-tool-</a><br>user-guide)帮助应用便捷完成数据迁移。</p>
<h3 id="四大核心应用场景"><a href="#四大核心应用场景" class="headerlink" title="四大核心应用场景"></a>四大核心应用场景</h3><ul>
<li>对数据一致性及高可靠、系统高可用、可扩展性、容灾要求较高的金融行业属性的场景</li>
</ul>
<p>众所周知，金融行业对数据一致性及高可靠、系统高可用、可扩展性、容灾要求较高。传统的解决方案是同城两个机房提供服务、异地一个机房提供数据容灾能力但不提供服务，此解决方案存在以下缺点：资源利用率低、维护成本高、RTO<br>(Recovery Time Objective) 及 RPO (Recovery Point Objective) 无法真实达到企业所期望的值。TiDB<br>采用多副本 + Multi-Raft 协议的方式将数据调度到不同的机房、机架、机器，当部分机器出现故障时系统可自动进行切换，确保系统的 RTO &lt;&#x3D; 30s<br>及 RPO &#x3D; 0。</p>
<ul>
<li>对存储容量、可扩展性、并发要求较高的海量数据及高并发的 OLTP 场景</li>
</ul>
<p>随着业务的高速发展，数据呈现爆炸性的增长，传统的单机数据库无法满足因数据爆炸性的增长对数据库的容量要求，可行方案是采用分库分表的中间件产品或者 NewSQL<br>数据库替代、采用高端的存储设备等，其中性价比最大的是 NewSQL 数据库，例如：TiDB。TiDB<br>采用计算、存储分离的架构，可对计算、存储分别进行扩容和缩容，计算最大支持 512 节点，每个节点最大支持 1000 并发，集群容量最大支持 PB 级别。</p>
<ul>
<li>Real-time HTAP 场景</li>
</ul>
<p>随着 5G、物联网、人工智能的高速发展，企业所生产的数据会越来越多，其规模可能达到数百 TB 甚至 PB 级别，传统的解决方案是通过 OLTP<br>型数据库处理在线联机交易业务，通过 ETL 工具将数据同步到 OLAP 型数据库进行数据分析，这种处理方案存在存储成本高、实时性差等多方面的问题。TiDB<br>在 4.0 版本中引入列存储引擎 TiFlash 结合行存储引擎 TiKV 构建真正的 HTAP<br>数据库，在增加少量存储成本的情况下，可以在同一个系统中做联机交易处理、实时数据分析，极大地节省企业的成本。</p>
<ul>
<li>数据汇聚、二次加工处理的场景</li>
</ul>
<p>当前绝大部分企业的业务数据都分散在不同的系统中，没有一个统一的汇总，随着业务的发展，企业的决策层需要了解整个公司的业务状况以便及时做出决策，故需要将分散在各个系统的数据汇聚在同一个系统并进行二次加工处理生成<br>T+0 或 T+1 的报表。传统常见的解决方案是采用 ETL + Hadoop 来完成，但 Hadoop<br>体系太复杂，运维、存储成本太高无法满足用户的需求。与 Hadoop 相比，TiDB 就简单得多，业务通过 ETL 工具或者 TiDB 的同步工具将数据同步到<br>TiDB，在 TiDB 中可通过 SQL 直接生成报表。</p>
<h2 id="TiDB整体架构"><a href="#TiDB整体架构" class="headerlink" title="TiDB整体架构"></a>TiDB整体架构</h2><p>在内核设计上，TiDB 分布式数据库将整体架构拆分成了多个模块，各模块之间互相通信，组成完整的 TiDB 系统。对应的架构图如下：</p>
<p>![architecture](<a target="_blank" rel="noopener" href="https://download.pingcap.com/images/docs-cn/tidb-">https://download.pingcap.com/images/docs-cn/tidb-</a><br>architecture-v6.png)</p>
<ul>
<li>TiDB Server：SQL 层，对外暴露 MySQL 协议的连接 endpoint，负责接受客户端的连接，执行 SQL 解析和优化，最终生成分布式执行计划。TiDB 层本身是无状态的，实践中可以启动多个 TiDB 实例，通过负载均衡组件（如 LVS、HAProxy 或 F5）对外提供统一的接入地址，客户端的连接可以均匀地分摊在多个 TiDB 实例上以达到负载均衡的效果。TiDB Server 本身并不存储数据，只是解析 SQL，将实际的数据读取请求转发给底层的存储节点 TiKV（或 TiFlash）。</li>
<li>PD (Placement Driver) Server：整个 TiDB 集群的元信息管理模块，负责存储每个 TiKV 节点实时的数据分布情况和集群的整体拓扑结构，提供 TiDB Dashboard 管控界面，并为分布式事务分配事务 ID。PD 不仅存储元信息，同时还会根据 TiKV 节点实时上报的数据分布状态，下发数据调度命令给具体的 TiKV 节点，可以说是整个集群的“大脑”。此外，PD 本身也是由至少 3 个节点构成，拥有高可用的能力。建议部署奇数个 PD 节点。</li>
<li>存储节点<ul>
<li>TiKV Server：负责存储数据，从外部看 TiKV 是一个分布式的提供事务的 Key-Value 存储引擎。存储数据的基本单位是 Region，每个 Region 负责存储一个 Key Range（从 StartKey 到 EndKey 的左闭右开区间）的数据，每个 TiKV 节点会负责多个 Region。TiKV 的 API 在 KV 键值对层面提供对分布式事务的原生支持，默认提供了 SI (Snapshot Isolation) 的隔离级别，这也是 TiDB 在 SQL 层面支持分布式事务的核心。TiDB 的 SQL 层做完 SQL 解析后，会将 SQL 的执行计划转换为对 TiKV API 的实际调用。所以，数据都存储在 TiKV 中。另外，TiKV 中的数据都会自动维护多副本（默认为三副本），天然支持高可用和自动故障转移。</li>
<li>TiFlash：TiFlash 是一类特殊的存储节点。和普通 TiKV 节点不一样的是，在 TiFlash 内部，数据是以列式的形式进行存储，主要的功能是为分析型的场景加速。</li>
</ul>
</li>
</ul>
<h3 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h3><h4 id="Key-Value-Pairs-键值对"><a href="#Key-Value-Pairs-键值对" class="headerlink" title="Key-Value Pairs (键值对)"></a>Key-Value Pairs (键值对)</h4><p>作为保存数据的系统，首先要决定的是数据的存储模型，也就是数据以什么样的形式保存下来。TiKV 的选择是 Key-Value 模型，并且提供有序遍历方法。<br>TiKV 数据存储的两个关键点：</p>
<ol>
<li>这是一个巨大的 Map（可以类比一下 C++ 的 std::map），也就是存储的是 Key-Value Pairs（键值对）</li>
<li>这个 Map 中的 Key-Value pair 按照 Key 的二进制顺序有序，也就是可以 Seek 到某一个 Key 的位置，然后不断地调用 Next 方法以递增的顺序获取比这个 Key 大的 Key-Value。</li>
</ol>
<p>有人可能会问，这里讲的存储模型和 SQL 中表是什么关系？在这里有一件重要的事情需要强调：</p>
<p><strong>TiKV 的 KV 存储模型和 SQL 中的 Table 无关！</strong></p>
<p>现在让我们忘记 SQL 中的任何概念，专注于讨论如何实现 TiKV 这样一个高性能、高可靠性、分布式的 Key-Value 存储。</p>
<h4 id="本地存储（RocksDB）"><a href="#本地存储（RocksDB）" class="headerlink" title="本地存储（RocksDB）"></a>本地存储（RocksDB）</h4><p>任何持久化的存储引擎，数据终归要保存在磁盘上，TiKV 也不例外。但是 TiKV 没有选择直接向磁盘上写数据，而是把数据保存在 RocksDB<br>中，具体的数据落地由 RocksDB 负责。这个选择的原因是开发一个单机存储引擎工作量很大，特别是要做一个高性能的单机引擎，需要做各种细致的优化，而<br>RocksDB 是由 Facebook 开源的一个非常优秀的单机 KV 存储引擎，可以满足 TiKV 对单机引擎的各种要求。这里可以简单的认为<br>RocksDB 是一个单机的持久化 Key-Value Map。</p>
<h4 id="Raft-协议"><a href="#Raft-协议" class="headerlink" title="Raft 协议"></a>Raft 协议</h4><p>接下来 TiKV 的实现面临一件更难的事情：如何保证单机失效的情况下，数据不丢失，不出错？</p>
<p>简单来说，需要想办法把数据复制到多台机器上，这样一台机器挂了，其他的机器上的副本还能提供服务；<br>复杂来说，还需要这个数据复制方案是可靠和高效的，并且能处理副本失效的情况。TiKV 选择了 Raft 算法。Raft 是一个一致性协议，它和 Multi<br>Paxos 实现一样的功能，但是更加易于理解。<a target="_blank" rel="noopener" href="https://raft.github.io/raft.pdf">这里</a> 是 Raft<br>的论文，感兴趣的可以看一下。下面对 Raft 做一个简要的介绍，细节问题可以参考论文。 Raft 提供几个重要的功能：</p>
<ol>
<li>Leader（主副本）选举</li>
<li>成员变更（如添加副本、删除副本、转移 Leader 等操作）</li>
<li>日志复制</li>
</ol>
<p>TiKV 利用 Raft 来做数据复制，每个数据变更都会落地为一条 Raft 日志，通过 Raft<br>的日志复制功能，将数据安全可靠地同步到复制组的每一个节点中。不过在实际写入中，根据 Raft 的协议，只需要同步复制到多数节点，即可安全地认为数据写入成功。</p>
<p><img src="https://book.tidb.io/res/session1/chapter2/tidb-storage/1.png" alt="1.png"></p>
<p>总结一下，通过单机的 RocksDB，TiKV 可以将数据快速地存储在磁盘上；通过 Raft，将数据复制到多台机器上，以防单机失效。数据的写入是通过<br>Raft 这一层的接口写入，而不是直接写 RocksDB。通过实现 Raft，TiKV 变成了一个分布式的 Key-Value<br>存储，少数几台机器宕机也能通过原生的 Raft 协议自动把副本补全，可以做到对业务无感知。</p>
<h4 id="Region"><a href="#Region" class="headerlink" title="Region"></a>Region</h4><p>讲到这里，我们需要提到一个非常重要的概念：Region。这个概念是理解后续一系列机制的基础，请仔细阅读这一小节。 前面提到，我们将 TiKV<br>看做一个巨大的有序的 KV Map，那么为了实现存储的水平扩展，我们需要将数据分散在多台机器上。这里提到的数据分散在多台机器上和 Raft<br>的数据复制不是一个概念，在这一节我们先忘记 Raft，假设所有的数据都只有一个副本，这样更容易理解。 对于一个 KV<br>系统，将数据分散在多台机器上有两种比较典型的方案：</p>
<ul>
<li>Hash：按照 Key 做 Hash，根据 Hash 值选择对应的存储节点</li>
<li>Range：按照 Key 分 Range，某一段连续的 Key 都保存在一个存储节点上</li>
</ul>
<p>TiKV 选择了第二种方式，将整个 Key-Value 空间分成很多段，每一段是一系列连续的 Key，将每一段叫做一个 Region，并且会尽量保持每个<br>Region 中保存的数据不超过一定的大小，目前在 TiKV 中默认是 96MB。每一个 Region 都可以用 [StartKey，EndKey)<br>这样一个左闭右开区间来描述。</p>
<p><img src="https://book.tidb.io/res/session1/chapter2/tidb-storage/2.png" alt="2.png"></p>
<p>注意，这里的 Region 还是和 SQL 中的表没什么关系！ 请各位继续忘记 SQL，只谈 KV。 将数据划分成 Region 后，TiKV<br>将会做两件重要的事情：</p>
<ul>
<li>以 Region 为单位，将数据分散在集群中所有的节点上，并且尽量保证每个节点上服务的 Region 数量差不多</li>
<li>以 Region 为单位做 Raft 的复制和成员管理</li>
</ul>
<p>这两点非常重要，我们一点一点来说。 先看第一点，数据按照 Key 切分成很多 Region，每个 Region<br>的数据只会保存在一个节点上面（暂不考虑多副本）。TiDB 系统会有一个组件（PD）来负责将 Region<br>尽可能均匀的散布在集群中所有的节点上，这样一方面实现了存储容量的水平扩展（增加新的节点后，会自动将其他节点上的 Region<br>调度过来），另一方面也实现了负载均衡（不会出现某个节点有很多数据，其他节点上没什么数据的情况）。同时为了保证上层客户端能够访问所需要的数据，系统中也会有一个组件（PD）记录<br>Region 在节点上面的分布情况，也就是通过任意一个 Key 就能查询到这个 Key 在哪个 Region 中，以及这个 Region<br>目前在哪个节点上（即 Key 的位置路由信息）。至于负责这两项重要工作的组件（PD），会在后续介绍。</p>
<p>对于第二点，TiKV 是以 Region 为单位做数据的复制，也就是一个 Region 的数据会保存多个副本，TiKV 将每一个副本叫做一个<br>Replica。Replica 之间是通过 Raft 来保持数据的一致，一个 Region 的多个 Replica 会保存在不同的节点上，构成一个 Raft<br>Group。其中一个 Replica 会作为这个 Group 的 Leader，其他的 Replica 作为 Follower。所有的读和写都是通过<br>Leader 进行，读操作在 Leader 上即可完成，而写操作再由 Leader 复制给 Follower。 大家理解了 Region<br>之后，应该可以理解下面这张图：</p>
<p><img src="https://book.tidb.io/res/session1/chapter2/tidb-storage/3.png" alt="3.png"></p>
<p>以 Region 为单位做数据的分散和复制，就有了一个分布式的具备一定容灾能力的 KeyValue<br>系统，不用再担心数据存不下，或者是磁盘故障丢失数据的问题。</p>
<h4 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a>MVCC</h4><p>很多数据库都会实现多版本并发控制（MVCC），TiKV 也不例外。设想这样的场景，两个客户端同时去修改一个 Key 的<br>Value，如果没有数据的多版本控制，就需要对数据上锁，在分布式场景下，可能会带来性能以及死锁问题。 TiKV 的 MVCC 实现是通过在 Key<br>后面添加版本号来实现，简单来说，没有 MVCC 之前，可以把 TiKV 看做这样的：</p>
<pre><code>Key1 -&gt; Value  
Key2 -&gt; Value  
……  
KeyN -&gt; Value  
  
</code></pre>
<p>有了 MVCC 之后，TiKV 的 Key 排列是这样的：</p>
<pre><code>Key1_Version3 -&gt; Value  
Key1_Version2 -&gt; Value  
Key1_Version1 -&gt; Value  
……  
Key2_Version4 -&gt; Value  
Key2_Version3 -&gt; Value  
Key2_Version2 -&gt; Value  
Key2_Version1 -&gt; Value  
……  
KeyN_Version2 -&gt; Value  
KeyN_Version1 -&gt; Value  
……  
  
</code></pre>
<p>注意，对于同一个 Key 的多个版本，我们把版本号较大的放在前面，版本号小的放在后面（回忆一下 Key-Value 一节我们介绍过的 Key<br>是有序的排列），这样当用户通过一个 Key + Version 来获取 Value 的时候，可以通过 Key 和 Version 构造出 MVCC 的<br>Key，也就是 Key_Version。然后可以直接通过 RocksDB 的 SeekPrefix(Key_Version)<br>API，定位到第一个大于等于这个 Key_Version 的位置。</p>
<h4 id="分布式-ACID-事务"><a href="#分布式-ACID-事务" class="headerlink" title="分布式 ACID 事务"></a>分布式 ACID 事务</h4><p>TiKV 的事务采用的是 Google 在 BigTable<br>中使用的事务模型：<a target="_blank" rel="noopener" href="https://research.google.com/pubs/pub36726.html">Percolator</a>，TiKV<br>根据这篇论文实现，并做了大量的优化。这个在后续的章节中会有详细的介绍。</p>
<p>在 TiKV 层的事务 API 的语义类似下面的伪代码：</p>
<pre><code>tx = tikv.Begin()  
    tx.Set(Key1, Value1)  
    tx.Set(Key2, Value2)  
    tx.Set(Key3, Value3)  
tx.Commit()  
  
</code></pre>
<p>这个事务中包含3条 Set 操作，TiKV 能保证这些操作要么全部成功，要么全部失败，不会出现中间状态或脏数据。 就如前面提到的，TiDB 的 SQL<br>层会将 SQL 的执行计划转换成多个 KV 操作，对于上层的同一个业务层的 SQL 事务，在底层也是对应一个 KV 层的事务，这是 TiDB 实现<br>MySQL 的事务语义的关键。</p>
<h3 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h3><h4 id="表数据与-Key-Value-的映射关系"><a href="#表数据与-Key-Value-的映射关系" class="headerlink" title="表数据与 Key-Value 的映射关系"></a>表数据与 Key-Value 的映射关系</h4><p>本小节介绍 TiDB 中数据到 (Key, Value) 键值对的映射方案。这里的数据主要包括以下两个方面：</p>
<ul>
<li>表中每一行的数据，以下简称表数据</li>
<li>表中所有索引的数据，以下简称索引数据</li>
</ul>
<h4 id="表数据与-Key-Value-的映射关系-1"><a href="#表数据与-Key-Value-的映射关系-1" class="headerlink" title="表数据与 Key-Value 的映射关系"></a>表数据与 Key-Value 的映射关系</h4><p>在关系型数据库中，一个表可能有很多列。要将一行中各列数据映射成一个 (Key, Value) 键值对，需要考虑如何构造 Key。首先，OLTP<br>场景下有大量针对单行或者多行的增、删、改、查等操作，要求数据库具备快速读取一行数据的能力。因此，对应的 Key 最好有一个唯一 ID（显示或隐式的<br>ID），以方便快速定位。其次，很多 OLAP 型查询需要进行全表扫描。如果能够将一个表中所有行的 Key<br>编码到一个区间内，就可以通过范围查询高效完成全表扫描的任务。</p>
<p>基于上述考虑，TiDB 中的表数据与 Key-Value 的映射关系作了如下设计：</p>
<ul>
<li>为了保证同一个表的数据放在一起，方便查找，TiDB 会为每个表分配一个表 ID，用 <code>TableID</code> 表示。表 ID 是一个整数，在整个集群内唯一。</li>
<li>TiDB 会为表中每行数据分配一个行 ID，用 <code>RowID</code> 表示。行 ID 也是一个整数，在表内唯一。对于行 ID，TiDB 做了一个小优化，如果某个表有整数型的主键，TiDB 会使用主键的值当做这一行数据的行 ID。</li>
</ul>
<p>每行数据按照如下规则编码成 (Key, Value) 键值对：</p>
<pre><code>Key:   tablePrefix&#123;TableID&#125;_recordPrefixSep&#123;RowID&#125;  
Value: [col1, col2, col3, col4]  
  
</code></pre>
<p>其中 <code>tablePrefix</code> 和 <code>recordPrefixSep</code> 都是特定的字符串常量，用于在 Key<br>空间内区分其他数据。其具体值在后面的小结中给出。</p>
<h4 id="索引数据和-Key-Value-的映射关系"><a href="#索引数据和-Key-Value-的映射关系" class="headerlink" title="索引数据和 Key-Value 的映射关系"></a>索引数据和 Key-Value 的映射关系</h4><p>TiDB 同时支持主键和二级索引（包括唯一索引和非唯一索引）。与表数据映射方案类似，TiDB 为表中每个索引分配了一个索引 ID，用 <code>IndexID</code><br>表示。</p>
<p>对于主键和唯一索引，需要根据键值快速定位到对应的 RowID，因此，按照如下规则编码成 (Key, Value) 键值对：</p>
<pre><code>Key:   tablePrefix&#123;tableID&#125;_indexPrefixSep&#123;indexID&#125;_indexedColumnsValue  
Value: RowID  
  
</code></pre>
<p>对于不需要满足唯一性约束的普通二级索引，一个键值可能对应多行，需要根据键值范围查询对应的 RowID。因此，按照如下规则编码成 (Key, Value)<br>键值对：</p>
<pre><code>Key:   tablePrefix&#123;TableID&#125;_indexPrefixSep&#123;IndexID&#125;_indexedColumnsValue_&#123;RowID&#125;  
Value: null  
  
</code></pre>
<h4 id="映射关系小结"><a href="#映射关系小结" class="headerlink" title="映射关系小结"></a>映射关系小结</h4><p>上述所有编码规则中的 <code>tablePrefix</code>、<code>recordPrefixSep</code> 和 <code>indexPrefixSep</code> 都是字符串常量，用于在 Key<br>空间内区分其他数据，定义如下：</p>
<pre><code>tablePrefix     = []byte&#123;&#39;t&#39;&#125;  
recordPrefixSep = []byte&#123;&#39;r&#39;&#125;  
indexPrefixSep  = []byte&#123;&#39;i&#39;&#125;  
  
</code></pre>
<p>另外请注意，上述方案中，无论是表数据还是索引数据的 Key 编码方案，一个表内所有的行都有相同的 Key<br>前缀，一个索引的所有数据也都有相同的前缀。这样具有相同的前缀的数据，在 TiKV 的 Key<br>空间内，是排列在一起的。因此只要小心地设计后缀部分的编码方案，保证编码前和编码后的比较关系不变，就可以将表数据或者索引数据有序地保存在 TiKV<br>中。采用这种编码后，一个表的所有行数据会按照 <code>RowID</code> 顺序地排列在 TiKV 的 Key<br>空间中，某一个索引的数据也会按照索引数据的具体的值（编码方案中的 <code>indexedColumnsValue</code>）顺序地排列在 Key 空间内。</p>
<h4 id="Key-Value-映射关系示例"><a href="#Key-Value-映射关系示例" class="headerlink" title="Key-Value 映射关系示例"></a>Key-Value 映射关系示例</h4><p>最后通过一个简单的例子，来理解 TiDB 的 Key-Value 映射关系。假设 TiDB 中有如下这个表：</p>
<pre><code>CREATE TABLE User (  
    ID int,  
    Name varchar(20),  
    Role varchar(20),  
    Age int,  
    PRIMARY KEY (ID),  
    KEY idxAge (Age)  
);  
</code></pre>
<p>假设该表中有 3 行数据：</p>
<pre><code>1, &quot;TiDB&quot;, &quot;SQL Layer&quot;, 10  
2, &quot;TiKV&quot;, &quot;KV Engine&quot;, 20  
3, &quot;PD&quot;, &quot;Manager&quot;, 30  
  
</code></pre>
<p>首先每行数据都会映射为一个 (Key, Value) 键值对，同时该表有一个 <code>int</code> 类型的主键，所以 <code>RowID</code> 的值即为该主键的值。假设该表的<br><code>TableID</code> 为 10，则其存储在 TiKV 上的表数据为：</p>
<pre><code>t10_r1 --&gt; [&quot;TiDB&quot;, &quot;SQL Layer&quot;, 10]  
t10_r2 --&gt; [&quot;TiKV&quot;, &quot;KV Engine&quot;, 20]  
t10_r3 --&gt; [&quot;PD&quot;, &quot;Manager&quot;, 30]  
</code></pre>
<p>除了主键外，该表还有一个非唯一的普通二级索引 <code>idxAge</code>，假设这个索引的 <code>IndexID</code> 为 1，则其存储在 TiKV 上的索引数据为：</p>
<pre><code>t10_i1_10_1 --&gt; null  
t10_i1_20_2 --&gt; null  
t10_i1_30_3 --&gt; null  
  
</code></pre>
<p>以上例子展示了 TiDB 中关系模型到 Key-Value 模型的映射规则，以及选择该方案背后的考量。</p>
<h4 id="元信息管理"><a href="#元信息管理" class="headerlink" title="元信息管理"></a>元信息管理</h4><p>TiDB 中每个 <code>Database</code> 和 <code>Table</code> 都有元信息，也就是其定义以及各项属性。这些信息也需要持久化，TiDB 将这些信息也存储在了<br>TiKV 中。</p>
<p>每个 <code>Database</code>&#x2F;<code>Table</code> 都被分配了一个唯一的 ID，这个 ID 作为唯一标识，并且在编码为 Key-Value 时，这个 ID<br>都会编码到 Key 中，再加上 <code>m_</code> 前缀。这样可以构造出一个 Key，Value 中存储的是序列化后的元信息。</p>
<p>除此之外，TiDB 还用一个专门的 (Key, Value) 键值对存储当前所有表结构信息的最新版本号。这个键值对是全局的，每次 DDL<br>操作的状态改变时其版本号都会加 1。目前，TiDB 把这个键值对持久化存储在 PD Server 中，其 Key 是<br>“&#x2F;tidb&#x2F;ddl&#x2F;global_schema_version”，Value 是类型为 int64 的版本号值。TiDB 采用 Online Schema<br>变更算法，有一个后台线程在不断地检查 PD Server 中存储的表结构信息的版本号是否发生变化，并且保证在一定时间内一定能够获取版本的变化。</p>
<h4 id="SQL-层简介"><a href="#SQL-层简介" class="headerlink" title="SQL 层简介"></a>SQL 层简介</h4><p>TiDB 的 SQL 层，即 TiDB Server，负责将 SQL 翻译成 Key-Value 操作，将其转发给共用的分布式 Key-Value 存储层<br>TiKV，然后组装 TiKV 返回的结果，最终将查询结果返回给客户端。</p>
<p>这一层的节点都是无状态的，节点本身并不存储数据，节点之间完全对等。</p>
<h4 id="SQL-运算"><a href="#SQL-运算" class="headerlink" title="SQL 运算"></a>SQL 运算</h4><p>最简单的方案就是通过上一节所述的[表数据与 Key-Value<br>的映射关系](<a target="_blank" rel="noopener" href="https://docs.pingcap.com/zh/tidb/stable/tidb-">https://docs.pingcap.com/zh/tidb/stable/tidb-</a><br>computing#%E8%A1%A8%E6%95%B0%E6%8D%AE%E4%B8%8E-key-<br>value-%E7%9A%84%E6%98%A0%E5%B0%84%E5%85%B3%E7%B3%BB)方案，将 SQL 查询映射为对 KV 的查询，再通过<br>KV 接口获取对应的数据，最后执行各种计算。</p>
<p>比如 <code>select count(*) from user where name = &quot;TiDB&quot;</code> 这样一个 SQL<br>语句，它需要读取表中所有的数据，然后检查 <code>name</code> 字段是否是 <code>TiDB</code>，如果是的话，则返回这一行。具体流程如下：</p>
<ol>
<li>构造出 Key Range：一个表中所有的 <code>RowID</code> 都在 <code>[0, MaxInt64)</code> 这个范围内，使用 <code>0</code> 和 <code>MaxInt64</code> 根据行数据的 <code>Key</code> 编码规则，就能构造出一个 <code>[StartKey, EndKey)</code>的左闭右开区间。</li>
<li>扫描 Key Range：根据上面构造出的 Key Range，读取 TiKV 中的数据。</li>
<li>过滤数据：对于读到的每一行数据，计算 <code>name = &quot;TiDB&quot;</code> 这个表达式，如果为真，则向上返回这一行，否则丢弃这一行数据。</li>
<li>计算 <code>Count(*)</code>：对符合要求的每一行，累计到 <code>Count(*)</code> 的结果上面。</li>
</ol>
<p><strong>整个流程示意图如下：</strong></p>
<p>![naive sql flow](<a target="_blank" rel="noopener" href="https://download.pingcap.com/images/docs-cn/tidb-computing-">https://download.pingcap.com/images/docs-cn/tidb-computing-</a><br>native-sql-flow.jpeg)</p>
<p>这个方案是直观且可行的，但是在分布式数据库的场景下有一些显而易见的问题：</p>
<ul>
<li>在扫描数据的时候，每一行都要通过 KV 操作从 TiKV 中读取出来，至少有一次 RPC 开销，如果需要扫描的数据很多，那么这个开销会非常大。</li>
<li>并不是所有的行都满足过滤条件 <code>name = &quot;TiDB&quot;</code>，如果不满足条件，其实可以不读取出来。</li>
<li>此查询只要求返回符合要求行的数量，不要求返回这些行的值。</li>
</ul>
<h4 id="分布式-SQL-运算"><a href="#分布式-SQL-运算" class="headerlink" title="分布式 SQL 运算"></a>分布式 SQL 运算</h4><p>为了解决上述问题，计算应该需要尽量靠近存储节点，以避免大量的 RPC 调用。首先，SQL 中的谓词条件 <code>name = &quot;TiDB&quot;</code><br>应被下推到存储节点进行计算，这样只需要返回有效的行，避免无意义的网络传输。然后，聚合函数 <code>Count(*)</code><br>也可以被下推到存储节点，进行预聚合，每个节点只需要返回一个 <code>Count(*)</code> 的结果即可，再由 SQL 层将各个节点返回的 <code>Count(*)</code><br>的结果累加求和。</p>
<p>以下是数据逐层返回的示意图：</p>
<p>![dist sql flow](<a target="_blank" rel="noopener" href="https://download.pingcap.com/images/docs-cn/tidb-computing-">https://download.pingcap.com/images/docs-cn/tidb-computing-</a><br>dist-sql-flow.png)</p>
<h4 id="SQL-层架构"><a href="#SQL-层架构" class="headerlink" title="SQL 层架构"></a>SQL 层架构</h4><p>通过上面的例子，希望大家对 SQL 语句的处理有一个基本的了解。实际上 TiDB 的 SQL<br>层要复杂得多，模块以及层次非常多，下图列出了重要的模块以及调用关系：</p>
<p>![tidb sql layer](<a target="_blank" rel="noopener" href="https://download.pingcap.com/images/docs-cn/tidb-computing-">https://download.pingcap.com/images/docs-cn/tidb-computing-</a><br>tidb-sql-layer.png)</p>
<p>用户的 SQL 请求会直接或者通过 <code>Load Balancer</code> 发送到 TiDB Server，TiDB Server 会解析 <code>MySQL Protocol Packet</code>，获取请求内容，对 SQL 进行语法解析和语义分析，制定和优化查询计划，执行查询计划并获取和处理数据。数据全部存储在<br>TiKV 集群中，所以在这个过程中 TiDB Server 需要和 TiKV 交互，获取数据。最后 TiDB Server 需要将查询结果返回给用户。</p>
<h2 id="TiDB和Mysql的区别"><a href="#TiDB和Mysql的区别" class="headerlink" title="TiDB和Mysql的区别"></a>TiDB和Mysql的区别</h2><p>TiDB 作为开源 NewSQL 数据库的典型代表之一，同样支持 SQL，支持事务 ACID 特性。在通讯协议上，TiDB 选择与 MySQL<br>完全兼容，并尽可能兼容 MySQL 的语法。因此，基于 MySQL 数据库开发的系统，大多数可以平滑迁移至<br>TiDB，而几乎不用修改代码。对用户来说，迁移成本极低，过渡自然。</p>
<p>然而，仍有一些 MySQL 的特性和行为，TiDB 目前暂时不支持或表现与 MySQL 有差异。除此之外，TiDB<br>提供了一些扩展语法和功能，为用户提供更多的便利。</p>
<p>TiDB 仍处在快速发展的道路上，对 MySQL 功能和行为的支持方面，正按 [路线图](<a target="_blank" rel="noopener" href="https://pingcap.com/docs-">https://pingcap.com/docs-</a><br>cn&#x2F;stable&#x2F;roadmap&#x2F;) 的规划在前行。</p>
<h3 id="兼容策略"><a href="#兼容策略" class="headerlink" title="兼容策略"></a>兼容策略</h3><p>先从总体上概括 TiDB 和 MySQL 兼容策略，如下表：</p>
<table>
<thead>
<tr>
<th>通讯协议</th>
<th>SQL语法</th>
<th>功能和行为</th>
</tr>
</thead>
<tbody><tr>
<td>完全兼容</td>
<td>兼容绝大多数</td>
<td>兼容大多数</td>
</tr>
</tbody></table>
<p>截至 4.0 版本，TiDB 与 MySQL 的区别总结如下表：</p>
<p>| MySQL | TiDB<br>—|—|—<br>隔离级别 | 支持读未提交、读已提交、可重复读、串行化，默认为可重复读 | 乐观事务支持快照隔离，悲观事务支持快照隔离和读已提交<br>锁机制 | 悲观锁 | 乐观锁、悲观锁<br>存储过程 | 支持 | 不支持<br>触发器 | 支持 | 不支持<br>事件 | 支持 | 不支持<br>自定义函数 | 支持 | 不支持<br>窗口函数 | 支持 | 部分支持<br>JSON | 支持 | 不支持部分 MySQL 8.0 新增的函数<br>外键约束 | 支持 | 忽略外键约束<br>字符集 |  | 只支持 ascii、latin1、binary、utf8、utf8mb4<br>增加&#x2F;删除主键 | 支持 | 通过 [alter-primary-key](<a target="_blank" rel="noopener" href="https://pingcap.com/docs-">https://pingcap.com/docs-</a><br>cn&#x2F;dev&#x2F;reference&#x2F;configuration&#x2F;tidb-server&#x2F;configuration-file&#x2F;#alter-primary-<br>key) 配置开关提供<br>CREATE TABLE tblName AS SELECT stmt | 支持 | 不支持<br>CREATE TEMPORARY TABLE | 支持 | TiDB 忽略 TEMPORARY 关键字，按照普通表创建<br>DML affected rows | 支持 | 不支持<br>AutoRandom 列属性 | 不支持 | 支持<br>Sequence 序列生成器 | 不支持 | 支持  </p>
<h3 id="区别点详述及应对方案"><a href="#区别点详述及应对方案" class="headerlink" title="区别点详述及应对方案"></a>区别点详述及应对方案</h3><h4 id="字符集支持"><a href="#字符集支持" class="headerlink" title="字符集支持"></a>字符集支持</h4><p>TiDB 目前支持以下字符集：</p>
<pre><code>tidb&gt; SHOW CHARACTER SET;  
+---------|---------------|-------------------|--------+  
| Charset | Description   | Default collation | Maxlen |  
+---------|---------------|-------------------|--------+  
| utf8    | UTF-8 Unicode | utf8_bin          |      3 |  
| utf8mb4 | UTF-8 Unicode | utf8mb4_bin       |      4 |  
| ascii   | US ASCII      | ascii_bin         |      1 |  
| latin1  | Latin1        | latin1_bin        |      1 |  
| binary  | binary        | binary            |      1 |  
+---------|---------------|-------------------|--------+  
5 rows in set (0.00 sec)  
  
</code></pre>
<p>注意：TiDB 的默认字符集为 <code>utf8mb4</code>，MySQL 5.7 中为 <code>latin1</code>，MySQL 8.0 中修改为 <code>utf8mb4</code>。<br>当指定的字符集为 <code>utf8</code> 或 <code>utf8mb4</code> 时，TiDB 仅支持合法的 UTF8 字符。对于不合法的字符，会报错：<code>incorrect utf8 value</code>，该字符合法性检查与 MySQL 8.0 一致。对于 MySQL 5.7 及以下版本，会存在允许插入非法 UTF8 字符，但同步到 TiDB<br>报错的情况。此时，可以通过 TiDB 配置<br>[“tidb_skip_utf8_check”](<a target="_blank" rel="noopener" href="https://pingcap.com/docs/stable/faq/upgrade/#issue-3-error-1366-hy000-incorrect-">https://pingcap.com/docs/stable/faq/upgrade/#issue-3-error-1366-hy000-incorrect-</a><br>utf8-value-f09f8c80-for-column-a) 跳过 UTF8 字符合法性检查强制写入 TiDB。</p>
<p>每一个字符集，都有一个默认的 Collation，例如 <code>utf8</code> 的默认 Collation 为 <code>utf8_bin</code>，TiDB 中字符集的默认<br>Collation 与 MySQL 不一致，具体如下：</p>
<table>
<thead>
<tr>
<th>字符集</th>
<th>TiDB 默认 Collation</th>
<th>MySQL 5.7 默认 Collation</th>
<th>MySQL 8.0 默认 Collation</th>
</tr>
</thead>
<tbody><tr>
<td>utf8</td>
<td>utf8_bin</td>
<td>utf8_general_ci</td>
<td>utf8_general_ci</td>
</tr>
<tr>
<td>utf8mb4</td>
<td>utf8mb4_bin</td>
<td>utf8mb4_general_ci</td>
<td>utf8mb4_0900_ai_ci</td>
</tr>
<tr>
<td>ascii</td>
<td>ascii_bin</td>
<td>ascii_general_ci</td>
<td>ascii_general_ci</td>
</tr>
<tr>
<td>latin1</td>
<td>latin1_bin</td>
<td>latin1_swedish_ci</td>
<td>latin1_swedish_ci</td>
</tr>
<tr>
<td>binary</td>
<td>binary</td>
<td>binary</td>
<td>binary</td>
</tr>
</tbody></table>
<p>在 4.0 版本之前，TiDB 中可以任意指定字符集对应的所有 Collation，并把它们按照默认 Collation<br>处理，即以编码字节序为字符定序。同时，并未像 MySQL 一样，在比较前按照 Collation 的 <code>PADDING</code><br>属性将字符补齐空格。因此，会造成以下的行为区别：</p>
<pre><code>tidb&gt; create table t(a varchar(20) charset utf8mb4 collate utf8mb4_general_ci primary key);  
Query OK, 0 rows affected  
tidb&gt; insert into t values (&#39;A&#39;);  
Query OK, 1 row affected  
tidb&gt; insert into t values (&#39;a&#39;);  
Query OK, 1 row affected // MySQL 中，由于 utf8mb4_general_ci 大小写不敏感，报错 Duplicate entry &#39;a&#39;.  
tidb&gt; insert into t1 values (&#39;a &#39;);  
Query OK, 1 row affected // MySQL 中，由于补齐空格比较，报错 Duplicate entry &#39;a &#39;  
</code></pre>
<p>TiDB 4.0 新增了完整的 Collation 支持框架，允许实现所有 MySQL 中的 Collation，并新增了配置开关<br><code>new_collation_enabled_on_first_boostrap</code>，在集群初次初始化时决定是否启用新 Collation<br>框架。在该配置开关打开之后初始化集群，可以通过 <code>mysql</code>.<code>tidb</code> 表中的 <code>new_collation_enabled</code> 变量确认新<br>Collation 是否启用：</p>
<pre><code>tidb&gt; select VARIABLE_VALUE from mysql.tidb where VARIABLE_NAME=&#39;new_collation_enabled&#39;;  
+----------------+  
| VARIABLE_VALUE |  
+----------------+  
| True           |  
+----------------+  
1 row in set (0.00 sec)  
</code></pre>
<p>在新 Collation 启用后，TiDB 修正了 <code>utf8mb4_general_bin</code> 和 <code>utf8_general_bin</code> 的<br><code>PADDING</code> 行为，会将字符串补齐空格后比较；同时支持了 <code>utf8mb4_general_ci</code> 和 <code>utf8_general_ci</code>，这两个<br>Collation 与 MySQL 保持兼容。</p>
<h4 id="系统时区"><a href="#系统时区" class="headerlink" title="系统时区"></a>系统时区</h4><p>在 MySQL 中，系统时区 <code>system_time_zone</code> 在 MySQL 服务启动时通过 <a target="_blank" rel="noopener" href="https://dev.mysql.com/doc/refman/8.0/en/time-zone-support.html">环境变量 <code>TZ</code> 或命令行参数<br><code>--timezone</code></a><br>指定。</p>
<p>对于 TiDB 而言，作为一个分布式数据库，TiDB 需要保证整个集群的系统时区始终一致。因此 TiDB 的系统时区在集群初始化时，由负责初始化的 TiDB<br>节点环境变量 <code>TZ</code> 决定。集群初始化后，固定在集群状态表 <code>mysql</code>.<code>tidb</code> 中：</p>
<pre><code>tidb&gt; select VARIABLE_VALUE from mysql.tidb where VARIABLE_NAME=&#39;system_tz&#39;;  
+----------------+  
| VARIABLE_VALUE |  
+----------------+  
| Asia/Shanghai  |  
+----------------+  
1 row in set (0.00 sec)  
  
</code></pre>
<p>通过查看 <code>system_time_zone</code> 变量，可以看到该值与状态表中的 <code>system_tz</code> 保持一致：</p>
<pre><code>tidb&gt; select @@system_time_zone;  
+--------------------+  
| @@system_time_zone |  
+--------------------+  
| Asia/Shanghai      |  
+--------------------+  
1 row in set (0.00 sec)  
</code></pre>
<p>请注意，这意味着 TiDB 的系统时区在初始化后不再更改。若需要改变集群的时区，可以显式指定 <code>time_zone</code> 系统变量，例如：</p>
<pre><code>tidb&gt; set @@global.time_zone=&#39;UTC&#39;;  
Query OK, 0 rows affected (0.00 sec)  
</code></pre>
<h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><h3 id="乐观事务"><a href="#乐观事务" class="headerlink" title="乐观事务"></a>乐观事务</h3><p>事务是数据库的基础，提供高效的、支持完整 ACID 的分布式事务更是分布式数据库的立足之本。本章节会首先介绍事务的基本概念，然后介绍 TiDB 基于<br>Percolator 实现的乐观事务以及在使用上的最佳实践。</p>
<h4 id="隔离级别"><a href="#隔离级别" class="headerlink" title="隔离级别"></a>隔离级别</h4><p>对用户来说，最友好的并发事务执行顺序为每个事务独占整个数据库，并发事务执行的结果与一个个串行执行相同，也就是串行化，能够避免所有的异常情况。但在这种隔离级别下，并发执行的事务性能较差，提供更弱保证的隔离级别能够显著提升系统的性能。根据允许出现的异常，SQL-92<br>标准定义了 4 种隔离级别：读未提交 (READ UNCOMMITTED)、读已提交 (READ COMMITTED)、可重复读 (REPEATABLE<br>READ)、串行化 (SERIALIZABLE)。详见下表：</p>
<table>
<thead>
<tr>
<th>Isolation Level</th>
<th>Dirty Write</th>
<th>Dirty Read</th>
<th>Fuzzy Read</th>
<th>Phantom</th>
</tr>
</thead>
<tbody><tr>
<td>READ UNCOMMITTED</td>
<td>Not Possible</td>
<td>Possible</td>
<td>Possible</td>
<td>Possible</td>
</tr>
<tr>
<td>READ COMMITTED</td>
<td>Not Possible</td>
<td>Not possible</td>
<td>Possible</td>
<td>Possible</td>
</tr>
<tr>
<td>REPEATABLE READ</td>
<td>Not Possible</td>
<td>Not possible</td>
<td>Not possible</td>
<td>Possible</td>
</tr>
<tr>
<td>SERIALIZABLE</td>
<td>Not Possible</td>
<td>Not possible</td>
<td>Not possible</td>
<td>Not possible</td>
</tr>
</tbody></table>
<h4 id="并发控制"><a href="#并发控制" class="headerlink" title="并发控制"></a>并发控制</h4><p>数据库有多种并发控制方法，这里只介绍以下两种：</p>
<ul>
<li>乐观并发控制（OCC）：在事务提交阶段检测冲突</li>
<li>悲观并发控制（PCC）：在事务执行阶段检测冲突</li>
</ul>
<p>乐观并发控制期望事务间数据冲突不多，只在提交阶段检测冲突能够获取更高的性能。悲观并发控制更适合数据冲突较多的场景，能够避免乐观事务在这类场景下事务因冲突而回滚的问题，但相比乐观并发控制，在没有数据冲突的场景下，性能相对要差。</p>
<h3 id="TiDB-乐观事务实现"><a href="#TiDB-乐观事务实现" class="headerlink" title="TiDB 乐观事务实现"></a>TiDB 乐观事务实现</h3><p>TiDB 基于 Google [Percolator](<a target="_blank" rel="noopener" href="https://storage.googleapis.com/pub-tools-public-">https://storage.googleapis.com/pub-tools-public-</a><br>publication-data&#x2F;pdf&#x2F;36726.pdf) 实现了支持完整 ACID、基于快照隔离级别（Snapshot<br>Isolation）的分布式乐观事务。TiDB 乐观事务需要将事务的所有修改都保存在内存中，直到提交时才会写入 TiKV 并检测冲突。</p>
<h4 id="Snapshot-Isolation"><a href="#Snapshot-Isolation" class="headerlink" title="Snapshot Isolation"></a>Snapshot Isolation</h4><p>Percolator 使用多版本并发控制（MVCC）来实现快照隔离级别，与可重复读的区别在于整个事务是在一个一致的快照上执行。TiDB 使用<br><a target="_blank" rel="noopener" href="https://github.com/pingcap/pd">PD</a> 作为全局授时服务（TSO）来提供单调递增的版本号：</p>
<ul>
<li>事务开始时获取 start timestamp，也是快照的版本号；事务提交时获取 commit timestamp，同时也是数据的版本号</li>
<li>事务只能读到在事务 start timestamp 之前最新已提交的数据</li>
<li>事务在提交时会根据 timestamp 来检测数据冲突</li>
</ul>
<h4 id="两阶段提交（2PC）"><a href="#两阶段提交（2PC）" class="headerlink" title="两阶段提交（2PC）"></a>两阶段提交（2PC）</h4><p>TiDB 使用两阶段提交(Two-Phase Commit）来保证分布式事务的原子性，分为 Prewrite 和 Commit 两个阶段：</p>
<ul>
<li>Prewrite：对事务修改的每个 Key 检测冲突并写入 lock 防止其他事务修改。对于每个事务，TiDB 会从涉及到改动的所有 Key 中选中一个作为当前事务的 Primary Key，事务提交或回滚都需要先修改 Primary Key，以它的提交与否作为整个事务执行结果的标识。</li>
<li>Commit：Prewrite 全部成功后，先同步提交 Primary Key，成功后事务提交成功，其他 Secondary Keys 会异步提交。</li>
</ul>
<p>Percolator<br>将事务的所有状态都保存在底层支持高可用、强一致性的存储系统中，从而弱化了传统两阶段提交中协调者（Coordinator）的作用，所有的客户端都可以根据存储系统中的事务状态对事务进行提交或回滚。</p>
<h4 id="两阶段提交过程"><a href="#两阶段提交过程" class="headerlink" title="两阶段提交过程"></a>两阶段提交过程</h4><p>事务的两阶段提交过程如下：</p>
<p><img src="https://book.tidb.io/res/session1/chapter6/optimistic-txn/1.png" alt="1.png"></p>
<ol>
<li><p>客户端开始一个事务。</p>
</li>
<li><p>TiDB 向 PD 获取 tso 作为当前事务的 start timestamp。</p>
</li>
<li><p>客户端发起读或写请求。</p>
</li>
<li><p>客户端发起 Commit。</p>
</li>
<li><p>TiDB 开始 <strong>两阶段提交</strong> ，保证分布式事务的原子性，让数据真正落盘。</p>
</li>
</ol>
<p>i. TiDB 从当前要写入的数据中选择一个 Key 作为当前事务的 Primary Key。</p>
<p>ii. TiDB 并发地向所有涉及的 TiKV 发起 Prewrite 请求。TiKV 收到 Prewrite<br>请求后，检查数据版本信息是否存在冲突，符合条件的数据会被加锁。</p>
<p>iii. TiDB 收到所有 Prewrite 响应且所有 Prewrite 都成功。</p>
<p>iv. TiDB 向 PD 获取第二个全局唯一递增版本号，定义为本次事务的 commit timestamp。</p>
<p>v. TiDB 向 Primary Key 所在 TiKV 发起第二阶段提交。TiKV 收到 Commit 操作后，检查锁是否存在并清理 Prewrite<br>阶段留下的锁。</p>
<ol start="6">
<li><p>TiDB 向客户端返回事务提交成功的信息。</p>
</li>
<li><p>TiDB 异步清理本次事务遗留的锁信息。</p>
</li>
</ol>
<h3 id="悲观事务"><a href="#悲观事务" class="headerlink" title="悲观事务"></a>悲观事务</h3><p>乐观事务模型在分布式系统中有着极大的性能优势，但为了让 TiDB 的使用方式更加贴近传统单机数据库，更好的适配用户场景，TiDB v3.0<br>及之后版本在乐观事务模型的基础上实现了悲观事务模型。本文将介绍 TiDB 悲观事务模型特点。</p>
<h4 id="悲观锁解决的问题"><a href="#悲观锁解决的问题" class="headerlink" title="悲观锁解决的问题"></a>悲观锁解决的问题</h4><p>通过支持悲观事务，降低用户修改代码的难度甚至不用修改代码：</p>
<ul>
<li>在 v3.0.8 之前，TiDB 默认使用的乐观事务模式会导致事务提交时因为冲突而失败。为了保证事务的成功率，需要修改应用程序，加上重试的逻辑。</li>
<li>乐观事务模型在冲突严重的场景和重试代价大的场景无法满足用户需求，支持悲观事务可以 弥补这方面的缺陷，拓展 TiDB 的应用场景。</li>
</ul>
<p>以发工资场景为例：对于一个用人单位来说，发工资的过程其实就是从企业账户给多个员工的个人账户转账的过程，一般来说都是批量操作，在一个大的转账事务中可能涉及到成千上万的更新，想象一下如果这个大事务执行的这段时间内，某个个人账户发生了消费（变更），如果这个大事务是乐观事务模型，提交的时候肯定要回滚，涉及上万个个人账户发生消费是大概率事件，如果不做任何处理，最坏的情况是这个大事务永远没办法执行，一直在重试和回滚（饥饿）。</p>
<h4 id="基于-Percolator-的悲观事务"><a href="#基于-Percolator-的悲观事务" class="headerlink" title="基于 Percolator 的悲观事务"></a>基于 Percolator 的悲观事务</h4><p>悲观事务在 Percolator 乐观事务基础上实现，在 Prewrite 之前增加了 Acquire Pessimistic Lock 阶段用于避免<br>Prewrite 时发生冲突：</p>
<ul>
<li>每个 DML 都会加悲观锁，锁写到 TiKV 里，同样会通过 raft 同步。</li>
<li>悲观事务在加悲观锁时检查各种约束，如 Write Conflict、key 唯一性约束等。</li>
<li>悲观锁不包含数据，只有锁，只用于防止其他事务修改相同的 Key，不会阻塞读，但 Prewrite 后会阻塞读（和 Percolator 相同，但有了大事务支持后将不会阻塞读）。</li>
<li>提交时同 Percolator，悲观锁的存在保证了 Prewrite 不会发生 Write Conflict，保证了提交一定成功。</li>
</ul>
<p><img src="https://book.tidb.io/res/session1/chapter6/pessimistic-txn/1.png" alt="1.png"></p>
<h4 id="等锁顺序"><a href="#等锁顺序" class="headerlink" title="等锁顺序"></a>等锁顺序</h4><p>TiKV 中实现了 <code>Waiter Manager</code> 用于管理等锁的事务，当悲观事务加锁遇到其他事务的锁时，将会进入 <code>Waiter Manager</code><br>中等待锁被释放，TiKV 会尽可能按照事务 start timestamp 的顺序来依次获取锁，从而避免事务间无用的竞争。</p>
<h4 id="分布式死锁检测"><a href="#分布式死锁检测" class="headerlink" title="分布式死锁检测"></a>分布式死锁检测</h4><p>在 <code>Waiter Manager</code> 中等待锁的事务间可能发生死锁，而且可能发生在不同的机器上，<code>TiDB</code> 采用分布式死锁检测来解决死锁问题：</p>
<ul>
<li>在整个 TiKV 集群中，有一个死锁检测器 leader。</li>
<li>当要等锁时，其他节点会发送检测死锁的请求给 leader。</li>
</ul>
<p><img src="https://book.tidb.io/res/session1/chapter6/pessimistic-txn/2.png" alt="2.png"></p>
<p>死锁检测器基于 Raft 实现了高可用，等锁事务也会定期发送死锁检测请求给死锁检测器的 leader，从而保证了即使之前 leader<br>宕机的情况下也能检测到死锁。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/05/17/jvm/JVM%E7%9A%84%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="merric">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Myoboku">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Myoboku">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/05/17/jvm/JVM%E7%9A%84%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/" class="post-title-link" itemprop="url">JVM内存结构</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-05-17 22:30:00" itemprop="dateCreated datePublished" datetime="2023-05-17T22:30:00+00:00">2023-05-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="JVM内存结构"><a href="#JVM内存结构" class="headerlink" title="JVM内存结构"></a>JVM内存结构</h1><p>首先，放张jvm架构图</p>
<p><img src="/images/JVM%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84.jpg" alt="JVM架构图"></p>
<p>JVM内存结构主要有三大块： <strong>堆内存</strong> 、 <strong>方法区</strong> 和 <strong>栈</strong><br>。堆内存是JVM中最大的一块由年轻代和老年代组成，而年轻代内存又被分成三部分， <strong>Eden空间</strong> 、 <strong>From Survivor空间</strong> 、<br><strong>To Survivor空间</strong> ,默认情况下年轻代按照 <strong>8:1:1</strong> 的比例来分配；</p>
<p>方法区存储类信息、常量、静态变量等数据，是线程共享的区域，为与Java堆区分，方法区还有一个别名Non-<br>Heap(非堆)；栈又分为java虚拟机栈和本地方法栈主要用于方法的执行。</p>
<p>Java<br>虚拟机定义了若干种程序运行期间会使用到的运行时数据区，其中有一些会随着虚拟机启动而创建，随着虚拟机退出而销毁。另外一些则是与线程一一对应的，这些与线程一一对应的数据区域会随着线程开始和结束而创建和销毁。</p>
<ul>
<li><strong>线程私有</strong> ：程序计数器、虚拟机栈、本地方法区</li>
<li><strong>线程共享</strong> ：堆、方法区, 堆外内存（Java7的永久代或JDK8的元空间、代码缓存）</li>
</ul>
<h2 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h2><p>程序计数寄存器（ <strong>Program Counter Register</strong> ），Register 的命名源于 CPU<br>的寄存器，寄存器存储指令相关的线程信息，CPU 只有把数据装载到寄存器才能够运行。</p>
<p>这里，并非是广义上所指的物理寄存器，叫程序计数器（或PC计数器或指令计数器）会更加贴切，并且也不容易引起一些不必要的误会。 <strong>JVM 中的 PC<br>寄存器是对物理 PC 寄存器的一种抽象模拟</strong> 。</p>
<p>程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的 <strong>行号指示器</strong> 。</p>
<h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><p>PC 寄存器用来存储指向下一条指令的地址，即将要执行的指令代码。由执行引擎读取下一条指令。</p>
<p><img src="/images/PC%E5%AF%84%E5%AD%98%E5%99%A8.jpg" alt="PC寄存器"></p>
<p>（分析：进入class文件所在目录，执行 <code>javap -v xx.class</code> 反解析（或者通过 IDEA 插件 <code>Jclasslib</code><br>直接查看，上图），可以看到当前类对应的Code区（汇编指令）、本地变量表、异常表和代码行偏移量映射表、常量池等信息。）</p>
<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><blockquote>
<p>通过下面两个问题，理解下PC计数器</p>
</blockquote>
<ul>
<li><strong>使用PC寄存器存储字节码指令地址有什么用呢？为什么使用PC寄存器记录当前线程的执行地址呢？</strong></li>
</ul>
<p>因为CPU需要不停的切换各个线程，这时候切换回来以后，就得知道接着从哪开始继续执行。JVM的字节码解释器就需要通过改变PC寄存器的值来明确下一条应该执行什么样的字节码指令。</p>
<ul>
<li><strong>PC寄存器为什么会被设定为线程私有的？</strong></li>
</ul>
<p>多线程在一个特定的时间段内只会执行其中某一个线程方法，CPU会不停的做任务切换，这样必然会导致经常中断或恢复。为了能够准确的记录各个线程正在执行的当前字节码指令地址，所以为每个线程都分配了一个PC寄存器，每个线程都独立计算，不会互相影响。</p>
<blockquote>
<p>相关总结如下：</p>
</blockquote>
<ul>
<li>它是一块很小的内存空间，几乎可以忽略不计。也是运行速度最快的存储区域</li>
<li>在 JVM 规范中，每个线程都有它自己的程序计数器，是线程私有的，生命周期与线程的生命周期一致</li>
<li>任何时间一个线程都只有一个方法在执行，也就是所谓的 <strong>当前方法</strong> 。如果当前线程正在执行的是 Java 方法，程序计数器记录的是 JVM 字节码指令地址，如果是执行 native 方法，则是未指定值（undefined）</li>
<li>它是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成</li>
<li>字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令</li>
<li><strong>它是唯一一个在 JVM 规范中没有规定任何<code>OutOfMemoryError</code> 情况的区域</strong></li>
</ul>
<h2 id="虚拟机栈"><a href="#虚拟机栈" class="headerlink" title="虚拟机栈"></a>虚拟机栈</h2><h3 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h3><blockquote>
<p>Java 虚拟机栈(Java Virtual Machine Stacks)，早期也叫 Java<br>栈。每个线程在创建的时候都会创建一个虚拟机栈，其内部保存一个个的栈帧(Stack Frame），对应着一次次 Java<br>方法调用，是线程私有的，生命周期和线程一致。</p>
</blockquote>
<p><strong>作用</strong> ：主管 Java 程序的运行，它保存方法的局部变量、部分结果，并参与方法的调用和返回。</p>
<p><strong>特点</strong> ：</p>
<ul>
<li>栈是一种快速有效的分配存储方式，访问速度仅次于程序计数器</li>
<li>JVM 直接对虚拟机栈的操作只有两个：每个方法执行，伴随着 <strong>入栈</strong> （进栈&#x2F;压栈），方法执行结束 <strong>出栈</strong></li>
<li><strong>栈不存在垃圾回收问题</strong></li>
</ul>
<p><strong>栈中可能出现的异常</strong> ：</p>
<p>Java 虚拟机规范允许 <strong>Java虚拟机栈的大小是动态的或者是固定不变的</strong></p>
<ul>
<li>如果采用固定大小的 Java 虚拟机栈，那每个线程的 Java 虚拟机栈容量可以在线程创建的时候独立选定。如果线程请求分配的栈容量超过 Java 虚拟机栈允许的最大容量，Java 虚拟机将会抛出一个 <strong>StackOverflowError</strong> 异常</li>
<li>如果 Java 虚拟机栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的虚拟机栈，那 Java 虚拟机将会抛出一个 <strong>OutOfMemoryError</strong> 异常</li>
</ul>
<p>可以通过参数<code>-Xss</code>来设置线程的最大栈空间，栈的大小直接决定了函数调用的最大可达深度。</p>
<p>官方提供的参考工具，可查一些参数和操作：<a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/8/docs/technotes/tools/windows/java.html#BGBCIEFC">https://docs.oracle.com/javase/8/docs/technotes/tools/windows/java.html#BGBCIEFC</a></p>
<h3 id="栈的存储单位"><a href="#栈的存储单位" class="headerlink" title="栈的存储单位"></a>栈的存储单位</h3><p>栈中存储什么？</p>
<ul>
<li>每个线程都有自己的栈，栈中的数据都是以 <strong>栈帧（Stack Frame）的格式存在</strong></li>
<li>在这个线程上正在执行的每个方法都各自有对应的一个栈帧</li>
<li>栈帧是一个内存区块，是一个数据集，维系着方法执行过程中的各种数据信息</li>
</ul>
<h3 id="栈运行原理"><a href="#栈运行原理" class="headerlink" title="栈运行原理"></a>栈运行原理</h3><ul>
<li>JVM 直接对 Java 栈的操作只有两个，对栈帧的 <strong>压栈</strong> 和 <strong>出栈</strong> ，遵循“先进后出&#x2F;后进先出”原则</li>
<li>在一条活动线程中，一个时间点上，只会有一个活动的栈帧。即只有当前正在执行的方法的栈帧（ <strong>栈顶栈帧</strong> ）是有效的，这个栈帧被称为 <strong>当前栈帧</strong> （Current Frame），与当前栈帧对应的方法就是 <strong>当前方法</strong> （Current Method），定义这个方法的类就是 <strong>当前类</strong> （Current Class）</li>
<li>执行引擎运行的所有字节码指令只针对当前栈帧进行操作</li>
<li>如果在该方法中调用了其他方法，对应的新的栈帧会被创建出来，放在栈的顶端，称为新的当前栈帧</li>
<li>不同线程中所包含的栈帧是不允许存在相互引用的，即不可能在一个栈帧中引用另外一个线程的栈帧</li>
<li>如果当前方法调用了其他方法，方法返回之际，当前栈帧会传回此方法的执行结果给前一个栈帧，接着，虚拟机会丢弃当前栈帧，使得前一个栈帧重新成为当前栈帧</li>
<li>Java 方法有两种返回函数的方式， <strong>一种是正常的函数返回，使用 return 指令，另一种是抛出异常，不管用哪种方式，都会导致栈帧被弹出</strong></li>
</ul>
<p>IDEA 在 debug 时候，可以在 debug 窗口看到 Frames 中各种方法的压栈和出栈情况</p>
<p><img src="/images/%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%E6%A0%88.jpg" alt="方法调用栈"></p>
<h3 id="栈帧的内部结构"><a href="#栈帧的内部结构" class="headerlink" title="栈帧的内部结构"></a>栈帧的内部结构</h3><p>每个 <strong>栈帧</strong> （Stack Frame）中存储着：</p>
<ul>
<li>局部变量表（Local Variables）</li>
<li>操作数栈（Operand Stack）(或称为表达式栈)</li>
<li>动态链接（Dynamic Linking）：指向运行时常量池的方法引用</li>
<li>方法返回地址（Return Address）：方法正常退出或异常退出的地址</li>
<li>一些附加信息</li>
</ul>
<p><img src="/images/%E6%A0%88%E8%A7%A3%E6%9E%90.jpg" alt="栈解析"></p>
<h4 id="局部变量表"><a href="#局部变量表" class="headerlink" title="局部变量表"></a>局部变量表</h4><ul>
<li>局部变量表也被称为局部变量数组或者本地变量表</li>
<li>是一组变量值存储空间， <strong>主要用于存储方法参数和定义在方法体内的局部变量</strong> ，包括编译器可知的各种 Java 虚拟机 <strong>基本数据类型</strong> （boolean、byte、char、short、int、float、long、double）、 <strong>对象引用</strong> （reference类型，它并不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此相关的位置）和 <strong>returnAddress</strong> 类型（指向了一条字节码指令的地址，已被异常表取代）</li>
<li>由于局部变量表是建立在线程的栈上，是线程的私有数据，因此 <strong>不存在数据安全问题</strong></li>
<li><strong>局部变量表所需要的容量大小是编译期确定下来的</strong> ，并保存在方法的 Code 属性的 <code>maximum local variables</code> 数据项中。在方法运行期间是不会改变局部变量表的大小的</li>
<li>方法嵌套调用的次数由栈的大小决定。一般来说， <strong>栈越大，方法嵌套调用次数越多</strong> 。对一个函数而言，它的参数和局部变量越多，使得局部变量表膨胀，它的栈帧就越大，以满足方法调用所需传递的信息增大的需求。进而函数调用就会占用更多的栈空间，导致其嵌套调用次数就会减少。</li>
<li><strong>局部变量表中的变量只在当前方法调用中有效</strong> 。在方法执行时，虚拟机通过使用局部变量表完成参数值到参数变量列表的传递过程。当方法调用结束后，随着方法栈帧的销毁，局部变量表也会随之销毁。</li>
<li>参数值的存放总是在局部变量数组的 index0 开始，到数组长度 -1 的索引结束</li>
</ul>
<h5 id="槽-Slot"><a href="#槽-Slot" class="headerlink" title="槽 Slot"></a>槽 Slot</h5><ul>
<li>局部变量表最基本的存储单元是 Slot（变量槽）</li>
<li>在局部变量表中，32 位以内的类型只占用一个 Slot(包括returnAddress类型)，64 位的类型（long和double）占用两个连续的 Slot<ul>
<li>byte、short、char 在存储前被转换为int，boolean也被转换为int，0 表示 false，非 0 表示 true</li>
<li>long 和 double 则占据两个 Slot</li>
</ul>
</li>
<li>JVM 会为局部变量表中的每一个 Slot 都分配一个访问索引，通过这个索引即可成功访问到局部变量表中指定的局部变量值，索引值的范围从 0 开始到局部变量表最大的 Slot 数量</li>
<li>当一个实例方法被调用的时候，它的方法参数和方法体内部定义的局部变量将会 <strong>按照顺序被复制</strong> 到局部变量表中的每一个 Slot 上</li>
<li><strong>如果需要访问局部变量表中一个 64bit 的局部变量值时，只需要使用前一个索引即可</strong> 。（比如：访问 long 或 double 类型变量，不允许采用任何方式单独访问其中的某一个 Slot）</li>
<li>如果当前帧是由构造方法或实例方法创建的，那么该对象引用 this 将会存放在 index 为 0 的 Slot 处，其余的参数按照参数表顺序继续排列（这里就引出一个问题：静态方法中为什么不可以引用 this，就是因为this 变量不存在于当前方法的局部变量表中）</li>
<li><strong>栈帧中的局部变量表中的槽位是可以重用的</strong> ，如果一个局部变量过了其作用域，那么在其作用域之后申明的新的局部变量就很有可能会复用过期局部变量的槽位，从而 <strong>达到节省资源的目的</strong> 。（下图中，this、a、b、c 理论上应该有 4 个变量，c 复用了 b 的槽）</li>
</ul>
<p><img src="/images/%E6%A7%BD.jpg" alt="槽"></p>
<ul>
<li>在栈帧中，与性能调优关系最为密切的就是局部变量表。在方法执行时，虚拟机使用局部变量表完成方法的传递</li>
<li><strong>局部变量表中的变量也是重要的垃圾回收根节点，只要被局部变量表中直接或间接引用的对象都不会被回收</strong></li>
</ul>
<h4 id="操作数栈"><a href="#操作数栈" class="headerlink" title="操作数栈"></a>操作数栈</h4><ul>
<li>每个独立的栈帧中除了包含局部变量表之外，还包含一个 <strong>后进先出</strong> （Last-In-First-Out）的操作数栈，也可以称为 <strong>表达式栈</strong> （Expression Stack）</li>
<li><strong>操作数栈，在方法执行过程中，根据字节码指令，往操作数栈中写入数据或提取数据，即入栈（push）、出栈（pop）</strong></li>
<li>某些字节码指令将值压入操作数栈，其余的字节码指令将操作数取出栈。使用它们后再把结果压入栈。比如，执行复制、交换、求和等操作</li>
</ul>
<h5 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h5><ul>
<li>操作数栈， <strong>主要用于保存计算过程的中间结果，同时作为计算过程中变量临时的存储空间</strong></li>
<li>操作数栈就是 JVM 执行引擎的一个工作区，当一个方法刚开始执行的时候，一个新的栈帧也会随之被创建出来， <strong>此时这个方法的操作数栈是空的</strong></li>
<li>每一个操作数栈都会拥有一个明确的栈深度用于存储数值，其所需的最大深度在编译期就定义好了，保存在方法的 Code 属性的 <code>max_stack</code> 数据项中</li>
<li>栈中的任何一个元素都可以是任意的 Java 数据类型 <ul>
<li>32bit 的类型占用一个栈单位深度</li>
<li>64bit 的类型占用两个栈单位深度</li>
</ul>
</li>
<li>操作数栈并非采用访问索引的方式来进行数据访问的，而是只能通过标准的入栈和出栈操作来完成一次数据访问</li>
<li><strong>如果被调用的方法带有返回值的话，其返回值将会被压入当前栈帧的操作数栈中</strong> ，并更新 PC 寄存器中下一条需要执行的字节码指令</li>
<li>操作数栈中元素的数据类型必须与字节码指令的序列严格匹配，这由编译器在编译期间进行验证，同时在类加载过程中的类检验阶段的数据流分析阶段要再次验证</li>
<li>另外，我们说 <strong>Java虚拟机的解释引擎是基于栈的执行引擎</strong> ，其中的栈指的就是操作数栈</li>
</ul>
<h5 id="栈顶缓存（Top-of-stack-Cashing）"><a href="#栈顶缓存（Top-of-stack-Cashing）" class="headerlink" title="栈顶缓存（Top-of-stack-Cashing）"></a>栈顶缓存（Top-of-stack-Cashing）</h5><p>HotSpot 的执行引擎采用的并非是基于寄存器的架构，但这并不代表 HotSpot VM 的实现并没有间接利用到寄存器资源。寄存器是物理 CPU<br>中的组成部分之一，它同时也是 CPU<br>中非常重要的高速存储资源。一般来说，寄存器的读&#x2F;写速度非常迅速，甚至可以比内存的读&#x2F;写速度快上几十倍不止，不过寄存器资源却非常有限，不同平台下的CPU<br>寄存器数量是不同和不规律的。寄存器主要用于缓存本地机器指令、数值和下一条需要被执行的指令地址等数据。</p>
<p>基于栈式架构的虚拟机所使用的零地址指令更加紧凑，但完成一项操作的时候必然需要使用更多的入栈和出栈指令，这同时也就意味着将需要更多的指令分派（instruction<br>dispatch）次数和内存读&#x2F;写次数。由于操作数是存储在内存中的，因此频繁的执行内存读&#x2F;写操作必然会影响执行速度。为了解决这个问题，HotSpot JVM<br>设计者们提出了栈顶缓存技术， <strong>将栈顶元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读&#x2F;写次数，提升执行引擎的执行效率</strong></p>
<h4 id="动态链接（指向运行时常量池的方法引用）"><a href="#动态链接（指向运行时常量池的方法引用）" class="headerlink" title="动态链接（指向运行时常量池的方法引用）"></a>动态链接（指向运行时常量池的方法引用）</h4><ul>
<li><strong>每一个栈帧内部都包含一个指向运行时常量池中该栈帧所属方法的引用</strong> 。包含这个引用的目的就是为了支持当前方法的代码能够实现动态链接(Dynamic Linking)。</li>
<li>在 Java 源文件被编译到字节码文件中时，所有的变量和方法引用都作为 <strong>符号引用</strong> （Symbolic Reference）保存在 Class 文件的常量池中。比如：描述一个方法调用了另外的其他方法时，就是通过常量池中指向方法的符号引用来表示的，那么 <strong>动态链接的作用就是为了将这些符号引用转换为调用方法的直接引用</strong></li>
</ul>
<p><img src="/images/%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5%E4%BD%9C%E7%94%A8.jpg" alt="动态链接作用"></p>
<h5 id="JVM-是如何执行方法调用的"><a href="#JVM-是如何执行方法调用的" class="headerlink" title="JVM 是如何执行方法调用的"></a>JVM 是如何执行方法调用的</h5><p>方法调用不同于方法执行，方法调用阶段的唯一任务就是确定被调用方法的版本（即调用哪一个方法），暂时还不涉及方法内部的具体运行过程。Class<br>文件的编译过程中不包括传统编译器中的连接步骤，一切方法调用在 Class文件里面存储的都是 <strong>符号引用</strong> ，而不是方法在实际运行时内存布局中的入口地址（<br><strong>直接引用</strong> ）。也就是需要在类加载阶段，甚至到运行期才能确定目标方法的直接引用。</p>
<blockquote>
<p>【这一块内容，除了方法调用，还包括解析、分派（静态分派、动态分派、单分派与多分派），这里先不介绍，后续再挖】</p>
</blockquote>
<p>在 JVM 中，将符号引用转换为调用方法的直接引用与方法的绑定机制有关</p>
<ul>
<li><strong>静态链接</strong> ：当一个字节码文件被装载进 JVM 内部时，如果被调用的 <strong>目标方法在编译期可知</strong> ，且运行期保持不变时。这种情况下将调用方法的符号引用转换为直接引用的过程称之为静态链接</li>
<li><strong>动态链接</strong> ：如果被调用的方法在编译期无法被确定下来，也就是说，只能在程序运行期将调用方法的符号引用转换为直接引用，由于这种引用转换过程具备动态性，因此也就被称之为动态链接</li>
</ul>
<p>对应的方法的绑定机制为：早期绑定（Early Binding）和晚期绑定（Late Binding）。<br><strong>绑定是一个字段、方法或者类在符号引用被替换为直接引用的过程，这仅仅发生一次</strong> 。</p>
<ul>
<li>早期绑定： <strong>早期绑定就是指被调用的目标方法如果在编译期可知，且运行期保持不变时</strong> ，即可将这个方法与所属的类型进行绑定，这样一来，由于明确了被调用的目标方法究竟是哪一个，因此也就可以使用静态链接的方式将符号引用转换为直接引用。</li>
<li>晚期绑定：如果被调用的方法在编译器无法被确定下来，只能够在程序运行期根据实际的类型绑定相关的方法，这种绑定方式就被称为晚期绑定。</li>
</ul>
<h5 id="虚方法和非虚方法"><a href="#虚方法和非虚方法" class="headerlink" title="虚方法和非虚方法"></a>虚方法和非虚方法</h5><ul>
<li>如果方法在编译器就确定了具体的调用版本，这个版本在运行时是不可变的。这样的方法称为非虚方法，比如静态方法、私有方法、final 方法、实例构造器、父类方法都是非虚方法</li>
<li>其他方法称为虚方法</li>
</ul>
<h5 id="虚方法表"><a href="#虚方法表" class="headerlink" title="虚方法表"></a>虚方法表</h5><p>在面向对象编程中，会频繁的使用到动态分派，如果每次动态分派都要重新在类的方法元数据中搜索合适的目标有可能会影响到执行效率。为了提高性能，JVM<br>采用在类的方法区建立一个虚方法表（virtual method table），使用索引表来代替查找。非虚方法不会出现在表中。</p>
<p>每个类中都有一个虚方法表，表中存放着各个方法的实际入口。</p>
<p>虚方法表会在类加载的连接阶段被创建并开始初始化，类的变量初始值准备完成之后，JVM 会把该类的方法表也初始化完毕。</p>
<h4 id="方法返回地址（return-address）"><a href="#方法返回地址（return-address）" class="headerlink" title="方法返回地址（return address）"></a>方法返回地址（return address）</h4><p>用来存放调用该方法的 PC 寄存器的值。</p>
<p>一个方法的结束，有两种方式</p>
<ul>
<li>正常执行完成</li>
<li>出现未处理的异常，非正常退出</li>
</ul>
<p>无论通过哪种方式退出，在方法退出后都返回到该方法被调用的位置。方法正常退出时，调用者的 PC<br>计数器的值作为返回地址，即调用该方法的指令的下一条指令的地址。而通过异常退出的，返回地址是要通过异常表来确定的，栈帧中一般不会保存这部分信息。</p>
<p>当一个方法开始执行后，只有两种方式可以退出这个方法：</p>
<ol>
<li>执行引擎遇到任意一个方法返回的字节码指令，会有返回值传递给上层的方法调用者，简称 <strong>正常完成出口</strong></li>
</ol>
<p>一个方法的正常调用完成之后究竟需要使用哪一个返回指令还需要根据方法返回值的实际数据类型而定</p>
<p>在字节码指令中，返回指令包含 ireturn(当返回值是 boolean、byte、char、short 和 int<br>类型时使用)、lreturn、freturn、dreturn 以及 areturn，另外还有一个 return 指令供声明为 void<br>的方法、实例初始化方法、类和接口的初始化方法使用。</p>
<ol start="2">
<li>在方法执行的过程中遇到了异常，并且这个异常没有在方法内进行处理，也就是只要在本方法的异常表中没有搜索到匹配的异常处理器，就会导致方法退出。简称 <strong>异常完成出口</strong></li>
</ol>
<p>方法执行过程中抛出异常时的异常处理，存储在一个异常处理表，方便在发生异常的时候找到处理异常的代码。</p>
<p>本质上， <strong>方法的退出就是当前栈帧出栈的过程</strong><br>。此时，需要恢复上层方法的局部变量表、操作数栈、将返回值压入调用者栈帧的操作数栈、设置PC寄存器值等，让调用者方法继续执行下去。</p>
<p>正常完成出口和异常完成出口的区别在于： <strong>通过异常完成出口退出的不会给他的上层调用者产生任何的返回值</strong></p>
<h4 id="附加信息"><a href="#附加信息" class="headerlink" title="附加信息"></a>附加信息</h4><p>栈帧中还允许携带与 Java 虚拟机实现相关的一些附加信息。例如，对程序调试提供支持的信息，但这些信息取决于具体的虚拟机实现。</p>
<h2 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h2><h3 id="本地方法接口"><a href="#本地方法接口" class="headerlink" title="本地方法接口"></a>本地方法接口</h3><p>简单的讲，一个 Native Method 就是一个 Java 调用非 Java 代码的接口。我们知道的 Unsafe 类就有很多本地方法。</p>
<blockquote>
<p>为什么要使用本地方法（Native Method）?</p>
</blockquote>
<p>Java 使用起来非常方便，然而有些层次的任务用 Java 实现起来也不容易，或者我们对程序的效率很在意时，问题就来了</p>
<ul>
<li>与 Java 环境外交互：有时 Java 应用需要与 Java 外面的环境交互，这就是本地方法存在的原因。</li>
<li>与操作系统交互：JVM 支持 Java 语言本身和运行时库，但是有时仍需要依赖一些底层系统的支持。通过本地方法，我们可以实现用 Java 与实现了 jre 的底层系统交互， JVM 的一些部分就是 C 语言写的。</li>
<li>Sun’s Java：Sun的解释器就是C实现的，这使得它能像一些普通的C一样与外部交互。jre大部分都是用 Java 实现的，它也通过一些本地方法与外界交互。比如，类 <code>java.lang.Thread</code> 的 <code>setPriority()</code> 的方法是用Java 实现的，但它实现调用的是该类的本地方法 <code>setPrioruty()</code>，该方法是C实现的，并被植入 JVM 内部。</li>
</ul>
<h3 id="本地方法栈（Native-Method-Stack）"><a href="#本地方法栈（Native-Method-Stack）" class="headerlink" title="本地方法栈（Native Method Stack）"></a>本地方法栈（Native Method Stack）</h3><ul>
<li>Java 虚拟机栈用于管理 Java 方法的调用，而本地方法栈用于管理本地方法的调用</li>
<li>本地方法栈也是线程私有的</li>
<li>允许线程固定或者可动态扩展的内存大小<ul>
<li>如果线程请求分配的栈容量超过本地方法栈允许的最大容量，Java 虚拟机将会抛出一个 <code>StackOverflowError</code> 异常</li>
<li>如果本地方法栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的本地方法栈，那么 Java虚拟机将会抛出一个<code>OutofMemoryError</code>异常</li>
</ul>
</li>
<li>本地方法是使用 C 语言实现的</li>
<li>它的具体做法是 <code>Native Method Stack</code> 中登记 native 方法，在 <code>Execution Engine</code> 执行时加载本地方法库当某个线程调用一个本地方法时，它就进入了一个全新的并且不再受虚拟机限制的世界。它和虚拟机拥有同样的权限。</li>
<li>本地方法可以通过本地方法接口来访问虚拟机内部的运行时数据区，它甚至可以直接使用本地处理器中的寄存器，直接从本地内存的堆中分配任意数量的内存</li>
<li>并不是所有 JVM 都支持本地方法。因为 Java 虚拟机规范并没有明确要求本地方法栈的使用语言、具体实现方式、数据结构等。如果 JVM 产品不打算支持 native 方法，也可以无需实现本地方法栈</li>
<li>在 Hotspot JVM 中，直接将本地方法栈和虚拟机栈合二为一</li>
</ul>
<blockquote>
<p><strong>栈是运行时的单位，而堆是存储的单位</strong> 。</p>
<p>栈解决程序的运行问题，即程序如何执行，或者说如何处理数据。堆解决的是数据存储的问题，即数据怎么放、放在哪。</p>
</blockquote>
<h2 id="堆内存"><a href="#堆内存" class="headerlink" title="堆内存"></a>堆内存</h2><h3 id="内存划分"><a href="#内存划分" class="headerlink" title="内存划分"></a>内存划分</h3><p>对于大多数应用，Java 堆是 Java<br>虚拟机管理的内存中最大的一块，被所有线程共享。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数据都在这里分配内存。</p>
<p>为了进行高效的垃圾回收，虚拟机把堆内存 <strong>逻辑上</strong> 划分成三块区域（分代的唯一理由就是优化 GC 性能）：</p>
<ul>
<li>新生带（年轻代）：新对象和没达到一定年龄的对象都在新生代</li>
<li>老年代（养老区）：被长时间使用的对象，老年代的内存空间应该要比年轻代更大</li>
<li>元空间（JDK1.8 之前叫永久代）：像一些方法中的操作临时对象等，JDK1.8 之前是占用 JVM 内存，JDK1.8 之后直接使用物理内存</li>
</ul>
<p><img src="/images/JVM%E5%A0%86%E5%86%85%E5%AD%98%E5%88%92%E5%88%86.jpg" alt="JVM堆内存划分"></p>
<p>Java 虚拟机规范规定，Java<br>堆可以是处于物理上不连续的内存空间中，只要逻辑上是连续的即可，像磁盘空间一样。实现时，既可以是固定大小，也可以是可扩展的，主流虚拟机都是可扩展的（通过<br><code>-Xmx</code> 和 <code>-Xms</code> 控制），如果堆中没有完成实例分配，并且堆无法再扩展时，就会抛出 <code>OutOfMemoryError</code> 异常。</p>
<h4 id="年轻代-Young-Generation"><a href="#年轻代-Young-Generation" class="headerlink" title="年轻代 (Young Generation)"></a>年轻代 (Young Generation)</h4><p>年轻代是所有新对象创建的地方。当填充年轻代时，执行垃圾收集。这种垃圾收集称为 <strong>Minor GC</strong> 。年轻一代被分为三个部分——伊甸园（ <strong>Eden<br>Memory</strong> ）和两个幸存区（ <strong>Survivor Memory</strong> ，被称为from&#x2F;to或s0&#x2F;s1），默认比例是<code>8:1:1</code></p>
<ul>
<li>大多数新创建的对象都位于 Eden 内存空间中</li>
<li>当 Eden 空间被对象填充时，执行 <strong>Minor GC</strong> ，并将所有幸存者对象移动到一个幸存者空间中</li>
<li>Minor GC 检查幸存者对象，并将它们移动到另一个幸存者空间。所以每次，一个幸存者空间总是空的</li>
<li>经过多次 GC 循环后存活下来的对象被移动到老年代。通常，这是通过设置年轻一代对象的年龄阈值来实现的，然后他们才有资格提升到老一代</li>
</ul>
<h4 id="老年代-Old-Generation"><a href="#老年代-Old-Generation" class="headerlink" title="老年代(Old Generation)"></a>老年代(Old Generation)</h4><p>旧的一代内存包含那些经过许多轮小型 GC 后仍然存活的对象。通常，垃圾收集是在老年代内存满时执行的。老年代垃圾收集称为 主GC（Major<br>GC），通常需要更长的时间。</p>
<p>大对象直接进入老年代（大对象是指需要大量连续内存空间的对象）。这样做的目的是避免在 Eden 区和两个Survivor 区之间发生大量的内存拷贝</p>
<p><img src="/images/Java8%E5%89%8D%E5%90%8E%E5%A0%86%E5%86%85%E5%AD%98%E5%AF%B9%E6%AF%94.jpg" alt="Java8前后堆内存对比"></p>
<h4 id="元空间"><a href="#元空间" class="headerlink" title="元空间"></a>元空间</h4><p>不管是 JDK8 之前的永久代，还是 JDK8 及以后的元空间，都可以看作是 Java 虚拟机规范中方法区的实现。</p>
<p>虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫 Non-Heap（非堆），目的应该是与 Java 堆区分开。</p>
<p>所以元空间放在后边的方法区再说。</p>
<h3 id="设置堆内存大小和-OOM"><a href="#设置堆内存大小和-OOM" class="headerlink" title="设置堆内存大小和 OOM"></a>设置堆内存大小和 OOM</h3><p>Java 堆用于存储 Java 对象实例，那么堆的大小在 JVM 启动的时候就确定了，我们可以通过 <code>-Xmx</code> 和 <code>-Xms</code> 来设定</p>
<ul>
<li><code>-Xms</code> 用来表示堆的起始内存，等价于 <code>-XX:InitialHeapSize</code></li>
<li><code>-Xmx</code> 用来表示堆的最大内存，等价于 <code>-XX:MaxHeapSize</code></li>
</ul>
<p>如果堆的内存大小超过 <code>-Xmx</code> 设定的最大内存， 就会抛出 <code>OutOfMemoryError</code> 异常。</p>
<p>我们通常会将 <code>-Xmx</code> 和 <code>-Xms</code> 两个参数配置为相同的值，其目的是为了能够在垃圾回收机制清理完堆区后不再需要重新分隔计算堆的大小，从而提高性能</p>
<ul>
<li>默认情况下，初始堆内存大小为：电脑内存大小&#x2F;64</li>
<li>默认情况下，最大堆内存大小为：电脑内存大小&#x2F;4</li>
</ul>
<p>可以通过代码获取到我们的设置值，当然也可以模拟 OOM：</p>
<pre><code>public static void main(String[] args) &#123;  
  
  //返回 JVM 堆大小  
  long initalMemory = Runtime.getRuntime().totalMemory() / 1024 /1024;  
  //返回 JVM 堆的最大内存  
  long maxMemory = Runtime.getRuntime().maxMemory() / 1024 /1024;  
  
  System.out.println(&quot;-Xms : &quot;+initalMemory + &quot;M&quot;);  
  System.out.println(&quot;-Xmx : &quot;+maxMemory + &quot;M&quot;);  
  
  System.out.println(&quot;系统内存大小：&quot; + initalMemory * 64 / 1024 + &quot;G&quot;);  
  System.out.println(&quot;系统内存大小：&quot; + maxMemory * 4 / 1024 + &quot;G&quot;);  
&#125;  
</code></pre>
<h4 id="查看-JVM-堆内存分配"><a href="#查看-JVM-堆内存分配" class="headerlink" title="查看 JVM 堆内存分配"></a>查看 JVM 堆内存分配</h4><ol>
<li><p>在默认不配置 JVM 堆内存大小的情况下，JVM 根据默认值来配置当前内存大小</p>
</li>
<li><p>默认情况下新生代和老年代的比例是 1:2，可以通过 <code>–XX:NewRatio</code> 来配置</p>
</li>
</ol>
<pre><code>* 新生代中的 **Eden** : **From Survivor** : **To Survivor** 的比例是 **8:1:1** ，可以通过 `-XX:SurvivorRatio` 来配置
</code></pre>
<ol start="3">
<li>若在 JDK 7 中开启了 <code>-XX:+UseAdaptiveSizePolicy</code>，JVM 会动态调整 JVM 堆中各个区域的大小以及进入老年代的年龄</li>
</ol>
<p>此时 <code>–XX:NewRatio</code> 和 <code>-XX:SurvivorRatio</code> 将会失效，而 JDK 8<br>是默认开启<code>-XX:+UseAdaptiveSizePolicy</code></p>
<p>在 JDK 8中， <strong>不要随意关闭</strong><code>-XX:+UseAdaptiveSizePolicy</code>，除非对堆内存的划分有明确的规划</p>
<p>每次 GC 后都会重新计算 Eden、From Survivor、To Survivor 的大小</p>
<p>计算依据是 <strong>GC过程</strong> 中统计的 <strong>GC时间</strong> 、 <strong>吞吐量</strong> 、 <strong>内存占用量</strong></p>
<pre><code>java -XX:+PrintFlagsFinal -version | grep HeapSize  
    uintx ErgoHeapSizeLimit                         = 0                                   &#123;product&#125;  
    uintx HeapSizePerGCThread                       = 87241520                            &#123;product&#125;  
    uintx InitialHeapSize                          := 134217728                           &#123;product&#125;  
    uintx LargePageHeapSizeThreshold                = 134217728                           &#123;product&#125;  
    uintx MaxHeapSize                              := 2147483648                          &#123;product&#125;  
java version &quot;1.8.0_211&quot;  
Java(TM) SE Runtime Environment (build 1.8.0_211-b12)  
Java HotSpot(TM) 64-Bit Server VM (build 25.211-b12, mixed mode)  
$ jmap -heap 进程号  
</code></pre>
<h3 id="对象在堆中的生命周期"><a href="#对象在堆中的生命周期" class="headerlink" title="对象在堆中的生命周期"></a>对象在堆中的生命周期</h3><ol>
<li>在 JVM 内存模型的堆中，堆被划分为新生代和老年代<br>* 新生代又被进一步划分为 <strong>Eden区</strong> 和 <strong>Survivor区</strong> ，Survivor 区由 <strong>From Survivor</strong> 和 <strong>To Survivor</strong> 组成</li>
<li>当创建一个对象时，对象会被优先分配到新生代的 Eden 区<br>* 此时 JVM 会给对象定义一个 <strong>对象年轻计数器</strong> （<code>-XX:MaxTenuringThreshold</code>）</li>
<li>当 Eden 空间不足时，JVM 将执行新生代的垃圾回收（Minor GC）<br>* JVM 会把存活的对象转移到 Survivor 中，并且对象年龄 +1<br>* 对象在 Survivor 中同样也会经历 Minor GC，每经历一次 Minor GC，对象年龄都会+1</li>
<li>如果分配的对象超过了<code>-XX:PetenureSizeThreshold</code>，对象会 <strong>直接被分配到老年代</strong></li>
</ol>
<h3 id="对象的分配过程"><a href="#对象的分配过程" class="headerlink" title="对象的分配过程"></a>对象的分配过程</h3><p>为对象分配内存是一件非常严谨和复杂的任务，JVM<br>的设计者们不仅需要考虑内存如何分配、在哪里分配等问题，并且由于内存分配算法和内存回收算法密切相关，所以还需要考虑 GC<br>执行完内存回收后是否会在内存空间中产生内存碎片。</p>
<ol>
<li>new 的对象先放在伊甸园区，此区有大小限制</li>
<li>当伊甸园的空间填满时，程序又需要创建对象，JVM 的垃圾回收器将对伊甸园区进行垃圾回收（Minor GC），将伊甸园区中的不再被其他对象所引用的对象进行销毁。再加载新的对象放到伊甸园区</li>
<li>然后将伊甸园中的剩余对象移动到幸存者 0 区</li>
<li>如果再次触发垃圾回收，此时上次幸存下来的放到幸存者 0 区，如果没有回收，就会放到幸存者 1 区</li>
<li>如果再次经历垃圾回收，此时会重新放回幸存者 0 区，接着再去幸存者 1 区</li>
<li>什么时候才会去养老区呢？ 默认是 15 次回收标记</li>
<li>在养老区，相对悠闲。当养老区内存不足时，再次触发 Major GC，进行养老区的内存清理</li>
<li>若养老区执行了 Major GC 之后发现依然无法进行对象的保存，就会产生 OOM 异常</li>
</ol>
<h3 id="GC-垃圾回收简介"><a href="#GC-垃圾回收简介" class="headerlink" title="GC 垃圾回收简介"></a>GC 垃圾回收简介</h3><h4 id="Minor-GC、Major-GC、Full-GC"><a href="#Minor-GC、Major-GC、Full-GC" class="headerlink" title="Minor GC、Major GC、Full GC"></a>Minor GC、Major GC、Full GC</h4><p>JVM 在进行 GC 时，并非每次都对堆内存（新生代、老年代；方法区）区域一起回收的，大部分时候回收的都是指新生代。</p>
<p>针对 HotSpot VM 的实现，它里面的 GC 按照回收区域又分为两大类：部分收集（Partial GC），整堆收集（Full GC）</p>
<ul>
<li>部分收集：不是完整收集整个 Java 堆的垃圾收集。其中又分为： <ul>
<li>新生代收集（Minor GC&#x2F;Young GC）：只是新生代的垃圾收集</li>
<li>老年代收集（Major GC&#x2F;Old GC）：只是老年代的垃圾收集 <ul>
<li>目前，只有 CMS GC 会有单独收集老年代的行为</li>
<li>很多时候 Major GC 会和 Full GC 混合使用，需要具体分辨是老年代回收还是整堆回收</li>
</ul>
</li>
<li>混合收集（Mixed GC）：收集整个新生代以及部分老年代的垃圾收集 <ul>
<li>目前只有 G1 GC 会有这种行为</li>
</ul>
</li>
</ul>
</li>
<li>整堆收集（Full GC）：收集整个 Java 堆和方法区的垃圾</li>
</ul>
<h3 id="TLAB"><a href="#TLAB" class="headerlink" title="TLAB"></a>TLAB</h3><h4 id="什么是-TLAB-（Thread-Local-Allocation-Buffer）"><a href="#什么是-TLAB-（Thread-Local-Allocation-Buffer）" class="headerlink" title="什么是 TLAB （Thread Local Allocation Buffer）?"></a>什么是 TLAB （Thread Local Allocation Buffer）?</h4><ul>
<li>从内存模型而不是垃圾回收的角度，对 Eden 区域继续进行划分，JVM 为每个线程分配了一个私有缓存区域，它包含在 Eden 空间内</li>
<li>多线程同时分配内存时，使用 TLAB 可以避免一系列的非线程安全问题，同时还能提升内存分配的吞吐量，因此我们可以将这种内存分配方式称为 <strong>快速分配策略</strong></li>
<li>OpenJDK 衍生出来的 JVM 大都提供了 TLAB 设计</li>
</ul>
<h4 id="为什么要有-TLAB"><a href="#为什么要有-TLAB" class="headerlink" title="为什么要有 TLAB ?"></a>为什么要有 TLAB ?</h4><ul>
<li>堆区是线程共享的，任何线程都可以访问到堆区中的共享数据</li>
<li>由于对象实例的创建在 JVM 中非常频繁，因此在并发环境下从堆区中划分内存空间是线程不安全的</li>
<li>为避免多个线程操作同一地址，需要使用加锁等机制，进而影响分配速度</li>
</ul>
<p>尽管不是所有的对象实例都能够在 TLAB 中成功分配内存，但 JVM 确实是将 TLAB 作为内存分配的首选。</p>
<p>在程序中，可以通过 <code>-XX:UseTLAB</code> 设置是否开启 TLAB 空间。</p>
<p>默认情况下，TLAB 空间的内存非常小，仅占有整个 Eden 空间的 1%，我们可以通过 <code>-XX:TLABWasteTargetPercent</code> 设置<br>TLAB 空间所占用 Eden 空间的百分比大小。</p>
<p>一旦对象在 TLAB 空间分配内存失败时，JVM 就会尝试着通过使用加锁机制确保数据操作的原子性，从而直接在 Eden 空间中分配内存。</p>
<h3 id="堆是分配对象存储的唯一选择吗"><a href="#堆是分配对象存储的唯一选择吗" class="headerlink" title="堆是分配对象存储的唯一选择吗"></a>堆是分配对象存储的唯一选择吗</h3><blockquote>
<p>随着 JIT 编译期的发展和逃逸分析技术的逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化，所有的对象都分配到堆上也渐渐变得不那么“绝对”了。<br>——《深入理解 Java 虚拟机》</p>
</blockquote>
<h4 id="逃逸分析"><a href="#逃逸分析" class="headerlink" title="逃逸分析"></a>逃逸分析</h4><p> <em><em>逃逸分析(Escape Analysis)*</em> 是目前 Java 虚拟机中比较前沿的优化技术</em>*。这是一种可以有效减少 Java<br>程序中同步负载和内存堆分配压力的跨函数全局数据流分析算法**。通过逃逸分析，Java Hotspot<br>编译器能够分析出一个新的对象的引用的使用范围从而决定是否要将这个对象分配到堆上。</p>
<p>逃逸分析的基本行为就是分析对象动态作用域：</p>
<ul>
<li>当一个对象在方法中被定义后，对象只在方法内部使用，则认为没有发生逃逸。</li>
<li>当一个对象在方法中被定义后，它被外部方法所引用，则认为发生逃逸。例如作为调用参数传递到其他地方中，称为方法逃逸。</li>
</ul>
<p>例如：</p>
<pre><code>public static StringBuffer craeteStringBuffer(String s1, String s2) &#123;  
   StringBuffer sb = new StringBuffer();  
   sb.append(s1);  
   sb.append(s2);  
   return sb;  
&#125;  
</code></pre>
<p><code>StringBuffer sb</code>是一个方法内部变量，上述代码中直接将sb返回，这样这个 StringBuffer<br>有可能被其他方法所改变，这样它的作用域就不只是在方法内部，虽然它是一个局部变量，但是其逃逸到了方法外部。甚至还有可能被外部线程访问到，譬如赋值给类变量或可以在其他线程中访问的实例变量，称为线程逃逸。</p>
<p>上述代码如果想要 <code>StringBuffer sb</code>不逃出方法，可以这样写：</p>
<pre><code>public static String createStringBuffer(String s1, String s2) &#123;  
   StringBuffer sb = new StringBuffer();  
   sb.append(s1);  
   sb.append(s2);  
   return sb.toString();  
&#125;  
</code></pre>
<p>不直接返回 StringBuffer，那么 StringBuffer 将不会逃逸出方法。</p>
<p><strong>参数设置：</strong></p>
<ul>
<li>在 JDK 6u23 版本之后，HotSpot 中默认就已经开启了逃逸分析</li>
<li>如果使用较早版本，可以通过<code>-XX&quot;+DoEscapeAnalysis</code>显式开启</li>
</ul>
<p>开发中使用局部变量，就不要在方法外定义。</p>
<p>使用逃逸分析，编译器可以对代码做优化：</p>
<ul>
<li><strong>栈上分配</strong> ：将堆分配转化为栈分配。如果一个对象在子程序中被分配，要使指向该对象的指针永远不会逃逸，对象可能是栈分配的候选，而不是堆分配</li>
<li><strong>同步省略</strong> ：如果一个对象被发现只能从一个线程被访问到，那么对于这个对象的操作可以不考虑同步</li>
<li><strong>分离对象或标量替换</strong> ：有的对象可能不需要作为一个连续的内存结构存在也可以被访问到，那么对象的部分（或全部）可以不存储在内存，而存储在 CPU 寄存器</li>
</ul>
<p>JIT<br>编译器在编译期间根据逃逸分析的结果，发现如果一个对象并没有逃逸出方法的话，就可能被优化成栈上分配。分配完成后，继续在调用栈内执行，最后线程结束，栈空间被回收，局部变量对象也被回收。这样就无需进行垃圾回收了。</p>
<p>常见栈上分配的场景：成员变量赋值、方法返回值、实例引用传递</p>
<h5 id="代码优化之同步省略（消除）"><a href="#代码优化之同步省略（消除）" class="headerlink" title="代码优化之同步省略（消除）"></a>代码优化之同步省略（消除）</h5><ul>
<li><p>线程同步的代价是相当高的，同步的后果是降低并发性和性能</p>
</li>
<li><p>在动态编译同步块的时候，JIT 编译器可以借助逃逸分析来判断同步块所使用的锁对象是否能够被一个线程访问而没有被发布到其他线程。如果没有，那么 JIT 编译器在编译这个同步块的时候就会取消对这个代码的同步。这样就能大大提高并发性和性能。这个取消同步的过程就叫做 <strong>同步省略，也叫锁消除</strong> 。</p>
<p>public void keep() {<br>  Object keeper &#x3D; new Object();<br>  synchronized(keeper) {<br>System.out.println(keeper);<br>  }<br>}</p>
</li>
</ul>
<p>如上代码，代码中对 keeper 这个对象进行加锁，但是 keeper 对象的生命周期只在 <code>keep()</code>方法中，并不会被其他线程所访问到，所以在<br>JIT编译阶段就会被优化掉。优化成：</p>
<pre><code>public void keep() &#123;  
  Object keeper = new Object();  
  System.out.println(keeper);  
&#125;  
  
</code></pre>
<h5 id="代码优化之标量替换"><a href="#代码优化之标量替换" class="headerlink" title="代码优化之标量替换"></a>代码优化之标量替换</h5><p> <strong>标量</strong> （Scalar）是指一个无法再分解成更小的数据的数据。Java 中的原始数据类型就是标量。</p>
<p>相对的，那些的还可以分解的数据叫做 <strong>聚合量</strong> （Aggregate），Java 中的对象就是聚合量，因为其还可以分解成其他聚合量和标量。</p>
<p>在 JIT 阶段，通过逃逸分析确定该对象不会被外部访问，并且对象可以被进一步分解时，JVM<br>不会创建该对象，而会将该对象成员变量分解若干个被这个方法使用的成员变量所代替。这些代替的成员变量在栈帧或寄存器上分配空间。这个过程就是 <strong>标量替换</strong> 。</p>
<p>通过 <code>-XX:+EliminateAllocations</code> 可以开启标量替换，<code>-XX:+PrintEliminateAllocations</code><br>查看标量替换情况。</p>
<pre><code>public static void main(String[] args) &#123;  
   alloc();  
&#125;  
  
private static void alloc() &#123;  
   Point point = new Point（1,2）;  
   System.out.println(&quot;point.x=&quot;+point.x+&quot;; point.y=&quot;+point.y);  
&#125;  
class Point&#123;  
    private int x;  
    private int y;  
&#125;  
</code></pre>
<p>以上代码中，point 对象并没有逃逸出 <code>alloc()</code> 方法，并且 point 对象是可以拆解成标量的。那么，JIT 就不会直接创建 Point<br>对象，而是直接使用两个标量 int x ，int y 来替代 Point 对象。</p>
<pre><code>private static void alloc() &#123;  
   int x = 1;  
   int y = 2;  
   System.out.println(&quot;point.x=&quot;+x+&quot;; point.y=&quot;+y);  
&#125;  
  
</code></pre>
<h5 id="代码优化之栈上分配"><a href="#代码优化之栈上分配" class="headerlink" title="代码优化之栈上分配"></a>代码优化之栈上分配</h5><p>我们通过 JVM 内存分配可以知道 JAVA 中的对象都是在堆上进行分配，当对象没有被引用的时候，需要依靠 GC 进行回收内存，如果对象数量较多的时候，会给<br>GC 带来较大压力，也间接影响了应用的性能。为了减少临时对象在堆内分配的数量，JVM<br>通过逃逸分析确定该对象不会被外部访问。那就通过标量替换将该对象分解在栈上分配内存，这样该对象所占用的内存空间就可以随栈帧出栈而销毁，就减轻了垃圾回收的压力。</p>
<p><strong>总结：</strong></p>
<p>关于逃逸分析的论文在1999年就已经发表了，但直到JDK 1.6才有实现，而且这项技术到如今也并不是十分成熟的。</p>
<p><strong>其根本原因就是无法保证逃逸分析的性能消耗一定能高于他的消耗。虽然经过逃逸分析可以做标量替换、栈上分配、和锁消除。但是逃逸分析自身也是需要进行一系列复杂的分析的，这其实也是一个相对耗时的过程。</strong></p>
<p>一个极端的例子，就是经过逃逸分析之后，发现没有一个对象是不逃逸的。那这个逃逸分析的过程就白白浪费掉了。</p>
<p>虽然这项技术并不十分成熟，但是他也是即时编译器优化技术中一个十分重要的手段。</p>
<h2 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h2><ul>
<li>方法区（Method Area）与 Java 堆一样，是所有线程共享的内存区域。</li>
<li>虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫 Non-Heap（非堆），目的应该是与 Java 堆区分开。</li>
<li>运行时常量池（Runtime Constant Pool）是方法区的一部分。Class 文件中除了有类的版本&#x2F;字段&#x2F;方法&#x2F;接口等描述信息外，还有一项信息是常量池（Constant Pool Table），用于存放编译期生成的各种字面量和符号引用，这部分内容将类在加载后进入方法区的运行时常量池中存放。运行期间也可能将新的常量放入池中，这种特性被开发人员利用得比较多的是 <code>String.intern()</code>方法。受方法区内存的限制，当常量池无法再申请到内存时会抛出 <code>OutOfMemoryErro</code>r 异常。</li>
<li>方法区的大小和堆空间一样，可以选择固定大小也可选择可扩展，方法区的大小决定了系统可以放多少个类，如果系统类太多，导致方法区溢出，虚拟机同样会抛出内存溢出错误</li>
<li>JVM 关闭后方法区即被释放</li>
</ul>
<h3 id="解惑"><a href="#解惑" class="headerlink" title="解惑"></a>解惑</h3><p>你是否也有看不同的参考资料，有的内存结构图有方法区，有的又是永久代，元数据区，一脸懵逼的时候？</p>
<ul>
<li><strong>方法区（method area）只是 JVM 规范中定义的一个概念</strong> ，用于存储类信息、常量池、静态变量、JIT编译后的代码等数据，并没有规定如何去实现它，不同的厂商有不同的实现。而 <strong>永久代（PermGen）是 Hotspot 虚拟机特有的概念， Java8 的时候又被元空间</strong> 取代了，永久代和元空间都可以理解为方法区的落地实现。</li>
<li>永久代物理是堆的一部分，和新生代，老年代地址是连续的（受垃圾回收器管理），而元空间存在于本地内存（我们常说的堆外内存，不受垃圾回收器管理），这样就不受 JVM 限制了，也比较难发生OOM（都会有溢出异常）</li>
<li>Java7 中我们通过<code>-XX:PermSize</code> 和 <code>-xx:MaxPermSize</code> 来设置永久代参数，Java8 之后，随着永久代的取消，这些参数也就随之失效了，改为通过<code>-XX:MetaspaceSize</code> 和 <code>-XX:MaxMetaspaceSize</code> 用来设置元空间参数</li>
<li>存储内容不同，元空间存储类的元信息，静态变量和常量池等并入堆中。相当于永久代的数据被分到了堆和元空间中</li>
<li>如果方法区域中的内存不能用于满足分配请求，则 Java 虚拟机抛出 <code>OutOfMemoryError</code></li>
<li>JVM 规范说方法区在逻辑上是堆的一部分，但目前实际上是与 Java 堆分开的（Non-Heap）</li>
</ul>
<p>所以对于方法区，Java8 之后的变化：</p>
<ul>
<li>移除了永久代（PermGen），替换为元空间（Metaspace）；</li>
<li>永久代中的 class metadata 转移到了 native memory（本地内存，而不是虚拟机）；</li>
<li>永久代中的 interned Strings 和 class static variables 转移到了 Java heap；</li>
<li>永久代参数 （PermSize MaxPermSize） -&gt; 元空间参数（MetaspaceSize MaxMetaspaceSize）</li>
</ul>
<h3 id="设置方法区内存的大小"><a href="#设置方法区内存的大小" class="headerlink" title="设置方法区内存的大小"></a>设置方法区内存的大小</h3><p>JDK8 及以后：</p>
<ul>
<li>元数据区大小可以使用参数 <code>-XX:MetaspaceSize</code> 和 <code>-XX:MaxMetaspaceSize</code> 指定，替代上述原有的两个参数</li>
<li>默认值依赖于平台。Windows 下，<code>-XX:MetaspaceSize</code> 是 21M，<code>-XX:MaxMetaspacaSize</code> 的值是 -1，即没有限制</li>
<li>与永久代不同，如果不指定大小，默认情况下，虚拟机会耗尽所有的可用系统内存。如果元数据发生溢出，虚拟机一样会抛出异常 <code>OutOfMemoryError:Metaspace</code></li>
<li><code>-XX:MetaspaceSize</code> ：设置初始的元空间大小。对于一个 64 位的服务器端 JVM 来说，其默认的 <code>-XX:MetaspaceSize</code> 的值为20.75MB，这就是初始的高水位线，一旦触及这个水位线，Full GC 将会被触发并卸载没用的类（即这些类对应的类加载器不再存活），然后这个高水位线将会重置，新的高水位线的值取决于 GC 后释放了多少元空间。如果释放的空间不足，那么在不超过 <code>MaxMetaspaceSize</code>时，适当提高该值。如果释放空间过多，则适当降低该值</li>
<li>如果初始化的高水位线设置过低，上述高水位线调整情况会发生很多次，通过垃圾回收的日志可观察到 Full GC 多次调用。为了避免频繁 GC，建议将 <code>-XX:MetaspaceSize</code> 设置为一个相对较高的值。</li>
</ul>
<h3 id="方法区内部结构"><a href="#方法区内部结构" class="headerlink" title="方法区内部结构"></a>方法区内部结构</h3><p>方法区用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等。</p>
<h4 id="类型信息"><a href="#类型信息" class="headerlink" title="类型信息"></a>类型信息</h4><p>对每个加载的类型（类 class、接口 interface、枚举 enum、注解 annotation），JVM 必须在方法区中存储以下类型信息</p>
<ul>
<li>这个类型的完整有效名称（全名&#x3D;包名.类名）</li>
<li>这个类型直接父类的完整有效名（对于 interface或是 java.lang.Object，都没有父类）</li>
<li>这个类型的修饰符（public，abstract，final 的某个子集）</li>
<li>这个类型直接接口的一个有序列表</li>
</ul>
<h4 id="域（Field）信息"><a href="#域（Field）信息" class="headerlink" title="域（Field）信息"></a>域（Field）信息</h4><ul>
<li>JVM 必须在方法区中保存类型的所有域的相关信息以及域的声明顺序</li>
<li>域的相关信息包括：域名称、域类型、域修饰符（public、private、protected、static、final、volatile、transient 的某个子集）</li>
</ul>
<h4 id="方法（Method）信息"><a href="#方法（Method）信息" class="headerlink" title="方法（Method）信息"></a>方法（Method）信息</h4><p>JVM 必须保存所有方法的</p>
<ul>
<li>方法名称</li>
<li>方法的返回类型</li>
<li>方法参数的数量和类型</li>
<li>方法的修饰符（public，private，protected，static，final，synchronized，native，abstract 的一个子集）</li>
<li>方法的字符码（bytecodes）、操作数栈、局部变量表及大小（abstract 和 native 方法除外）</li>
<li>异常表（abstract 和 native 方法除外） <ul>
<li>每个异常处理的开始位置、结束位置、代码处理在程序计数器中的偏移地址、被捕获的异常类的常量池索引</li>
</ul>
</li>
</ul>
<h3 id="运行时常量池"><a href="#运行时常量池" class="headerlink" title="运行时常量池"></a>运行时常量池</h3><p>运行时常量池（Runtime Constant Pool）是方法区的一部分，理解运行时常量池的话，我们先来说说字节码文件（Class<br>文件）中的常量池（常量池表）</p>
<h4 id="常量池"><a href="#常量池" class="headerlink" title="常量池"></a>常量池</h4><p>一个有效的字节码文件中除了包含类的版本信息、字段、方法以及接口等描述信息外，还包含一项信息那就是常量池表（Constant Pool<br>Table），包含各种字面量和对类型、域和方法的符号引用。</p>
<h5 id="为什么需要常量池？"><a href="#为什么需要常量池？" class="headerlink" title="为什么需要常量池？"></a>为什么需要常量池？</h5><p>一个 Java 源文件中的类、接口，编译后产生一个字节码文件。而 Java<br>中的字节码需要数据支持，通常这种数据会很大以至于不能直接存到字节码里，换另一种方式，可以存到常量池，这个字节码包含了指向常量池的引用。在动态链接的时候用到的就是运行时常量池。</p>
<p>如下，我们通过 jclasslib 查看一个只有 Main 方法的简单类，字节码中的 #2 指向的就是 Constant Pool</p>
<p>![ Constant Pool](&#x2F;images&#x2F; Constant Pool.jpg)</p>
<p>常量池可以看作是一张表，虚拟机指令根据这张常量表找到要执行的类名、方法名、参数类型、字面量等类型。</p>
<h4 id="运行时常量池-1"><a href="#运行时常量池-1" class="headerlink" title="运行时常量池"></a>运行时常量池</h4><ul>
<li>在加载类和结构到虚拟机后，就会创建对应的运行时常量池</li>
<li>常量池表（Constant Pool Table）是 Class 文件的一部分，用于存储编译期生成的各种字面量和符号引用， <strong>这部分内容将在类加载后存放到方法区的运行时常量池中</strong></li>
<li>JVM 为每个已加载的类型（类或接口）都维护一个常量池。池中的数据项像数组项一样，是通过索引访问的</li>
<li>运行时常量池中包含各种不同的常量，包括编译器就已经明确的数值字面量，也包括到运行期解析后才能够获得的方法或字段引用。此时不再是常量池中的符号地址了，这里换为真实地址 <ul>
<li>运行时常量池，相对于 Class 文件常量池的另一个重要特征是： <strong>动态性</strong> ，Java 语言并不要求常量一定只有编译期间才能产生，运行期间也可以将新的常量放入池中，String 类的 <code>intern()</code> 方法就是这样的</li>
</ul>
</li>
<li>当创建类或接口的运行时常量池时，如果构造运行时常量池所需的内存空间超过了方法区所能提供的最大值，则 JVM 会抛出 OutOfMemoryError 异常。</li>
</ul>
<h3 id="方法区在-JDK6、7、8中的演进细节"><a href="#方法区在-JDK6、7、8中的演进细节" class="headerlink" title="方法区在 JDK6、7、8中的演进细节"></a>方法区在 JDK6、7、8中的演进细节</h3><p>只有 HotSpot 才有永久代的概念</p>
<table>
<thead>
<tr>
<th>jdk1.6及之前</th>
<th>有永久代，静态变量存放在永久代上</th>
</tr>
</thead>
<tbody><tr>
<td>jdk1.7</td>
<td>有永久代，但已经逐步“去永久代”，字符串常量池、静态变量移除，保存在堆中</td>
</tr>
<tr>
<td>jdk1.8及之后</td>
<td>取消永久代，类型信息、字段、方法、常量保存在本地内存的元空间，但字符串常量池、静态变量仍在堆中</td>
</tr>
</tbody></table>
<ul>
<li>HotSpot中字符串常量池保存哪里？永久代？方法区还是堆区**？</li>
</ul>
<ol>
<li>运行时常量池（Runtime Constant Pool）是虚拟机规范中是方法区的一部分，在加载类和结构到虚拟机后，就会创建对应的运行时常量池；而字符串常量池是这个过程中常量字符串的存放位置。所以从这个角度，字符串常量池属于虚拟机规范中的方法区，它是一个 <strong>逻辑上的概念</strong> ；而堆区，永久代以及元空间是实际的存放位置。</li>
<li>不同的虚拟机对虚拟机的规范（比如方法区）是不一样的，只有 HotSpot 才有永久代的概念。</li>
<li>HotSpot也是发展的，由于<a target="_blank" rel="noopener" href="http://openjdk.java.net/jeps/122">一些问题</a>的存在，HotSpot考虑逐渐去永久代，对于不同版本的JDK， <strong>实际的存储位置</strong> 是有差异的，具体看如下表格：</li>
</ol>
<table>
<thead>
<tr>
<th>JDK版本</th>
<th>是否有永久代，字符串常量池放在哪里？</th>
<th>方法区逻辑上规范，由哪些实际的部分实现的？</th>
</tr>
</thead>
<tbody><tr>
<td>jdk1.6及之前</td>
<td>有永久代，运行时常量池（包括字符串常量池），静态变量存放在永久代上</td>
<td>这个时期方法区在HotSpot中是由永久代来实现的，以至于</td>
</tr>
<tr>
<td><strong>这个时期说方法区就是指永久代</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>jdk1.7</td>
<td>有永久代，但已经逐步“去永久代”，字符串常量池、静态变量移除，保存在堆中；</td>
<td>这个时期方法区在HotSpot中由 <strong>永久代</strong></td>
</tr>
<tr>
<td>（类型信息、字段、方法、常量）和 <strong>堆</strong> （字符串常量池、静态变量）共同实现</td>
<td></td>
<td></td>
</tr>
<tr>
<td>jdk1.8及之后</td>
<td>取消永久代，类型信息、字段、方法、常量保存在本地内存的元空间，但字符串常量池、静态变量仍在堆中</td>
<td></td>
</tr>
<tr>
<td>这个时期方法区在HotSpot中由本地内存的 <strong>元空间</strong> （类型信息、字段、方法、常量）和 <strong>堆</strong> （字符串常量池、静态变量）共同实现</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h4 id="移除永久代原因"><a href="#移除永久代原因" class="headerlink" title="移除永久代原因"></a>移除永久代原因</h4><p><a target="_blank" rel="noopener" href="http://openjdk.java.net/jeps/122">http://openjdk.java.net/jeps/122</a></p>
<ul>
<li>为永久代设置空间大小是很难确定的。</li>
</ul>
<p>在某些场景下，如果动态加载类过多，容易产生 Perm 区的 OOM。如果某个实际 Web<br>工程中，因为功能点比较多，在运行过程中，要不断动态加载很多类，经常出现<br>OOM。而元空间和永久代最大的区别在于，元空间不在虚拟机中，而是使用本地内存，所以默认情况下，元空间的大小仅受本地内存限制</p>
<ul>
<li>对永久代进行调优较困难</li>
</ul>
<h3 id="方法区的垃圾回收"><a href="#方法区的垃圾回收" class="headerlink" title="方法区的垃圾回收"></a>方法区的垃圾回收</h3><p>方法区的垃圾收集主要回收两部分内容： <strong>常量池中废弃的常量和不再使用的类型</strong> 。</p>
<p>先来说说方法区内常量池之中主要存放的两大类常量：字面量和符号引用。字面量比较接近 Java 语言层次的常量概念，如文本字符串、被声明为 final<br>的常量值等。而符号引用则属于编译原理方面的概念，包括下面三类常量：</p>
<ul>
<li>类和接口的全限定名</li>
<li>字段的名称和描述符</li>
<li>方法的名称和描述符</li>
</ul>
<p>HotSpot 虚拟机对常量池的回收策略是很明确的，只要常量池中的常量没有被任何地方引用，就可以被回收</p>
<p>判定一个类型是否属于“不再被使用的类”，需要同时满足三个条件：</p>
<ul>
<li>该类所有的实例都已经被回收，也就是 Java 堆中不存在该类及其任何派生子类的实例</li>
<li>加载该类的类加载器已经被回收，这个条件除非是经过精心设计的可替换类加载器的场景，如 OSGi、JSP 的重加载等，否则通常很难达成</li>
<li>该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法</li>
</ul>
<p>Java<br>虚拟机被允许堆满足上述三个条件的无用类进行回收，这里说的仅仅是“被允许”，而并不是和对象一样，不使用了就必然会回收。是否对类进行回收，HotSpot<br>虚拟机提供了 <code>-Xnoclassgc</code> 参数进行控制，还可以使用 <code>-verbose:class</code> 以及 <code>-XX:+TraceClassLoading</code><br>、<code>-XX:+TraceClassUnLoading</code> 查看类加载和卸载信息。</p>
<p>在大量使用反射、动态代理、CGLib 等 ByteCode 框架、动态生成 JSP 以及 OSGi 这类频繁自定义 ClassLoader<br>的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/05/17/jvm/Java%E7%BA%BF%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="merric">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Myoboku">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Myoboku">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/05/17/jvm/Java%E7%BA%BF%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/" class="post-title-link" itemprop="url">Jvav线程间通信</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-05-17 22:30:00" itemprop="dateCreated datePublished" datetime="2023-05-17T22:30:00+00:00">2023-05-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h1><h2 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h2><h3 id="保证内存可见性"><a href="#保证内存可见性" class="headerlink" title="保证内存可见性"></a>保证内存可见性</h3><h4 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h4><p>可见性是指线程之间的可见性，一个线程修改的状态对另一个线程是可见的。也就是一个线程修改的结果，另一个线程马上就能看到。</p>
<h4 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h4><p>当对非volatile变量进行读写的时候，每个线程先从主内存拷贝变量到CPU缓存中，如果计算机有多个CPU，每个线程可能在不同的CPU上被处理，这意味着每个线程可以拷贝到不同的CPU<br>cache中。<br>volatile变量不会被缓存在寄存器或者对其他处理器不可见的地方，保证了每次读写变量都从主内存中读，跳过CPU<br>cache这一步。当一个线程修改了这个变量的值，新值对于其他线程是立即得知的。</p>
<p><img src="/images/volatile.png" alt="内存可见性问题"></p>
<h3 id="禁止指令重排序"><a href="#禁止指令重排序" class="headerlink" title="禁止指令重排序"></a>禁止指令重排序</h3><h4 id="基本概念-1"><a href="#基本概念-1" class="headerlink" title="基本概念"></a>基本概念</h4><p>指令重排序是JVM为了优化指令、提高程序运行效率，在不影响单线程程序执行结果的前提下，尽可能地提高并行度。指令重排序包括编译器重排序和运行时重排序。<br>在JDK1.5之后，可以使用volatile变量禁止指令重排序。针对volatile修饰的变量，在读写操作指令前后会插入内存屏障，指令重排序时不能把后面的指令重排序到内存屏</p>
<pre><code>示例说明：  
double r = 2.1; //(1)   
double pi = 3.14;//(2)   
double area = pi*r*r;//(3)1234  
</code></pre>
<p>虽然代码语句的定义顺序为1-&gt;2-&gt;3，但是计算顺序1-&gt;2-&gt;3与2-&gt;1-&gt;3对结果并无影响，所以编译时和运行时可以根据需要对1、2语句进行重排序。后面写文章分析一下JIT的问题，工作中同事提出了一个有意思的问题。。</p>
<h4 id="指令重排序带来的问题"><a href="#指令重排序带来的问题" class="headerlink" title="指令重排序带来的问题"></a>指令重排序带来的问题</h4><p>基于双重检验的单例模式(懒汉型)</p>
<pre><code>public class Singleton3 &#123;  
    private static Singleton3 instance = null;  
  
    private Singleton3() &#123;&#125;  
  
    public static Singleton3 getInstance() &#123;  
        if (instance == null) &#123;  
            synchronized(Singleton3.class) &#123;  
                if (instance == null)  
                    instance = new Singleton3();// 非原子操作  
            &#125;  
        &#125;  
  
        return instance;  
    &#125;  
&#125;12345678910111213141516  
  
</code></pre>
<p>instance&#x3D; new Singleton()并不是一个原子操作，其实际上可以抽象为下面几条JVM指令：</p>
<pre><code>memory =allocate();    //1：分配对象的内存空间   
ctorInstance(memory);  //2：初始化对象   
instance =memory;     //3：设置instance指向刚分配的内存地址123  
  
</code></pre>
<p>上面操作2依赖于操作1，但是操作3并不依赖于操作2。所以JVM是可以针对它们进行指令的优化重排序的，经过重排序后如下：</p>
<pre><code>memory =allocate();    //1：分配对象的内存空间   
instance =memory;     //3：instance指向刚分配的内存地址，此时对象还未初始化  
ctorInstance(memory);  //2：初始化对象123  
  
</code></pre>
<p>指令重排之后，instance指向分配好的内存放在了前面，而这段内存的初始化被排在了后面。在线程A执行这段赋值语句，在初始化分配对象之前就已经将其赋值给instance引用，恰好另一个线程进入方法判断instance引用不为null，然后就将其返回使用，导致出错。</p>
<p><strong>解决办法</strong><br>用volatile关键字修饰instance变量，使得instance在读、写操作前后都会插入内存屏障，避免重排序。</p>
<pre><code>public class Singleton3 &#123;  
    private static volatile Singleton3 instance = null;  
  
    private Singleton3() &#123;&#125;  
  
    public static Singleton3 getInstance() &#123;  
        if (instance == null) &#123;  
            synchronized(Singleton3.class) &#123;  
                if (instance == null)  
                    instance = new Singleton3();  
            &#125;  
        &#125;  
        return instance;  
    &#125;  
  
</code></pre>
<p>volatile关键字提供内存屏障的方式来防止指令被重排，编译器在生成字节码文件时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。</p>
<p>JVM内存屏障插入策略：</p>
<ol>
<li>每个volatile写操作的前面插入一个StoreStore屏障；</li>
<li>在每个volatile写操作的后面插入一个StoreLoad屏障；</li>
<li>在每个volatile读操作的后面插入一个LoadLoad屏障；</li>
<li>在每个volatile读操作的后面插入一个LoadStore屏障。</li>
</ol>
<h2 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h2><ul>
<li>volatile是 <strong>轻量级同步机制</strong> 。在访问volatile变量时不会执行加锁操作，因此也就不会使执行线程阻塞，是一种比synchronized关键字更轻量级的同步机制。</li>
<li>volatile <strong>无法同时保证内存可见性和原子性</strong> 。加锁机制既可以确保可见性又可以确保原子性，而volatile变量 <strong>只能确保可见性</strong> 。</li>
<li>volatile不能修饰写入操作依赖当前值的变量。声明为volatile的简单变量如果当前值与该变量以前的值相关，那么volatile关键字不起作用，也就是说如下的表达式都不是原子操作：“count++”、“count &#x3D; count+1”。</li>
<li>当要访问的变量已在synchronized代码块中，或者为常量时，没必要使用volatile；</li>
<li>volatile屏蔽掉了JVM中必要的代码优化，所以在效率上比较低，因此一定在必要时才使用此关键字。</li>
</ul>
<p>虽然volatile只能保证可见性不能保证原子性，但用volatile修饰long和double可以保证其操作原子性。</p>
<p>所以从Oracle Java Spec里面可以看到：</p>
<ul>
<li>对于64位的long和double，如果没有被volatile修饰，那么对其操作可以不是原子的。在操作的时候，可以分成两步，每次对32位操作。</li>
<li>如果使用volatile修饰long和double，那么其读写都是原子操作</li>
<li>对于64位的引用地址的读写，都是原子操作</li>
<li>在实现JVM时，可以自由选择是否把读写long和double作为原子操作</li>
<li>推荐JVM实现为原子操作</li>
</ul>
<h1 id="synchronized"><a href="#synchronized" class="headerlink" title="synchronized"></a>synchronized</h1><p>众所周知 <code>synchronized</code> 关键字是解决并发问题常用解决方案，有以下三种使用方式:</p>
<ul>
<li>同步普通方法，锁的是当前对象。</li>
<li>同步静态方法，锁的是当前 <code>Class</code> 对象。</li>
<li>同步块，锁的是 <code>()</code> 中的对象。</li>
</ul>
<h2 id="实现原理-1"><a href="#实现原理-1" class="headerlink" title="实现原理"></a>实现原理</h2><p><code>JVM</code> 是通过进入、退出对象监视器( <code>Monitor</code> )来实现对方法、同步块的同步的。</p>
<p>具体实现是在编译之后在同步方法调用前加入一个 <code>monitor.enter</code> 指令，在退出方法和异常处插入 <code>monitor.exit</code> 的指令。</p>
<p>其本质就是对一个对象监视器( <code>Monitor</code> )进行获取，而这个获取过程具有排他性从而达到了同一时刻只能一个线程访问的目的。</p>
<p>而对于没有获取到锁的线程将会阻塞到方法入口处，直到获取锁的线程 <code>monitor.exit</code> 之后才能尝试继续获取锁。</p>
<h2 id="锁优化"><a href="#锁优化" class="headerlink" title="锁优化"></a>锁优化</h2><p><code>synchronized</code> 很多都称之为重量锁，<code>JDK1.6</code> 中对 <code>synchronized</code><br>进行了各种优化，为了能减少获取和释放锁带来的消耗引入了<code>偏向锁</code>和<code>轻量锁</code>。</p>
<p>Java SE 1.6中，锁一共有4种状态，级别从低到高依次是： <strong>无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态</strong><br>，这几个状态会随着竞争情况逐渐升级。 <strong>锁可以升级但不能降级</strong><br>，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。对象的MarkWord变化为下图：</p>
<p><img src="/images/Java%E5%AF%B9%E8%B1%A1%E5%A4%B4MarkWord.png" alt="Java对象头MarkWord"></p>
<h3 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h3><p>HotSpot的作者经过研究发现，大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。</p>
<h4 id="获取锁"><a href="#获取锁" class="headerlink" title="获取锁"></a>获取锁</h4><p>当一个线程访问同步块并获取锁时，会在 <strong>对象头</strong> 和 <strong>栈帧中的锁记录</strong><br>里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark<br>Word里是否存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁。如果测试失败，则需要再测试一下Mark<br>Word中偏向锁的标识是否设置成1（表示当前是偏向锁）：如果没有设置，则使用CAS竞争锁；如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程</p>
<h4 id="释放锁"><a href="#释放锁" class="headerlink" title="释放锁"></a>释放锁</h4><p>偏向锁使用了一种 <strong>等到竞争出现才释放锁</strong> 的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。</p>
<p><img src="/images/%E5%81%8F%E5%90%91%E9%94%81%E7%9A%84%E6%92%A4%E9%94%80.png" alt="偏向锁的撤销"></p>
<p>如图，偏向锁的撤销，需要等待 <strong>全局安全点</strong><br>（在这个时间点上没有正在执行的字节码）。它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态；如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark<br>Word <strong>要么</strong> 重新偏向于其他线程， <strong>要么</strong> 恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。</p>
<p>如果配置中关闭偏向锁，则直接进入轻量级锁</p>
<h3 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h3><p>当偏向锁出现锁竞争时，就会升级为轻量级锁。</p>
<h4 id="加锁"><a href="#加锁" class="headerlink" title="加锁"></a>加锁</h4><p>线程在执行同步块之前，JVM会先在当前线程的栈桢中 <strong>创建用于存储锁记录的空间</strong> ，并将对象头中的Mark Word复制到锁记录中，官方称为<br><strong>Displaced Mark Word</strong> 。然后线程尝试使用CAS <strong>将对象头中的Mark Word替换为指向锁记录的指针</strong><br>。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。</p>
<h4 id="解锁"><a href="#解锁" class="headerlink" title="解锁"></a>解锁</h4><p>轻量级解锁时，会使用原子的CAS操作将Displaced Mark<br>Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。</p>
<p>因为自旋会消耗CPU，为了避免无用的自旋（比如获得锁的线程被阻塞住了），一旦锁升级成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时，都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮的夺锁之争。</p>
<h3 id="其他优化"><a href="#其他优化" class="headerlink" title="其他优化"></a>其他优化</h3><h4 id="适应性自旋"><a href="#适应性自旋" class="headerlink" title="适应性自旋"></a>适应性自旋</h4><p>在使用 <code>CAS</code> 时，如果操作失败，<code>CAS</code> 会自旋再次尝试。由于自旋是需要消耗 <code>CPU</code> 资源的，所以如果长期自旋就白白浪费了<br><code>CPU</code>。<code>JDK1.6</code>加入了适应性自旋:</p>
<blockquote>
<p>如果某个锁自旋很少成功获得，那么下一次就会减少自旋。</p>
</blockquote>
<p>这里还需要提一下，重量级锁是可以降级的，在GC中STW时，<br><strong>重量级锁的降级发生于STW阶段，降级对象就是那些仅仅能被VMThread访问而没有其他JavaThread访问的对象。</strong></p>
<h1 id="AQS"><a href="#AQS" class="headerlink" title="AQS"></a>AQS</h1><p><img src="/images/AQS%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="AQS架构图"></p>
<h2 id="原理概述"><a href="#原理概述" class="headerlink" title="原理概述"></a>原理概述</h2><p>AQS核心思想是，如果被请求的共享资源空闲，那么就将当前请求资源的线程设置为有效的工作线程，将共享资源设置为锁定状态；如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要用的是CLH队列的变体实现的，将暂时获取不到锁的线程加入到队列中。</p>
<p>CLH：Craig、Landin and<br>Hagersten队列，是单向链表，AQS中的队列是CLH变体的虚拟双向队列（FIFO），AQS是通过将每条请求共享资源的线程封装成一个节点来实现锁的分配。</p>
<p><img src="/images/CLH%E9%98%9F%E5%88%97.png" alt="CLH队列"></p>
<h3 id="AQS数据结构"><a href="#AQS数据结构" class="headerlink" title="AQS数据结构"></a>AQS数据结构</h3><pre><code>// 队列的数据结构如下  
// 结点的数据结构  
static final class Node &#123;  
    // 表示该节点等待模式为共享式，通常记录于nextWaiter，  
    // 通过判断nextWaiter的值可以判断当前结点是否处于共享模式  
    static final Node SHARED = new Node();  
    // 表示节点处于独占式模式，与SHARED相对  
    static final Node EXCLUSIVE = null;  
    // waitStatus的不同状态，具体内容见下文的表格  
    static final int CANCELLED =  1;  
    static final int SIGNAL    = -1;  
    static final int CONDITION = -2;  
    static final int PROPAGATE = -3;  
    volatile int waitStatus;  
    // 记录前置结点  
    volatile Node prev;  
    // 记录后置结点  
    volatile Node next;  
    // 记录当前的线程  
    volatile Thread thread;  
    // 用于记录共享模式(SHARED), 也可以用来记录CONDITION队列(见扩展分析)  
    Node nextWaiter;  
    // 通过nextWaiter的记录值判断当前结点的模式是否为共享模式  
    final boolean isShared() &#123;	return nextWaiter == SHARED;&#125;  
    // 获取当前结点的前置结点  
    final Node predecessor() throws NullPointerException &#123; ... &#125;  
    // 用于初始化时创建head结点或者创建SHARED结点  
    Node() &#123;&#125;  
    // 在addWaiter方法中使用，用于创建一个新的结点  
    Node(Thread thread, Node mode) &#123;       
        this.nextWaiter = mode;  
        this.thread = thread;  
    &#125;  
    // 在CONDITION队列中使用该构造函数新建结点  
    Node(Thread thread, int waitStatus) &#123;   
        this.waitStatus = waitStatus;  
        this.thread = thread;  
    &#125;  
&#125;  
// 记录头结点  
private transient volatile Node head;  
// 记录尾结点  
private transient volatile Node tail;  
  
</code></pre>
<p>Node状态表(waitStatus，初始化时默认为0)</p>
<table>
<thead>
<tr>
<th>状态名称</th>
<th>状态值</th>
<th>状态描述</th>
</tr>
</thead>
<tbody><tr>
<td>CANCELLED</td>
<td>1</td>
<td>说明当前结点(即相应的线程)是因为超时或者中断取消的，进入该状态后将无法恢复</td>
</tr>
<tr>
<td>SIGNAL</td>
<td>-1</td>
<td></td>
</tr>
<tr>
<td>说明当前结点的后继结点是(或者将要)由park导致阻塞的，当结点被释放或者取消时，需要通过unpark唤醒后继结点(表现为unparkSuccessor()方法)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>CONDITION</td>
<td>-2</td>
<td></td>
</tr>
<tr>
<td>该状态是用于condition队列结点的，表明结点在等待队列中，结点线程等待在Condition上，当其他线程对Condition调用了signal()方法时，会将其加入到同步队列中去</td>
<td></td>
<td></td>
</tr>
<tr>
<td>PROPAGATE</td>
<td>-3</td>
<td>说明下一次共享式同步状态的获取将会无条件地向后继结点传播</td>
</tr>
</tbody></table>
<h3 id="AQS的重要方法"><a href="#AQS的重要方法" class="headerlink" title="AQS的重要方法"></a>AQS的重要方法</h3><p>从架构图中可以得知，AQS提供了大量用于自定义同步器实现的Protected方法。自定义同步器实现的相关方法也只是为了通过修改State字段来实现多线程的独占模式或者共享模式。自定义同步器需要实现以下方法（并不是全部）：</p>
<table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>protected boolean isHeldExclusively()</td>
<td>该线程是否正在独占资源。只有用到Condition才需要去实现它。</td>
</tr>
<tr>
<td>protected boolean tryAcquire(int arg)</td>
<td></td>
</tr>
<tr>
<td>独占方式。arg为获取锁的次数，尝试获取资源，成功则返回True，失败则返回False。</td>
<td></td>
</tr>
<tr>
<td>protected boolean tryRelease(int arg)</td>
<td></td>
</tr>
<tr>
<td>独占方式。arg为释放锁的次数，尝试释放资源，成功则返回True，失败则返回False。</td>
<td></td>
</tr>
<tr>
<td>protected int tryAcquireShared(int arg)</td>
<td></td>
</tr>
<tr>
<td>共享方式。arg为获取锁的次数，尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。</td>
<td></td>
</tr>
<tr>
<td>protected boolean tryReleaseShared(int arg)</td>
<td></td>
</tr>
<tr>
<td>共享方式。arg为释放锁的次数，尝试释放资源，如果释放后允许唤醒后续等待结点返回True，否则返回False。</td>
<td></td>
</tr>
</tbody></table>
<p>一般来说，自定义同步器要么是独占方式，要么是共享方式，它们也只需实现tryAcquire-tryRelease、tryAcquireShared-<br>tryReleaseShared中的一种即可。AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。ReentrantLock是独占锁，所以实现了tryAcquire-<br>tryRelease。</p>
<p>以非公平锁为例，这里主要阐述一下非公平锁与AQS之间方法的关联之处，具体每一处核心方法的作用会在文章后面详细进行阐述。</p>
<p><img src="/images/%E5%85%AC%E5%B9%B3%E9%94%81%E5%92%8C%E9%9D%9E%E5%85%AC%E5%B9%B3%E9%94%81%E6%B5%81%E7%A8%8B.png" alt="公平锁和非公平锁加锁流程"></p>
<p>以非公平锁ReentrantLock为例，加锁和解锁的流程如下：</p>
<p><img src="/images/ReentrantLock%E5%8A%A0%E9%94%81%E5%92%8C%E8%A7%A3%E9%94%81%E6%B5%81%E7%A8%8B.png" alt="ReentrantLock加锁和解锁流程"></p>
<p>加锁：</p>
<ul>
<li>通过ReentrantLock的加锁方法Lock进行加锁操作。</li>
<li>会调用到内部类Sync的Lock方法，由于Sync#lock是抽象方法，根据ReentrantLock初始化选择的公平锁和非公平锁，执行相关内部类的Lock方法，本质上都会执行AQS的Acquire方法。</li>
<li>AQS的Acquire方法会执行tryAcquire方法，但是由于tryAcquire需要自定义同步器实现，因此执行了ReentrantLock中的tryAcquire方法，由于ReentrantLock是通过公平锁和非公平锁内部类实现的tryAcquire方法，因此会根据锁类型不同，执行不同的tryAcquire。</li>
<li>tryAcquire是获取锁逻辑，获取失败后，会执行框架AQS的后续逻辑，跟ReentrantLock自定义同步器无关。</li>
</ul>
<p>解锁：</p>
<ul>
<li>通过ReentrantLock的解锁方法Unlock进行解锁。</li>
<li>Unlock会调用内部类Sync的Release方法，该方法继承于AQS。</li>
<li>Release中会调用tryRelease方法，tryRelease需要自定义同步器实现，tryRelease只在ReentrantLock中的Sync实现，因此可以看出，释放锁的过程，并不区分是否为公平锁。</li>
<li>释放成功后，所有处理由AQS框架完成，与自定义同步器无关。</li>
</ul>
<h4 id="acquire方法"><a href="#acquire方法" class="headerlink" title="acquire方法"></a>acquire方法</h4><pre><code>// 这里不去看tryAcquire、tryRelease方法的具体实现，只知道它们的作用分别为尝试获取同步状态、尝试释放同步状态  
  
public final void acquire(int arg) &#123;  
    // 如果线程直接获取成功，或者再尝试获取成功后都是直接工作，  
    // 如果是从阻塞状态中唤醒开始工作的线程，将当前的线程中断  
    if (!tryAcquire(arg) &amp;&amp;  
        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))  
        selfInterrupt();  
&#125;  
// 包装线程，新建结点并加入到同步队列中  
private Node addWaiter(Node mode) &#123;  
    Node node = new Node(Thread.currentThread(), mode);  
    Node pred = tail;  
    // 尝试入队， 成功返回  
    if (pred != null) &#123;  
        node.prev = pred;  
        // CAS操作设置队尾  
        if (compareAndSetTail(pred, node)) &#123;  
            pred.next = node;  
            return node;  
        &#125;  
    &#125;  
    // 通过CAS操作自旋完成node入队操作  
    enq(node);  
    return node;  
&#125;  
&#125;  
  
</code></pre>
<p>addWaiter主要的流程如下：</p>
<ul>
<li><p>通过当前的线程和锁模式新建一个节点。</p>
</li>
<li><p>Pred指针指向尾节点Tail。</p>
</li>
<li><p>将New中Node的Prev指针指向Pred。</p>
</li>
<li><p>通过compareAndSetTail方法，完成尾节点的设置。这个方法主要是对tailOffset和Expect进行比较，如果tailOffset的Node和Expect的Node地址是相同的，那么设置Tail的值为Update的值。</p>
<p>static {<br>try {<br>    stateOffset &#x3D; unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField(“state”));<br>    headOffset &#x3D; unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField(“head”));<br>    tailOffset &#x3D; unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField(“tail”));<br>    waitStatusOffset &#x3D; unsafe.objectFieldOffset(Node.class.getDeclaredField(“waitStatus”));<br>    nextOffset &#x3D; unsafe.objectFieldOffset(Node.class.getDeclaredField(“next”));<br>} catch (Exception ex) {<br>throw new Error(ex);<br>  }<br>}</p>
</li>
</ul>
<p>从AQS的静态代码块可以看出，都是获取一个对象的属性相对于该对象在内存当中的偏移量，这样我们就可以根据这个偏移量在对象内存当中找到这个属性。tailOffset指的是tail对应的偏移量，所以这个时候会将new出来的Node置为当前队列的尾节点。同时，由于是双向链表，也需要将前一个节点指向尾节点。</p>
<ul>
<li><p>如果Pred指针是Null（说明等待队列中没有元素），或者当前Pred指针和Tail指向的位置不同（说明被别的线程已经修改），就需要看一下Enq的方法。</p>
<p>&#x2F;&#x2F; java.util.concurrent.locks.AbstractQueuedSynchronizer  </p>
<p>private Node enq(final Node node) {<br>for (;;) {<br>    Node t &#x3D; tail;<br>    if (t &#x3D;&#x3D; null) { &#x2F;&#x2F; Must initialize<br>        if (compareAndSetHead(new Node()))<br>            tail &#x3D; head;<br>    } else {<br>        node.prev &#x3D; t;<br>        if (compareAndSetTail(t, node)) {<br>            t.next &#x3D; node;<br>            return t;<br>        }<br>    }<br>}<br>}</p>
</li>
</ul>
<p>如果没有被初始化，需要进行初始化一个头结点出来。但请注意，初始化的头结点并不是当前线程节点，而是调用了无参构造函数的节点。如果经历了初始化或者并发导致队列中有元素，则与之前的方法相同。其实，addWaiter就是一个在双端链表添加尾节点的操作，需要注意的是，双端链表的头结点是一个无参构造函数的头结点。</p>
<pre><code>// 在同步队列中等待获取同步状态  
final boolean acquireQueued(final Node node, int arg) &#123;  
    boolean failed = true;  
    try &#123;  
        boolean interrupted = false;  
        // 自旋  
        for (;;) &#123;  
            final Node p = node.predecessor();  
            // 检查是否符合开始工作的条件  
            if (p == head &amp;&amp; tryAcquire(arg)) &#123;  
                setHead(node);  
                p.next = null;  
                failed = false;  
                return interrupted;  
            &#125;  
            // 获取不到同步状态，将前置结点标为SIGNAL状态并且通过park操作将node包装的线程阻塞  
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;  
                parkAndCheckInterrupt())  
                interrupted = true;  
        &#125;  
    &#125; finally &#123;  
        // 如果获取失败，将node标记为CANCELLED  
        if (failed)  
            cancelAcquire(node);  
    &#125;  

//setHead方法是把当前节点置为虚节点，但并没有修改waitStatus，因为它是一直需要用的数据。  
private void setHead(Node node) &#123;  
    head = node;  
    node.thread = null;  
    node.prev = null;  
&#125;  
  
// java.util.concurrent.locks.AbstractQueuedSynchronizer  
  
// 靠前驱节点判断当前线程是否应该被阻塞  
private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123;  
    // 获取头结点的节点状态  
    int ws = pred.waitStatus;  
    // 说明头结点处于唤醒状态  
    if (ws == Node.SIGNAL)  
        return true;   
    // 通过枚举值我们知道waitStatus&gt;0是取消状态  
    if (ws &gt; 0) &#123;  
        do &#123;  
            // 循环向前查找取消节点，把取消节点从队列中剔除  
            node.prev = pred = pred.prev;  
        &#125; while (pred.waitStatus &gt; 0);  
        pred.next = node;  
    &#125; else &#123;  
        // 设置前任节点等待状态为SIGNAL  
        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);  
    &#125;  
    return false;  
&#125;  
  
</code></pre>
<p>parkAndCheckInterrupt主要用于挂起当前线程，阻塞调用栈，返回当前线程的中断状态。</p>
<pre><code>// java.util.concurrent.locks.AbstractQueuedSynchronizer  
  
private final boolean parkAndCheckInterrupt() &#123;  
    LockSupport.park(this);  
    return Thread.interrupted();  
&#125;  
</code></pre>
<h4 id="cancelAcquire方法"><a href="#cancelAcquire方法" class="headerlink" title="cancelAcquire方法"></a>cancelAcquire方法</h4><pre><code>private void cancelAcquire(Node node) &#123;  
  // 将无效节点过滤  
    if (node == null)  
        return;  
  // 设置该节点不关联任何线程，也就是虚节点  
    node.thread = null;  
    Node pred = node.prev;  
  // 通过前驱节点，跳过取消状态的node  
    while (pred.waitStatus &gt; 0)  
        node.prev = pred = pred.prev;  
  // 获取过滤后的前驱节点的后继节点  
    Node predNext = pred.next;  
  // 把当前node的状态设置为CANCELLED  
    node.waitStatus = Node.CANCELLED;  
  // 如果当前节点是尾节点，将从后往前的第一个非取消状态的节点设置为尾节点  
  // 更新失败的话，则进入else，如果更新成功，将tail的后继节点设置为null  
    if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123;  
        compareAndSetNext(pred, predNext, null);  
    &#125; else &#123;  
        int ws;  
    // 如果当前节点不是head的后继节点，1:判断当前节点前驱节点的是否为SIGNAL，2:如果不是，则把前驱节点设置为SINGAL看是否成功  
    // 如果1和2中有一个为true，再判断当前节点的线程是否为null  
    // 如果上述条件都满足，把当前节点的前驱节点的后继指针指向当前节点的后继节点  
        if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) &#123;  
            Node next = node.next;  
            if (next != null &amp;&amp; next.waitStatus &lt;= 0)  
                compareAndSetNext(pred, predNext, next);  
        &#125; else &#123;  
      // 如果当前节点是head的后继节点，或者上述条件不满足，那就唤醒当前节点的后继节点  
            unparkSuccessor(node);  
        &#125;  
        node.next = node; // help GC  
    &#125;  
&#125;  
  
</code></pre>
<p>当前的流程：</p>
<ul>
<li>获取当前节点的前驱节点，如果前驱节点的状态是CANCELLED，那就一直往前遍历，找到第一个waitStatus &lt;&#x3D; 0的节点，将找到的Pred节点和当前Node关联，将当前Node设置为CANCELLED。</li>
<li>根据当前节点的位置，考虑以下三种情况：</li>
</ul>
<p>(1) 当前节点是尾节点。</p>
<p>(2) 当前节点是Head的后继节点。</p>
<p>(3) 当前节点不是Head的后继节点，也不是尾节点。</p>
<p><strong>执行cancelAcquire的时候，当前节点的前置节点可能已经从队列中出去了（已经执行过Try代码块中的shouldParkAfterFailedAcquire方法了），如果此时修改Prev指针，有可能会导致Prev指向另一个已经移除队列的Node，因此这块变化Prev指针不安全。<br>shouldParkAfterFailedAcquire方法中，会执行下面的代码，其实就是在处理Prev指针。shouldParkAfterFailedAcquire是获取锁失败的情况下才会执行，进入该方法后，说明共享资源已被获取，当前节点之前的节点都不会出现变化，因此这个时候变更Prev指针比较安全。</strong></p>
<pre><code>do &#123;  
    node.prev = pred = pred.prev;  
&#125; while (pred.waitStatus &gt; 0);  
  
</code></pre>
<h4 id="unlock方法"><a href="#unlock方法" class="headerlink" title="unlock方法"></a><strong>unlock方法</strong></h4><pre><code>public void unlock() &#123;  
    sync.release(1);  
&#125;  
  
</code></pre>
<p>可以看到，本质释放锁的地方，是通过框架来完成的。</p>
<pre><code>// java.util.concurrent.locks.AbstractQueuedSynchronizer  
  
public final boolean release(int arg) &#123;  
    if (tryRelease(arg)) &#123;  
        Node h = head;  
        if (h != null &amp;&amp; h.waitStatus != 0)  
            unparkSuccessor(h);  
        return true;  
    &#125;  
    return false;  
&#125;  
  
</code></pre>
<p>在ReentrantLock里面的公平锁和非公平锁的父类Sync定义了可重入锁的释放锁机制。</p>
<pre><code>// java.util.concurrent.locks.ReentrantLock.Sync  
  
// 方法返回当前锁是不是没有被线程持有  
protected final boolean tryRelease(int releases) &#123;  
    // 减少可重入次数  
    int c = getState() - releases;  
    // 当前线程不是持有锁的线程，抛出异常  
    if (Thread.currentThread() != getExclusiveOwnerThread())  
        throw new IllegalMonitorStateException();  
    boolean free = false;  
    // 如果持有线程全部释放，将当前独占锁所有线程设置为null，并更新state  
    if (c == 0) &#123;  
        free = true;  
        setExclusiveOwnerThread(null);  
    &#125;  
    setState(c);  
    return free;  
&#125;  
  
</code></pre>
<p>我们来解释下述源码：</p>
<pre><code>// java.util.concurrent.locks.AbstractQueuedSynchronizer  
  
public final boolean release(int arg) &#123;  
    // 上边自定义的tryRelease如果返回true，说明该锁没有被任何线程持有  
    if (tryRelease(arg)) &#123;  
        // 获取头结点  
        Node h = head;  
        // 头结点不为空并且头结点的waitStatus不是初始化节点情况，解除线程挂起状态  
        if (h != null &amp;&amp; h.waitStatus != 0)  
            unparkSuccessor(h);  
        return true;  
    &#125;  
    return false;  
&#125;  
  
</code></pre>
<p>这里的判断条件为什么是h !&#x3D; null &amp;&amp; h.waitStatus !&#x3D; 0？</p>
<blockquote>
<p>h &#x3D;&#x3D; null Head还没初始化。初始情况下，head &#x3D;&#x3D;<br>null，第一个节点入队，Head会被初始化一个虚拟节点。所以说，这里如果还没来得及入队，就会出现head &#x3D;&#x3D; null 的情况。</p>
<p>h !&#x3D; null &amp;&amp; waitStatus &#x3D;&#x3D; 0 表明后继节点对应的线程仍在运行中，不需要唤醒。</p>
<p>h !&#x3D; null &amp;&amp; waitStatus &lt; 0 表明后继节点可能被阻塞了，需要唤醒。</p>
</blockquote>
<p>再看一下unparkSuccessor方法：</p>
<pre><code>// java.util.concurrent.locks.AbstractQueuedSynchronizer  
  
private void unparkSuccessor(Node node) &#123;  
    // 获取头结点waitStatus  
    int ws = node.waitStatus;  
    if (ws &lt; 0)  
        compareAndSetWaitStatus(node, ws, 0);  
    // 获取当前节点的下一个节点  
    Node s = node.next;  
    // 如果下个节点是null或者下个节点被cancelled，就找到队列最开始的非cancelled的节点  
    if (s == null || s.waitStatus &gt; 0) &#123;  
        s = null;  
        // 就从尾部节点开始找，到队首，找到队列第一个waitStatus&lt;0的节点。  
        for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev)  
            if (t.waitStatus &lt;= 0)  
                s = t;  
    &#125;  
    // 如果当前节点的下个节点不为空，而且状态&lt;=0，就把当前节点unpark  
    if (s != null)  
        LockSupport.unpark(s.thread);  
&#125;  
  
</code></pre>
<p>为什么要从后往前找第一个非Cancelled的节点呢？原因如下。</p>
<p>之前的addWaiter方法：</p>
<pre><code>// java.util.concurrent.locks.AbstractQueuedSynchronizer  
  
private Node addWaiter(Node mode) &#123;  
    Node node = new Node(Thread.currentThread(), mode);  
    // Try the fast path of enq; backup to full enq on failure  
    Node pred = tail;  
    if (pred != null) &#123;  
        node.prev = pred;  
        if (compareAndSetTail(pred, node)) &#123;  
            pred.next = node;  
            return node;  
        &#125;  
    &#125;  
    enq(node);  
    return node;  
&#125;  
  
</code></pre>
<p>我们从这里可以看到，节点入队并不是原子操作，也就是说，node.prev &#x3D; pred; compareAndSetTail(pred, node)<br>这两个地方可以看作Tail入队的原子操作，但是此时pred.next &#x3D;<br>node;还没执行，如果这个时候执行了unparkSuccessor方法，就没办法从前往后找了，所以需要从后往前找。还有一点原因，在产生CANCELLED状态节点的时候，先断开的是Next指针，Prev指针并未断开，因此也是必须要从后往前遍历才能够遍历完全部的Node。</p>
<p>综上所述，如果是从前往后找，由于极端情况下入队的非原子操作和CANCELLED节点产生过程中断开Next指针的操作，可能会导致无法遍历所有的节点。所以，唤醒对应的线程后，对应的线程就会继续往下执行。继续执行acquireQueued方法以后，中断如何处理？</p>
<h3 id="中断恢复后的执行流程"><a href="#中断恢复后的执行流程" class="headerlink" title="中断恢复后的执行流程"></a>中断恢复后的执行流程</h3><p>唤醒后，会执行return Thread.interrupted();，这个函数返回的是当前执行线程的中断状态，并清除。</p>
<pre><code>// java.util.concurrent.locks.AbstractQueuedSynchronizer  
  
private final boolean parkAndCheckInterrupt() &#123;  
    LockSupport.park(this);  
    return Thread.interrupted();  
&#125;  
</code></pre>
<p>再回到acquireQueued代码，当parkAndCheckInterrupt返回True或者False的时候，interrupted的值不同，但都会执行下次循环。如果这个时候获取锁成功，就会把当前interrupted返回。</p>
<pre><code>// java.util.concurrent.locks.AbstractQueuedSynchronizer  
  
final boolean acquireQueued(final Node node, int arg) &#123;  
    boolean failed = true;  
    try &#123;  
        boolean interrupted = false;  
        for (;;) &#123;  
            final Node p = node.predecessor();  
            if (p == head &amp;&amp; tryAcquire(arg)) &#123;  
                setHead(node);  
                p.next = null; // help GC  
                failed = false;  
                return interrupted;  
            &#125;  
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt())  
                interrupted = true;  
            &#125;  
    &#125; finally &#123;  
        if (failed)  
            cancelAcquire(node);  
    &#125;  
&#125;  
  
</code></pre>
<p>如果acquireQueued为True，就会执行selfInterrupt方法。</p>
<pre><code>// java.util.concurrent.locks.AbstractQueuedSynchronizer  
  
static void selfInterrupt() &#123;  
    Thread.currentThread().interrupt();  
&#125;  
  
</code></pre>
<p>该方法其实是为了中断线程。但为什么获取了锁以后还要中断线程呢？这部分属于Java提供的协作式中断知识内容，感兴趣同学可以查阅一下。这里简单介绍一下：</p>
<ol>
<li>当中断线程被唤醒时，并不知道被唤醒的原因，可能是当前线程在等待中被中断，也可能是释放了锁以后被唤醒。因此我们通过Thread.interrupted()方法检查中断标记（该方法返回了当前线程的中断状态，并将当前线程的中断标识设置为False），并记录下来，如果发现该线程被中断过，就再中断一次。</li>
<li>线程在等待资源的过程中被唤醒，唤醒后还是会不断地去尝试获取锁，直到抢到锁为止。也就是说，在整个流程中，并不响应中断，只是记录中断记录。最后抢到锁返回了，那么如果被中断过的话，就需要补充一次中断。</li>
</ol>
<h1 id="原子类"><a href="#原子类" class="headerlink" title="原子类"></a>原子类</h1><p>原子操作是指一个不受其他操作影响的操作任务单元。原子操作是在多线程环境下避免数据不一致必须的手段。</p>
<p>int++并不是一个原子操作，所以当一个线程读取它的值并加 1 时，另外一个线程有可能会读到之前的值，这就会引发错误。</p>
<p>为了解决这个问题，必须保证增加操作是原子的，在 JDK1.5 之前我们可以使用同步技术来做到这一点。到<br>JDK1.5，java.util.concurrent.atomic 包提供了 int 和long<br>类型的原子包装类，它们可以自动的保证对于他们的操作是原子的并且不需要使用同步。</p>
<p>java.util.concurrent<br>这个包里面提供了一组原子类。其基本的特性就是在多线程环境下，当有多个线程同时执行这些类的实例包含的方法时，具有排他性，即当某个线程进入方法，执行其中的指令时，不会被其他线程打断，而别的线程就像自旋锁一样，一直等到该方法执行完成，才由<br>JVM 从等待队列中选择另一个线程进入，这只是一种逻辑上的理解。</p>
<p>原子类：AtomicBoolean，AtomicInteger，AtomicLong，AtomicReference</p>
<p>原子数组：AtomicIntegerArray，AtomicLongArray，AtomicReferenceArray</p>
<p>原子属性更新器：AtomicLongFieldUpdater，AtomicIntegerFieldUpdater，AtomicReferenceFieldUpdater</p>
<p>解决 ABA 问题的原子类：AtomicMarkableReference（通过引入一个<br>boolean来反映中间有没有变过），AtomicStampedReference（通过引入一个 int 来累加来反映中间有没有变过）</p>
<h2 id="AtomicInteger举例"><a href="#AtomicInteger举例" class="headerlink" title="AtomicInteger举例"></a>AtomicInteger举例</h2><pre><code>public class AtomicInteger extends Number implements java.io.Serializable &#123;  
    
    private static final sun.misc.Unsafe U = sun.misc.Unsafe.getUnsafe();  
    private static final long VALUE;  
  
    private volatile int value;//注意该值用volatile修饰  
  
    public AtomicInteger(int initialValue) &#123;  
        value = initialValue;  
    &#125;  
    //以原子的方式将输入的值与ActomicInteger中的值进行相加，  
    //注意：返回相加前ActomicInteger中的值  
    public final int getAndAdd(int delta) &#123;  
        return U.getAndAddInt(this, VALUE, delta);  
    &#125;  
    //以原子的方式将输入的值与ActomicInteger中的值进行相加，  
    //注意：返回相加后的结果  
    public final int addAndGet(int delta) &#123;  
        return U.getAndAddInt(this, VALUE, delta) + delta;  
    &#125;  
    //以原子方式将当前ActomicInteger中的值加1,  
    //注意：返回相加前ActomicInteger中的值  
    public final int getAndIncrement() &#123;  
        return U.getAndAddInt(this, VALUE, 1);  
    &#125;  
    //以原子方式将当前ActomicInteger中的值加1,  
    //注意：返回相加后的结果  
    public final int incrementAndGet() &#123;  
        return U.getAndAddInt(this, VALUE, 1) + 1;  
    &#125;  
  
    //省略部分代码...  
  &#125;  
  
</code></pre>
<p>AtomicInteger内部会调用其中sun.misc.Unsafe方法中getAndAddInt的方法。具体代码如下：</p>
<pre><code>public final int getAndAdd(int delta) &#123;  
       return U.getAndAddInt(this, VALUE, delta);  
   &#125;  
  
</code></pre>
<p>而sun.misc.Unsafe方法中getAndAddInt方法又会调用jdk.internal.misc.Unsafe的getAndAddInt，具体代码如下：</p>
<pre><code>public final int getAndAddInt(Object o, long offset, int delta) &#123;  
       return theInternalUnsafe.getAndAddInt(o, offset, delta);  
   &#125;  
</code></pre>
<p>jdk.internal.misc.Unsafe的getAndAddInt（）方法的声明如下：</p>
<pre><code>public final int getAndAddInt(Object o, long offset, int delta) &#123;  
        int v;  
        do &#123;  
            v = getIntVolatile(o, offset);//先获取内存中存储的值  
        &#125; while (!weakCompareAndSetInt(o, offset, v, v + delta));//如果不是期望的结果值，就一直循环  
        return v;  
    &#125;  
      
//该函数返回值代表CAS操作是否成功      
public final boolean weakCompareAndSetInt(Object o, long offset,  
                                          int expected,  
                                          int x) &#123;  
     return compareAndSetInt(o, offset, expected, x);//执行CAS操作  
    &#125;  
  
</code></pre>
<p>从上述代码中我们可以得出，会先获取内存中存储的值，最终会调用compareAndSetInt（）方法来完成最终的原子操作。其中compareAndSetInt（）方法的返回值代表着该次CAS操作是否成功。如果不成功。那么会一直循环。直到成功为止（也就是循环CAS操作）。</p>
<h1 id="CountDownLatch"><a href="#CountDownLatch" class="headerlink" title="CountDownLatch"></a>CountDownLatch</h1><p>CountDownLatch顾名思义，count + down + latch ＝ 计数 ＋ 减 ＋ 门闩。<br>可以理解这个东西就是个计数器，只能减不能加，同时它还有个门闩的作用，当计数器不为0时，门闩是锁着的；当计数器减到0时，门闩就打开了。</p>
<h2 id="实现原理-2"><a href="#实现原理-2" class="headerlink" title="实现原理"></a>实现原理</h2><h3 id="构造方法"><a href="#构造方法" class="headerlink" title="构造方法"></a>构造方法</h3><p>下面是实现的源码，非常简短，主要是创建了一个Sync对象。</p>
<pre><code>public CountDownLatch(int count) &#123;  
        if (count &lt; 0) throw new IllegalArgumentException(&quot;count &lt; 0&quot;);  
        this.sync = new Sync(count);  
&#125;  
</code></pre>
<h3 id="Sync对象"><a href="#Sync对象" class="headerlink" title="Sync对象"></a>Sync对象</h3><pre><code>private static final class Sync extends AbstractQueuedSynchronizer &#123;  
        private static final long serialVersionUID = 4982264981922014374L;  
   
        Sync(int count) &#123;  
            setState(count);  
        &#125;  
   
        int getCount() &#123;  
            return getState();  
        &#125;  
   
        protected int tryAcquireShared(int acquires) &#123;  
            return (getState() == 0) ? 1 : -1;  
        &#125;  
   
        protected boolean tryReleaseShared(int releases) &#123;  
            // Decrement count; signal when transition to zero  
            for (;;) &#123;  
                int c = getState();  
                if (c == 0)  
                    return false;  
                int nextc = c-1;  
                if (compareAndSetState(c, nextc))  
                    return nextc == 0;  
            &#125;  
        &#125;  
    &#125;  
</code></pre>
<p>假设我们是这样创建的：new CountDownLatch(5)。其实也就相当于new<br>Sync(5)，相当于setState(5)。setState其实就是共享锁资源总数,我们可以暂时理解为设置一个计数器，当前计数器初始值为5。</p>
<p>tryAcquireShared方法其实就是判断一下当前计数器的值，是否为0了，如果为0的话返回1（<br><strong>返回1的时候，就表示获取锁成功,awit()方法就不再阻塞</strong> ）。</p>
<p>tryReleaseShared方法就是利用CAS的方式，对计数器进行减一的操作，而我们实际上每次调用countDownLatch.countDown()方法的时候，最终都会调到这个方法，对计数器进行减一操作，一直减到0为止。</p>
<h3 id="await"><a href="#await" class="headerlink" title="await()"></a>await()</h3><pre><code>public void await() throws InterruptedException &#123;      
    sync.acquireSharedInterruptibly(1);      
&#125;  
</code></pre>
<p>代码很简单，就一句话（注意acquireSharedInterruptibly（）方法是抽象类：AbstractQueuedSynchronizer的一个方法，我们上面提到的Sync继承了它），我们跟踪源码，继续往下看：</p>
<h3 id="acquireSharedInterruptibly-int-arg"><a href="#acquireSharedInterruptibly-int-arg" class="headerlink" title="acquireSharedInterruptibly(int arg)"></a>acquireSharedInterruptibly(int arg)</h3><pre><code>public final void acquireSharedInterruptibly(int arg)  
           throws InterruptedException &#123;  
       if (Thread.interrupted())  
           throw new InterruptedException();  
       if (tryAcquireShared(arg) &lt; 0)  
           doAcquireSharedInterruptibly(arg);  
   &#125;  
  
</code></pre>
<p>源码也是非常简单的，首先判断了一下，当前线程是否有被中断，如果没有的话，就调用tryAcquireShared(int<br>acquires)方法，判断一下当前线程是否还需要“阻塞”。其实这里调用的tryAcquireShared方法，就是我们上面提到的java.util.concurrent.CountDownLatch.Sync.tryAcquireShared(int)这个方法。<br>当然，在一开始我们没有调用过countDownLatch.countDown()方法时，这里tryAcquireShared方法肯定是会返回-1的，因为会进入到doAcquireSharedInterruptibly方法。</p>
<pre><code>private void doAcquireSharedInterruptibly(int arg)  
    throws InterruptedException &#123;  
    final Node node = addWaiter(Node.SHARED);  
    boolean failed = true;  
    try &#123;  
        for (;;) &#123;  
            final Node p = node.predecessor();  
            if (p == head) &#123;  
                int r = tryAcquireShared(arg);  
                if (r &gt;= 0) &#123;  
                    setHeadAndPropagate(node, r);  
                    p.next = null; // help GC  
                    failed = false;  
                    return;  
                &#125;  
            &#125;  
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;  
                parkAndCheckInterrupt())  
                throw new InterruptedException();  
        &#125;  
    &#125; finally &#123;  
        if (failed)  
            cancelAcquire(node);  
    &#125;  
&#125;  
  
</code></pre>
<h3 id="countDown-方法"><a href="#countDown-方法" class="headerlink" title="countDown()方法"></a>countDown()方法</h3><pre><code>// 计数器减1  
public void countDown() &#123;  
    sync.releaseShared(1);   
&#125;  
  
//调用AQS的releaseShared方法  
public final boolean releaseShared(int arg) &#123;  
    if (tryReleaseShared(arg)) &#123;//计数器减一  
        doReleaseShared();//唤醒后继结点,这个时候队列中可能只有调用过await()的线程节点,也可能队列为空,一般为主线程  
        return true;  
    &#125;  
    return false;  
&#125;  
  
//自定义同步器实现的方法  
protected boolean tryReleaseShared(int releases) &#123;  
    // Decrement count; signal when transition to zero  
    for (;;) &#123;  
        int c = getState();  
        if (c == 0)  
            return false;  //重复调用的时候返回false结束上层方法  
        int nextc = c-1;  
        if (compareAndSetState(c, nextc))  
            return nextc == 0;  //调用countDown的线程不把资源释放到0,改方法一直返回 false   
    &#125;  
&#125;  
  
</code></pre>
<p>这个时候，我们应该对于countDownLatch.await()方法是怎么“阻塞”当前线程的，已经非常明白了。其实说白了，就是当你调用了countDownLatch.await()方法后，你当前线程就会进入了一个死循环当中，在这个死循环里面，会不断的进行判断，通过调用tryAcquireShared方法，不断判断我们上面说的那个计数器，看看它的值是否为0了（为0的时候，其实就是我们调用了足够多<br>countDownLatch.countDown()方法的时候），如果是为0的话，tryAcquireShared就会返回1，代码也会进入到if (r &gt;&#x3D;<br>0)部分，然后跳出了循环，也就不再“阻塞”当前线程了。需要注意的是，说是在不停的循环，其实也并非在不停的执行for循环里面的内容，因为在后面调用parkAndCheckInterrupt（）方法时，在这个方法里面是会调用<br>LockSupport.park(this);来挂起当前线程。</p>
<h3 id="CountDownLatch-使用的注意点："><a href="#CountDownLatch-使用的注意点：" class="headerlink" title="CountDownLatch 使用的注意点："></a>CountDownLatch 使用的注意点：</h3><ol>
<li>只有当count为0时， <strong>await之后的程序才够执行</strong> 。</li>
<li><strong>countDown必须写在finally中，防止发生异程常时，导致程序死锁。</strong></li>
</ol>
<h3 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h3><pre><code>public class Test &#123;  
    public static void main(String[] args) &#123;  
        final CountDownLatch latch = new CountDownLatch(2);  
        new Thread() &#123;  
            public void run() &#123;  
                try &#123;  
                    System.out.println(&quot;子线程&quot; + Thread.currentThread().getName() + &quot;正在执行&quot;);  
                    Thread.sleep(3000);  
                    System.out.println(&quot;子线程&quot; + Thread.currentThread().getName() + &quot;执行完毕&quot;);  
                &#125; catch (InterruptedException e) &#123;  
                    e.printStackTrace();  
                &#125; finally &#123;  
                    latch.countDown();  
                &#125;  
            &#125;;  
        &#125;.start();  
  
        new Thread() &#123;  
            public void run() &#123;  
                try &#123;  
                    System.out.println(&quot;子线程&quot; + Thread.currentThread().getName() + &quot;正在执行&quot;);  
                    Thread.sleep(3000);  
                    System.out.println(&quot;子线程&quot; + Thread.currentThread().getName() + &quot;执行完毕&quot;);  
                    latch.countDown();  
                &#125; catch (InterruptedException e) &#123;  
                    e.printStackTrace();  
                &#125; finally &#123;  
                    latch.countDown();  
                &#125;  
            &#125;;  
        &#125;.start();  
        try &#123;  
            System.out.println(&quot;等待2个子线程执行完毕...&quot;);  
            latch.await();  
            System.out.println(&quot;2个子线程已经执行完毕&quot;);  
            System.out.println(&quot;继续执行主线程&quot;);  
        &#125; catch (InterruptedException e) &#123;              
            e.printStackTrace();          
            &#125;     
    &#125;  
&#125;  
  
</code></pre>
<h1 id="CyclicBarrier"><a href="#CyclicBarrier" class="headerlink" title="CyclicBarrier"></a>CyclicBarrier</h1><p>CyclicBarrier是一个同步辅助类，允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)。因为该<br>barrier 在释放等待线程后可以重用，所以称它为循环 的 barrier。</p>
<p>注意比较CountDownLatch和CyclicBarrier：</p>
<ol>
<li><p>CountDownLatch的作用是允许1或N个线程等待其他线程完成执行；而CyclicBarrier则是允许N个线程相互等待。</p>
</li>
<li><p>CountDownLatch的计数器无法被重置；CyclicBarrier的计数器可以被重置后使用，因此它被称为是循环的barrier。</p>
</li>
</ol>
<h2 id="CyclicBarrier函数列表"><a href="#CyclicBarrier函数列表" class="headerlink" title="CyclicBarrier函数列表"></a><strong>CyclicBarrier函数列表</strong></h2><pre><code>CyclicBarrier(int parties)  
创建一个新的 CyclicBarrier，它将在给定数量的参与者（线程）处于等待状态时启动，但它不会在启动 barrier 时执行预定义的操作。  
CyclicBarrier(int parties, Runnable barrierAction)  
创建一个新的 CyclicBarrier，它将在给定数量的参与者（线程）处于等待状态时启动，并在启动 barrier 时执行给定的屏障操作，该操作由最后一个进入 barrier 的线程执行。  
  
int await()  
在所有参与者都已经在此 barrier 上调用 await 方法之前，将一直等待。  
int await(long timeout, TimeUnit unit)  
在所有参与者都已经在此屏障上调用 await 方法之前将一直等待,或者超出了指定的等待时间。  
int getNumberWaiting()  
返回当前在屏障处等待参与者数目。  
int getParties()  
返回要求启动此 barrier 的参与者数目。  
boolean isBroken()  
查询此屏障是否处于损坏状态。  
void reset()  
将屏障重置为其初始状态。  
</code></pre>
<h2 id="CyclicBarrier数据结构"><a href="#CyclicBarrier数据结构" class="headerlink" title="CyclicBarrier数据结构"></a>CyclicBarrier数据结构</h2><p>CyclicBarrier的UML类图如下：</p>
<p><img src="/images/CyclicBarrier%E7%9A%84UML%E7%B1%BB%E5%9B%BE.jpg" alt="CyclicBarrier的UML类图"></p>
<p>CyclicBarrier是包含了”<a target="_blank" rel="noopener" href="http://www.cnblogs.com/skywang12345/p/3496147.html">ReentrantLock</a>对象lock”和”<a target="_blank" rel="noopener" href="http://www.cnblogs.com/skywang12345/p/3496716.html">Condition</a>对象trip”，它是通过独占锁实现的。下面通过源码去分析到底是如何实现的。</p>
<h2 id="CyclicBarrier源码分析"><a href="#CyclicBarrier源码分析" class="headerlink" title="CyclicBarrier源码分析"></a>CyclicBarrier源码分析</h2><h3 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h3><p>CyclicBarrier的构造函数共2个：CyclicBarrier 和 CyclicBarrier(int parties, Runnable<br>barrierAction)。第1个构造函数是调用第2个构造函数来实现的，下面第2个构造函数的源码。</p>
<pre><code>public CyclicBarrier(int parties, Runnable barrierAction) &#123;  
    if (parties &lt;= 0) throw new IllegalArgumentException();  
    // parties表示“必须同时到达barrier的线程个数”。  
    this.parties = parties;  
    // count表示“处在等待状态的线程个数”。  
    this.count = parties;  
    // barrierCommand表示“parties个线程到达barrier时，会执行的动作”。  
    this.barrierCommand = barrierAction;  
&#125;  
  
</code></pre>
<h3 id="await-1"><a href="#await-1" class="headerlink" title="await()"></a>await()</h3><pre><code>public int await() throws InterruptedException, BrokenBarrierException &#123;  
    try &#123;  
        return dowait(false, 0L);  
    &#125; catch (TimeoutException toe) &#123;  
        throw new Error(toe); // cannot happen;  
    &#125;  
&#125;  
</code></pre>
<p><strong>说明</strong> ：await()是通过dowait()实现的。</p>
<pre><code>private int dowait(boolean timed, long nanos)  
    throws InterruptedException, BrokenBarrierException,  
           TimeoutException &#123;  
    final ReentrantLock lock = this.lock;  
    // 获取“独占锁(lock)”  
    lock.lock();  
    try &#123;  
        // 保存“当前的generation”  
        final Generation g = generation;  
  
        // 若“当前generation已损坏”，则抛出异常。  
        if (g.broken)  
            throw new BrokenBarrierException();  
  
        // 如果当前线程被中断，则通过breakBarrier()终止CyclicBarrier，唤醒CyclicBarrier中所有等待线程。  
        if (Thread.interrupted()) &#123;  
            breakBarrier();  
            throw new InterruptedException();  
        &#125;  
  
       // 将“count计数器”-1  
       int index = --count;  
       // 如果index=0，则意味着“有parties个线程到达barrier”。  
       if (index == 0) &#123;  // tripped  
           boolean ranAction = false;  
           try &#123;  
               // 如果barrierCommand不为null，则执行该动作。  
               final Runnable command = barrierCommand;  
               if (command != null)  
                   command.run();  
               ranAction = true;  
               // 唤醒所有等待线程，并更新generation。  
               nextGeneration();  
               return 0;    //这里等价于return index;  
           &#125; finally &#123;  
               if (!ranAction)  
                   breakBarrier();  
           &#125;  
       &#125;  
  
        // 当前线程一直阻塞，直到“有parties个线程到达barrier” 或 “当前线程被中断” 或 “超时”这3者之一发生，  
        // 当前线程才继续执行。  
        for (;;) &#123;  
            try &#123;  
                // 如果不是“超时等待”，则调用awati()进行等待；否则，调用awaitNanos()进行等待。  
                if (!timed)  
                    trip.await();  
                else if (nanos &gt; 0L)  
                    nanos = trip.awaitNanos(nanos);  
            &#125; catch (InterruptedException ie) &#123;  
                // 如果等待过程中，线程被中断，则执行下面的函数。  
                if (g == generation &amp;&amp; ! g.broken) &#123;  
                    breakBarrier();  
                    throw ie;  
                &#125; else &#123;  
                    Thread.currentThread().interrupt();  
                &#125;  
            &#125;  
  
            // 如果“当前generation已经损坏”，则抛出异常。  
            if (g.broken)  
                throw new BrokenBarrierException();  
  
            // 如果“generation已经换代”，则返回index。  
            if (g != generation)  
                return index;  
  
            // 如果是“超时等待”，并且时间已到，则通过breakBarrier()终止CyclicBarrier，唤醒CyclicBarrier中所有等待线程。  
            if (timed &amp;&amp; nanos &lt;= 0L) &#123;  
                breakBarrier();  
                throw new TimeoutException();  
            &#125;  
        &#125;  
    &#125; finally &#123;  
        // 释放“独占锁(lock)”  
        lock.unlock();  
    &#125;  
&#125;  
</code></pre>
<p><strong>说明</strong> ：dowait()的作用就是让当前线程阻塞，直到“有parties个线程到达barrier” 或 “当前线程被中断” 或<br>“超时”这3者之一发生，当前线程才继续执行。<br>(01) generation是CyclicBarrier的一个成员变量，它的定义如下：</p>
<pre><code>private Generation generation = new Generation();  
  
private static class Generation &#123;  
    boolean broken = false;  
&#125;  
</code></pre>
<p>在CyclicBarrier中，同一批的线程属于同一代，即同一个Generation；CyclicBarrier中通过generation对象，记录属于哪一代。<br>当有parties个线程到达barrier，generation就会被更新换代。</p>
<p>(02)<br>如果当前线程被中断，即Thread.interrupted()为true；则通过breakBarrier()终止CyclicBarrier。breakBarrier()的源码如下：</p>
<pre><code>private void breakBarrier() &#123;  
    generation.broken = true;  
    count = parties;  
    trip.signalAll();  
&#125;  
  
</code></pre>
<p>breakBarrier()会设置当前中断标记broken为true，意味着“将该Generation中断”；同时，设置count&#x3D;parties，即重新初始化count；最后，通过signalAll()唤醒CyclicBarrier上所有的等待线程。</p>
<p>(03) 将“count计数器”-1，即–count；然后判断是不是“有parties个线程到达barrier”，即index是不是为0。<br>当index&#x3D;0时，如果barrierCommand不为null，则执行该barrierCommand，barrierCommand就是我们创建CyclicBarrier时，传入的Runnable对象。然后，调用nextGeneration()进行换代工作，nextGeneration()的源码如下：</p>
<pre><code>private void nextGeneration() &#123;  
    trip.signalAll();  
    count = parties;  
    generation = new Generation();  
&#125;  
</code></pre>
<p>首先，它会调用signalAll()唤醒CyclicBarrier上所有的等待线程；接着，重新初始化count；最后，更新generation的值。</p>
<p>(04)<br>在for(;;)循环中。timed是用来表示当前是不是“超时等待”线程。如果不是，则通过trip.await()进行等待；否则，调用awaitNanos()进行超时等待。</p>
<h3 id="举个栗子-1"><a href="#举个栗子-1" class="headerlink" title="举个栗子"></a>举个栗子</h3><pre><code>import java.util.concurrent.CyclicBarrier;  
import java.util.concurrent.BrokenBarrierException;  
  
public class CyclicBarrierTest1 &#123;  
  
    private static int SIZE = 5;  
    private static CyclicBarrier cb;  
    public static void main(String[] args) &#123;  
  
        cb = new CyclicBarrier(SIZE);  
  
        // 新建5个任务  
        for(int i=0; i&lt;SIZE; i++)  
            new InnerThread().start();  
    &#125;  
  
    static class InnerThread extends Thread&#123;  
        public void run() &#123;  
            try &#123;  
                System.out.println(Thread.currentThread().getName() + &quot; wait for CyclicBarrier.&quot;);  
  
                // 将cb的参与者数量加1  
                cb.await();  
  
                // cb的参与者数量等于5时，才继续往后执行  
                System.out.println(Thread.currentThread().getName() + &quot; continued.&quot;);  
            &#125; catch (BrokenBarrierException e) &#123;  
                e.printStackTrace();  
            &#125; catch (InterruptedException e) &#123;  
                e.printStackTrace();  
            &#125;  
        &#125;  
    &#125;  
&#125;  
运行结果：  
Thread-1 wait for CyclicBarrier.  
Thread-2 wait for CyclicBarrier.  
Thread-3 wait for CyclicBarrier.  
Thread-4 wait for CyclicBarrier.  
Thread-0 wait for CyclicBarrier.  
Thread-0 continued.  
Thread-4 continued.  
Thread-2 continued.  
Thread-3 continued.  
Thread-1 continued.  
  

import java.util.concurrent.CyclicBarrier;  
import java.util.concurrent.BrokenBarrierException;  
  
public class CyclicBarrierTest2 &#123;  
  
    private static int SIZE = 5;  
    private static CyclicBarrier cb;  
    public static void main(String[] args) &#123;  
  
        cb = new CyclicBarrier(SIZE, new Runnable () &#123;  
            public void run() &#123;  
                System.out.println(&quot;CyclicBarrier&#39;s parties is: &quot;+ cb.getParties());  
            &#125;  
        &#125;);  
  
        // 新建5个任务  
        for(int i=0; i&lt;SIZE; i++)  
            new InnerThread().start();  
    &#125;  
  
    static class InnerThread extends Thread&#123;  
        public void run() &#123;  
            try &#123;  
                System.out.println(Thread.currentThread().getName() + &quot; wait for CyclicBarrier.&quot;);  
  
                // 将cb的参与者数量加1  
                cb.await();  
  
                // cb的参与者数量等于5时，才继续往后执行  
                System.out.println(Thread.currentThread().getName() + &quot; continued.&quot;);  
            &#125; catch (BrokenBarrierException e) &#123;  
                e.printStackTrace();  
            &#125; catch (InterruptedException e) &#123;  
                e.printStackTrace();  
            &#125;  
        &#125;  
    &#125;  
&#125;  
运行结果：  
  
Thread-1 wait for CyclicBarrier.  
Thread-2 wait for CyclicBarrier.  
Thread-3 wait for CyclicBarrier.  
Thread-4 wait for CyclicBarrier.  
Thread-0 wait for CyclicBarrier.  
CyclicBarrier&#39;s parties is: 5  
Thread-0 continued.  
Thread-4 continued.  
Thread-2 continued.  
Thread-3 continued.  
Thread-1 continued.  
</code></pre>
<h1 id="Semaphore"><a href="#Semaphore" class="headerlink" title="Semaphore"></a>Semaphore</h1><p>我们以一个停车场运作为例来说明信号量的作用。假设停车场只有三个车位，一开始三个车位都是空的。这时如果同时来了三辆车，看门人允许其中它们进入，然后放下车拦。以后来的车必须在入口等待，直到停车场中有车辆离开。这时，如果有一辆车离开停车场，看门人得知后，打开车拦，放入一辆，如果又离开一辆，则又可以放入一辆，如此往复。</p>
<p>在这个停车场系统中，车位是公共资源，每辆车好比一个线程，看门人起的就是信号量的作用。信号量是一个非负整数，表示了当前公共资源的可用数目（在上面的例子中可以用空闲的停车位类比信号量），当一个线程要使用公共资源时（在上面的例子中可以用车辆类比线程），首先要查看信号量，如果信号量的值大于1，则将其减1，然后去占有公共资源。如果信号量的值为0，则线程会将自己阻塞，直到有其它线程释放公共资源</p>
<p>在信号量上我们定义两种操作： acquire（获取） 和<br>release（释放）。当一个线程调用acquire操作时，它要么通过成功获取信号量（信号量减1），要么一直等下去，直到有线程释放信号量，或超时。release（释放）实际上会将信号量的值加1，然后唤醒等待的线程。</p>
<p>信号量主要用于两个目的，一个是用于多个共享资源的互斥使用，另一个用于并发线程数的控制。</p>
<h2 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h2><p>在Java的并发包中，Semaphore类表示信号量。Semaphore内部主要通过AQS（AbstractQueuedSynchronizer）实现线程的管理。Semaphore有两个构造函数，<br><strong>参数permits表示许可数</strong> ，它最后传递给了AQS的state值。线程在运行时首先获取许可， <strong>如果成功，许可数就减1</strong><br>，线程运行，当线程运行结束就释放许可， <strong>许可数就加1</strong><br>。如果许可数为0，则获取失败，线程位于AQS的等待队列中，它会被其它释放许可的线程唤醒。在创建Semaphore对象的时候还可以指定它的公平性。一般常用非公平的信号量，非公平信号量是指在获取许可时先尝试获取许可，而不必关心是否已有需要获取许可的线程位于等待队列中，如果获取失败，才会入列。而公平的信号量在获取许可时首先要查看等待队列中是否已有线程，如果有则入列。</p>
<h3 id="构造函数-1"><a href="#构造函数-1" class="headerlink" title="构造函数"></a>构造函数</h3><pre><code>//非公平的构造函数  
public Semaphore(int permits) &#123;  
    sync = new NonfairSync(permits);  
&#125;  
  
//通过fair参数决定公平性  
public Semaphore(int permits, boolean fair) &#123;  
    sync = fair ? new FairSync(permits) : new NonfairSync(permits);  
&#125;   
  
</code></pre>
<h3 id="acquire"><a href="#acquire" class="headerlink" title="acquire()"></a>acquire()</h3><pre><code>public void acquire() throws InterruptedException &#123;  
    sync.acquireSharedInterruptibly(1);  
&#125;  
  
public final void acquireSharedInterruptibly(int arg)  
        throws InterruptedException &#123;  
    if (Thread.interrupted())  
        throw new InterruptedException();  
    if (tryAcquireShared(arg) &lt; 0)  
        doAcquireSharedInterruptibly(arg);  
&#125;  
</code></pre>
<ul>
<li>调用tryAcquireShared()方法尝试获取信号。</li>
<li>如果没有可用信号，将当前线程加入等待队列并挂起</li>
</ul>
<p>tryAcquireShared<br>会调用对应公平或者非公平同步器的方法,xxTAcquireShared下面是非公平的,公平的方法就多了一个hasQueuedPredecessors方法的逻辑</p>
<h3 id="NonfairSync-tryAcquireShared"><a href="#NonfairSync-tryAcquireShared" class="headerlink" title="NonfairSync.tryAcquireShared()"></a>NonfairSync.tryAcquireShared()</h3><pre><code>final int nonfairTryAcquireShared(int acquires) &#123;  
    for (;;) &#123;  
        int available = getState();  
        int remaining = available - acquires; //剩余许可数  
        if (remaining &lt; 0 ||  
            compareAndSetState(available, remaining))   
            return remaining;  
    &#125;  
&#125;  
</code></pre>
<p>可以看出，如果remaining &lt;0<br>即获取许可后，许可数小于0，则获取失败，在doAcquireSharedInterruptibly方法中线程会将自身阻塞，然后入列。可以看到，非公平锁对于信号的获取是直接使用CAS进行尝试的。</p>
<h3 id="FairSync-tryAcquireShared"><a href="#FairSync-tryAcquireShared" class="headerlink" title="FairSync.tryAcquireShared()"></a>FairSync.tryAcquireShared()</h3><pre><code>protected int tryAcquireShared(int acquires) &#123;  
            for (;;) &#123;  
                if (hasQueuedPredecessors())  
                    return -1;  
                int available = getState();  
                int remaining = available - acquires;  
                if (remaining &lt; 0 ||  
                    compareAndSetState(available, remaining))  
                    return remaining;  
            &#125;  
        &#125;  
  
</code></pre>
<ul>
<li><p>先调用hasQueuedPredecessors()方法，判断队列中是否有等待线程。如果有，直接返回-1，表示没有可用信号</p>
</li>
<li><p>队列中没有等待线程，再使用CAS尝试更新state，获取信号</p>
</li>
</ul>
<h3 id="doAcquireSharedInterruptibly"><a href="#doAcquireSharedInterruptibly" class="headerlink" title="doAcquireSharedInterruptibly()"></a>doAcquireSharedInterruptibly()</h3><pre><code>private void doAcquireSharedInterruptibly(int arg)  
        throws InterruptedException &#123;  
        final Node node = addWaiter(Node.SHARED);   // 1  
        boolean failed = true;  
        try &#123;  
            for (;;) &#123;  
                final Node p = node.predecessor();     
                if (p == head) &#123;      // 2  
                    int r = tryAcquireShared(arg);  
                    if (r &gt;= 0) &#123;  
                        setHeadAndPropagate(node, r);  
                        p.next = null; // help GC  
                        failed = false;  
                        return;  
                    &#125;  
                &#125;  
                if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;     // 3  
                    parkAndCheckInterrupt())  
                    throw new InterruptedException();  
            &#125;  
        &#125; finally &#123;  
            if (failed)  
                cancelAcquire(node);     
        &#125;  
    &#125;  
  
</code></pre>
<ol>
<li>封装一个Node节点，加入队列尾部</li>
<li>在无限循环中，如果当前节点是头节点，就尝试获取信号</li>
<li>不是头节点，在经过节点状态判断后，挂起当前线程</li>
</ol>
<h3 id="release-释放信号"><a href="#release-释放信号" class="headerlink" title="release()释放信号"></a><strong>release()释放信号</strong></h3><pre><code>public final boolean releaseShared(int arg) &#123;  
        if (tryReleaseShared(arg)) &#123;    // 1  
            doReleaseShared();  // 2  
            return true;  
        &#125;  
        return false;  
    &#125;  
</code></pre>
<ol>
<li>cas更新state加一</li>
<li>唤醒等待队列头节点线程</li>
</ol>
<h2 id="举个栗子-2"><a href="#举个栗子-2" class="headerlink" title="举个栗子"></a>举个栗子</h2><pre><code>public static void main(String[] args) &#123;  
        ThreadPoolExecutor threadPool = new ThreadPoolExecutor(10, 10,  
                0L, TimeUnit.MILLISECONDS,  
                new LinkedBlockingQueue&lt;Runnable&gt;(10));  
        //信号总数为5  
        Semaphore semaphore = new Semaphore(5);  
        //运行10个线程  
        for (int i = 0; i &lt; 10; i++) &#123;  
            threadPool.execute(new Runnable() &#123;  
                  
                @Override  
                public void run() &#123;  
                    try &#123;  
                        //获取信号  
                        semaphore.acquire();     
                        System.out.println(Thread.currentThread().getName() + &quot;获得了信号量,时间为&quot; + System.currentTimeMillis());  
                        //阻塞2秒，测试效果  
                        Thread.sleep(2000);  
                        System.out.println(Thread.currentThread().getName() + &quot;释放了信号量,时间为&quot; + System.currentTimeMillis());  
                    &#125; catch (InterruptedException e) &#123;  
                        e.printStackTrace();  
                    &#125; finally &#123;  
                        //释放信号  
                        semaphore.release();  
                    &#125;  
                  
                &#125;  
            &#125;);  
        &#125;  
        threadPool.shutdown();  
    &#125;  
  
pool-1-thread-2获得了信号量,时间为1550584196125  
pool-1-thread-1获得了信号量,时间为1550584196125  
pool-1-thread-3获得了信号量,时间为1550584196125  
pool-1-thread-4获得了信号量,时间为1550584196126  
pool-1-thread-5获得了信号量,时间为1550584196127  
pool-1-thread-2释放了信号量,时间为1550584198126  
pool-1-thread-3释放了信号量,时间为1550584198126  
pool-1-thread-4释放了信号量,时间为1550584198126  
pool-1-thread-6获得了信号量,时间为1550584198126  
pool-1-thread-9获得了信号量,时间为1550584198126  
pool-1-thread-8获得了信号量,时间为1550584198126  
pool-1-thread-1释放了信号量,时间为1550584198126  
pool-1-thread-10获得了信号量,时间为1550584198126  
pool-1-thread-5释放了信号量,时间为1550584198127  
pool-1-thread-7获得了信号量,时间为1550584198127  
pool-1-thread-6释放了信号量,时间为1550584200126  
pool-1-thread-8释放了信号量,时间为1550584200126  
pool-1-thread-10释放了信号量,时间为1550584200126  
pool-1-thread-9释放了信号量,时间为1550584200126  
pool-1-thread-7释放了信号量,时间为1550584200127  
</code></pre>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/03/28/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%80%BB%E7%BB%93%E4%B8%80%E4%B8%8BKafka/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="merric">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Myoboku">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Myoboku">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/03/28/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%80%BB%E7%BB%93%E4%B8%80%E4%B8%8BKafka/" class="post-title-link" itemprop="url">总结一下Kafka</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-03-28 22:10:00" itemprop="dateCreated datePublished" datetime="2022-03-28T22:10:00+00:00">2022-03-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">数据库与中间件</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="基础架构及术语"><a href="#基础架构及术语" class="headerlink" title="基础架构及术语"></a>基础架构及术语</h2><p>话不多说，先看图，通过这张图我们来捋一捋相关的概念及之间的关系：</p>
<p><img src="/images/Kafka%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84.png" alt="Kafka基础架构"></p>
<p><strong>Producer</strong> ：Producer即生产者，消息的产生者，是消息的入口。</p>
<p><strong>kafka cluster</strong> ：<br><strong>Broker</strong><br>：Broker是kafka实例，每个服务器上有一个或多个kafka的实例，我们姑且认为每个broker对应一台服务器。每个kafka集群内的broker都有一个<br><strong>不重复</strong> 的编号，如图中的broker-0、broker-1等……<br><strong>Topic</strong> ：消息的主题，可以理解为消息的分类，kafka的数据就保存在topic。在每个broker上都可以创建多个topic。<br><strong>Partition</strong><br>：Topic的分区，每个topic可以有多个分区，分区的作用是做负载，提高kafka的吞吐量。同一个topic在不同的分区的数据是不重复的，partition的表现形式就是一个一个的文件夹！<br><strong>Replication</strong><br>:每一个分区都有多个副本，副本的作用是做备胎。当主分区（Leader）故障的时候会选择一个备胎（Follower）上位，成为Leader。在kafka中默认副本的最大数量是10个，且副本的数量不能大于Broker的数量，follower和leader绝对是在不同的机器，同一机器对同一个分区也只可能存放一个副本（包括自己）。<br><strong>Message</strong> ：每一条发送的消息主体。</p>
<p>Leader： <strong>每个分区多个副本的“主”</strong> ， <strong>生产者发送数据的对象，以及消费者消费数据的对象都是Leader</strong> 。</p>
<p>Follower：每个分区多个副本中的“从”，实时从Leader中同步数据，保持和Leader数据的同步。Leader发生故障时，某个Follower会成为新的Leader。</p>
<p><strong>Consumer</strong> ：消费者，即消息的消费方，是消息的出口。<br><strong>Consumer Group</strong><br>：我们可以将多个消费组组成一个消费者组，在kafka的设计中同一个分区的数据只能被消费者组中的某一个消费者消费。同一个消费者组的消费者可以消费同一个topic的不同分区的数据，这也是为了提高kafka的吞吐量！</p>
<p><strong>Zookeeper</strong> ：kafka集群依赖zookeeper来保存集群的的元信息，来保证系统的可用性。</p>
<h2 id="工作流程分析"><a href="#工作流程分析" class="headerlink" title="工作流程分析"></a>工作流程分析</h2><p>上面介绍了kafka的基础架构及基本概念，不知道大家看完有没有对kafka有个大致印象，如果对还比较懵也没关系！我们接下来再结合上面的结构图分析kafka的工作流程，最后再回来整个梳理一遍我相信你会更有收获！</p>
<h3 id="发送数据"><a href="#发送数据" class="headerlink" title="发送数据"></a>发送数据</h3><p>我们看上面的架构图中，producer就是生产者，是数据的入口。注意看图中的红色箭头，Producer在写入数据的时候 <strong>永远的找leader</strong><br>，不会直接将数据写入follower！那leader怎么找呢？写入的流程又是什么样的呢？我们看下图：</p>
<p><img src="/images/Kafka%E5%8F%91%E9%80%81%E6%95%B0%E6%8D%AE.png" alt="Kafka发送数据"></p>
<p>发送的流程就在图中已经说明了，就不单独在文字列出来了！需要注意的一点是，消息写入leader后，follower是主动的去leader进行同步的！producer采用push模式将数据发布到broker，每条消息追加到分区中，顺序写入磁盘，所以保证<br><strong>同一分区</strong> 内的数据是有序的！写入示意图如下：</p>
<p><img src="/images/%E6%AF%8F%E6%9D%A1%E6%B6%88%E6%81%AF%E8%BF%BD%E5%8A%A0%E5%88%B0%E5%88%86%E5%8C%BA%E4%B8%AD.png" alt="每条消息追加到分区中"></p>
<p>上面说到数据会写入到不同的分区，那kafka为什么要做分区呢？相信大家应该也能猜到，分区的主要目的是：<br><strong>1、 方便扩展</strong> 。因为一个topic可以有多个partition，所以我们可以通过扩展机器去轻松的应对日益增长的数据量。<br><strong>2、 提高并发</strong> 。以partition为读写单位，可以多个消费者同时消费数据，提高了消息的处理效率。</p>
<p>熟悉负载均衡的朋友应该知道，当我们向某个服务器发送请求的时候，服务端可能会对请求做一个负载，将流量分发到不同的服务器，那在kafka中，如果某个topic有多个partition，producer又怎么知道该将数据发往哪个partition呢？kafka中有几个原则：<br>1、 partition在写入的时候可以指定需要写入的partition，如果有指定，则写入对应的partition。<br>2、 如果没有指定partition，但是设置了数据的key，则会根据key的值hash出一个partition。<br>3、 如果既没指定partition，又没有设置key，则会轮询选出一个partition。</p>
<p>保证消息不丢失是一个消息队列中间件的基本保证，那producer在向kafka写入消息的时候，怎么保证消息不丢失呢？其实上面的写入流程图中有描述出来，那就是通过ACK应答机制！在生产者向队列写入数据的时候可以设置参数来确定是否确认kafka接收到数据，这个参数可设置的值为<br><strong>0</strong> 、 <strong>1</strong> 、 <strong>all</strong> 。<br>0代表producer往集群发送数据不需要等到集群的返回，不确保消息发送成功。安全性最低但是效率最高。<br>1代表producer往集群发送数据只要leader应答就可以发送下一条，只确保leader发送成功。<br>all代表producer往集群发送数据需要所有的follower都完成从leader的同步才会发送下一条，确保leader发送成功和所有的副本都完成备份。安全性最高，但是效率最低。</p>
<p>最后要注意的是，如果往不存在的topic写数据，能不能写入成功呢？kafka会自动创建topic，分区和副本的数量根据默认配置都是1。</p>
<h3 id="数据传递语义"><a href="#数据传递语义" class="headerlink" title="数据传递语义"></a>数据传递语义</h3><ul>
<li>至少一次（AtLeastOnce）&#x3D;ACK级别设置为-1+分区副本大于等于2+ISR里应答的最小副本数量大于等于2。可以保证数据不丢失，但是不能保证数据不重复；</li>
<li>最多一次（AtMostOnce）&#x3D;ACK级别设置为0。可以保证数据不重复，但是不能保证数据不丢失。</li>
<li>精确一次（ExactlyOnce）： <strong>精确一次（ExactlyOnce）&#x3D;幂等性+至少一次（ack&#x3D;-1+分区副本数 &gt;&#x3D;2+ISR最小副本数量&gt;&#x3D;2）</strong>。对于一些非常重要的信息，比如和钱相关的数据， <strong>要求数据既不能重复也不丢失。</strong></li>
</ul>
<p>Kafka0.11版本以后，引入了一项重大特性： <strong>幂等性和事务。</strong></p>
<h3 id="幂等性"><a href="#幂等性" class="headerlink" title="幂等性"></a><strong>幂等性</strong></h3><p> <strong>幂等性：就是指Producer不论向Broker发送多少次重复数据，Broker端都只会持久化一条，保证了不重复</strong></p>
<p><strong>重复数据的判断标准</strong> ：具有&lt;**PID,Partition,SeqNumber**&gt;相同主键的消息提交时，Broker只会持久化一条。其中<br><strong>PID是Kafka每次重启都会分配一个新的</strong> ； <strong>Partition表示分区号；SequenceNumber是单调自增的。</strong></p>
<p><strong>所以幂等性只能保证的是在单分区单会话内不重复。</strong></p>
<p><img src="/images/Kafka%E5%B9%82%E7%AD%89%E6%80%A7.png" alt="Kafka幂等性"></p>
<p><strong>如何使用幂等性？</strong></p>
<p>开启参数enable.idempotence 默认为true，false关闭。</p>
<pre><code>// 8.开启幂等性（开启事务，必须开启幂等性，默认为true）  
properties.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG,true);  
</code></pre>
<h3 id="生产者事务"><a href="#生产者事务" class="headerlink" title="生产者事务"></a>生产者事务</h3><p> <strong>1）Kafka事务原理</strong> ， <strong>开启事务，必须开启幂等性。</strong></p>
<p><strong>Kafka事务一共有5个API</strong></p>
<pre><code>/**  
     * See &#123;@link KafkaProducer#initTransactions()&#125;  
     */  
    void initTransactions();  
  
    /**  
     * See &#123;@link KafkaProducer#beginTransaction()&#125;  
     */  
    void beginTransaction() throws ProducerFencedException;  
  
    /**  
     * See &#123;@link KafkaProducer#sendOffsetsToTransaction(Map, String)&#125;  
     */  
    @Deprecated  
    void sendOffsetsToTransaction(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets,  
                                  String consumerGroupId) throws ProducerFencedException;  
  
    /**  
     * See &#123;@link KafkaProducer#sendOffsetsToTransaction(Map, ConsumerGroupMetadata)&#125;  
     */  
    void sendOffsetsToTransaction(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets,  
                                  ConsumerGroupMetadata groupMetadata) throws ProducerFencedException;  
  
    /**  
     * See &#123;@link KafkaProducer#commitTransaction()&#125;  
     */  
    void commitTransaction() throws ProducerFencedException;  
  
    /**  
     * See &#123;@link KafkaProducer#abortTransaction()&#125;  
     */  
    void abortTransaction() throws ProducerFencedException;   
</code></pre>
<p>3）使用kafka事务配置如下</p>
<pre><code>// 7.设置事务id（必须）  
properties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG,&quot;transaction_id_0&quot;);  
  
// 8.开启幂等性（开启事务，必须开启幂等性，默认为true）  
properties.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG,true);   
</code></pre>
<p>4）自定类 ：CustomProducerTransactions 实现kafka事务</p>
<pre><code>import ch.qos.logback.classic.Level;  
import ch.qos.logback.classic.Logger;  
import ch.qos.logback.classic.LoggerContext;  
import org.apache.kafka.clients.producer.Callback;  
import org.apache.kafka.clients.producer.KafkaProducer;  
import org.apache.kafka.clients.producer.ProducerRecord;  
import org.apache.kafka.clients.producer.RecordMetadata;  
import org.slf4j.LoggerFactory;  
  
import java.util.List;  
  
/**  
 * @author huangdh  
 * @version 1.0  
 * @description:  
 * @date 2022-11-10 21:45  
 */  
public class CustomProducerTransactions &#123;  
  
    // 修改日志打印级别，默认为debug级别  
    static &#123;  
        LoggerContext loggerContext = (LoggerContext) LoggerFactory.getILoggerFactory();  
        List&lt;Logger&gt; loggerList = loggerContext.getLoggerList();  
        loggerList.forEach(logger -&gt; &#123;  
            logger.setLevel(Level.INFO);  
        &#125;);  
    &#125;  
  
    public static void main(String[] args) &#123;  
  
        KafkaProducer&lt;String, String&gt; producer = KafkaProducerFactory.getProducer();  
  
        // 初始化事务  
        producer.initTransactions();  
        // 开启事务  
        producer.beginTransaction();  
        try &#123;  
            for (int i = 0; i &lt; 5; i++) &#123;  
                producer.send(new ProducerRecord&lt;&gt;(&quot;kafka&quot;, &quot;study hard everyday&quot; + i), new Callback() &#123;  
                    @Override  
                    public void onCompletion(RecordMetadata recordMetadata, Exception e) &#123;  
                        if (e == null) &#123;  
                            System.out.println(&quot;主题：&quot; + recordMetadata.topic() + &quot;-&gt;&quot; + &quot;分区：&quot; + recordMetadata.partition());  
                        &#125; else &#123;  
                            e.printStackTrace();  
                        &#125;  
                    &#125;  
                &#125;);  
            &#125;  
  
//            int i = 1/0;  
            // 提交事务  
            producer.commitTransaction();  
        &#125; catch (Exception e) &#123;  
            // 终止事务  
            producer.abortTransaction();  
            e.printStackTrace();  
        &#125;finally &#123;  
            producer.close();  
        &#125;  
    &#125;  
&#125;  
  
</code></pre>
<p>执行结果如下：</p>
<pre><code>23:04:15.842 [kafka-producer-network-thread | producer-transaction_id_0] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-transaction_id_0, transactionalId=transaction_id_0] Discovered transaction coordinator 8.8.80.8:9092 (id: 0 rack: null)  
23:04:15.979 [kafka-producer-network-thread | producer-transaction_id_0] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-transaction_id_0, transactionalId=transaction_id_0] ProducerId set to 1000 with epoch 4  
主题：kafka-&gt;分区：1  
主题：kafka-&gt;分区：1  
主题：kafka-&gt;分区：1  
主题：kafka-&gt;分区：1  
主题：kafka-&gt;分区：1  
</code></pre>
<h3 id="保存数据"><a href="#保存数据" class="headerlink" title="保存数据"></a>保存数据</h3><p>Producer将数据写入kafka后，集群就需要对数据进行保存了！kafka将数据保存在磁盘，可能在我们的一般的认知里，写入磁盘是比较耗时的操作，不适合这种高并发的组件。Kafka初始会单独开辟一块磁盘空间，顺序写入数据（效率比随机写入高）。</p>
<p><strong>Partition 结构</strong><br>前面说过了每个topic都可以分为一个或多个partition，如果你觉得topic比较抽象，那partition就是比较具体的东西了！Partition在服务器上的表现形式就是一个一个的文件夹，每个partition的文件夹下面会有多组segment文件，每组segment文件又包含.index文件、.log文件、.timeindex文件（早期版本中没有）三个文件，<br>log文件就实际是存储message的地方，而index和timeindex文件为索引文件，用于检索消息。</p>
<p><img src="/images/Partition%E7%BB%93%E6%9E%84.png" alt="Partition结构"></p>
<p>如上图，这个partition有三组segment文件，每个log文件的大小是一样的，但是存储的message数量是不一定相等的（每条的message大小不一致）。文件的命名是以该segment最小offset来命名的，如000.index存储offset为0~368795的消息，kafka就是利用分段+索引的方式来解决查找效率的问题。</p>
<p><strong>Message结构</strong><br>上面说到log文件就实际是存储message的地方，我们在producer往kafka写入的也是一条一条的message，那存储在log中的message是什么样子的呢？消息主要包含消息体、消息大小、offset、压缩类型……等等！我们重点需要知道的是下面三个：<br>1、 offset：offset是一个占8byte的有序id号，它可以唯一确定每条消息在parition内的位置！<br>2、 消息大小：消息大小占用4byte，用于描述消息的大小。<br>3、 消息体：消息体存放的是实际的消息数据（被压缩过），占用的空间根据具体的消息而不一样。</p>
<p><strong>存储策略</strong><br>无论消息是否被消费，kafka都会保存所有的消息。那对于旧数据有什么删除策略呢？<br>1、 基于时间，默认配置是168小时（7天）。<br>2、 基于大小，默认配置是1073741824。<br>需要注意的是，kafka读取特定消息的时间复杂度是O(1)，所以这里删除过期的文件并不会提高kafka的性能！</p>
<h3 id="Kafka副本"><a href="#Kafka副本" class="headerlink" title="Kafka副本"></a>Kafka副本</h3><h4 id="kafka副本"><a href="#kafka副本" class="headerlink" title="kafka副本"></a>kafka副本</h4><ol>
<li><strong>Kafka副本作用：提高数据可靠性。</strong></li>
<li>Kafka默认副本1个，生产环境一般配置为2个，保证数据可靠性；太多副本会增加磁盘存储空间，增加网络上数据传输，降低效率。</li>
<li>Kafka中副本分为：Leader和Follower。Kafka生产者只会把数据发往Leader，然后Follower找Leader进行同步数据。 </li>
<li><strong>Kafka分区中的所有副本统称为AR（Assigned Repllicas），AR &#x3D; ISR + OSR。</strong><br>1. <strong>ISR，表示和Leader保持同步的Follower集合</strong> 。 <strong>如果Follower长时间未向Leader发送通信请求或同步数据，则该Follower将被踢出ISR</strong>** 。该时间阈值由replica.lag.time.max.ms参数设定，默认30s**。Leader发生故障之后，就会从ISR中选举新的Leader。<br>2. <strong>OSR，表示Follower与Leader副本同步时，延迟过多的副本。</strong></li>
</ol>
<h4 id="Leader选举流程"><a href="#Leader选举流程" class="headerlink" title="Leader选举流程"></a>Leader选举流程</h4><p>Kafka集群中有一个broker的Controller会被选举为Controller Leader，<br><strong>负责管理集群broker的上下线，所有topic的分区副本分配和Leader选举等工作</strong><br>。Controller的信息同步工作是依赖于Zookeeper的。</p>
<h4 id="Leader和Follower故障处理细节"><a href="#Leader和Follower故障处理细节" class="headerlink" title="Leader和Follower故障处理细节"></a>Leader和Follower故障处理细节</h4><p> <strong>LEO（Log End Offset）：每个副本的最后一个offset，LEO其实就是最新的offset+1。</strong></p>
<p><strong>HW（High Watermark）：所有副本中最小的LEO。</strong></p>
<p><img src="/images/Leader%E5%92%8CFollower%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E7%BB%86%E8%8A%82.png" alt="Leader和Follower故障处理细节"></p>
<p><strong>Follower故障</strong></p>
<p>（1）Follower发生故障后会被临时踢出ISR。</p>
<p>（2）这个期间Leader和Follower继续接收数据。</p>
<p><img src="/images/Follower%E6%95%85%E9%9A%9C.png" alt="Follower故障"></p>
<p>（3）待该Follower恢复后，Follower会读取本地磁盘记录上次的HW，并将log文件高于HW的部分截取掉，从HW开始向Leader进行同步。</p>
<p><img src="/images/%E4%BB%8EHW%E5%BC%80%E5%A7%8B%E5%90%91Leader%E8%BF%9B%E8%A1%8C%E5%90%8C%E6%AD%A5.png" alt="从HW开始向Leader进行同步"></p>
<p>（4）等该Follower的LEO大于等于该Partition的HW，即Follower追上Leader之后，就可以重新加入ISR了。</p>
<p><img src="/images/Follower%E8%BF%BD%E4%B8%8ALeader.png" alt="Follower追上Leader"></p>
<p><strong>Leader故障处理机制</strong></p>
<p>（1）Leader发生故障之后，会从ISR中选出一个新的Leader。</p>
<p><img src="/images/%E4%BB%8EISR%E4%B8%AD%E9%80%89%E5%87%BA%E4%B8%80%E4%B8%AA%E6%96%B0%E7%9A%84Leader.png" alt="从ISR中选出一个新的Leader"></p>
<p>（2）为保证多个副本之间的数据一致性，其余的Follower会先将各自的log文件高于HW的部分截掉，然后从新的Leader同步数据。</p>
<p><img src="/images/%E9%AB%98%E4%BA%8EHW%E7%9A%84%E9%83%A8%E5%88%86%E6%88%AA%E6%8E%89.png" alt="高于HW的部分截掉"></p>
<p><strong>注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</strong></p>
<h3 id="消费数据"><a href="#消费数据" class="headerlink" title="消费数据"></a>消费数据</h3><p>消息存储在log文件后，消费者就可以进行消费了。与生产消息相同的是，消费者在拉取消息的时候也是 <strong>找leader</strong> 去拉取。</p>
<p>多个消费者可以组成一个消费者组（consumer<br>group），每个消费者组都有一个组id！同一个消费组者的消费者可以消费同一topic下不同分区的数据，但是不会组内多个消费者消费同一分区的数据！！！是不是有点绕。我们看下图：</p>
<p><img src="/images/%E6%B6%88%E8%B4%B9%E6%95%B0%E6%8D%AE.png" alt="消费数据"></p>
<p>图示是消费者组内的消费者小于partition数量的情况，所以会出现某个消费者消费多个partition数据的情况，消费的速度也就不及只处理一个partition的消费者的处理速度！如果是消费者组的消费者多于partition的数量，那会不会出现多个消费者消费同一个partition的数据呢？上面已经提到过不会出现这种情况！多出来的消费者不消费任何partition的数据。所以在实际的应用中，建议<br><strong>消费者组的consumer的数量与partition的数量一致</strong> ！<br>在保存数据的小节里面，我们聊到了partition划分为多组segment，每个segment又包含.log、.index、.timeindex文件，存放的每条message包含offset、消息大小、消息体……我们多次提到segment和offset，查找消息的时候是怎么利用segment+offset配合查找的呢？假如现在需要查找一个offset为368801的message是什么样的过程呢？我们先看看下面的图：</p>
<p><img src="/images/Kafka%E6%9F%A5%E6%89%BE%E6%B6%88%E6%81%AF.png" alt="Kafka查找消息"></p>
<p>1、 先找到offset的368801message所在的segment文件（利用二分法查找），这里找到的就是在第二个segment文件。<br>2、<br>打开找到的segment中的.index文件（也就是368796.index文件，该文件起始偏移量为368796+1，我们要查找的offset为368801的message在该index内的偏移量为368796+5&#x3D;368801，所以这里要查找的<br><strong>相对offset</strong><br>为5）。由于该文件采用的是稀疏索引的方式存储着相对offset及对应message物理偏移量的关系，所以直接找相对offset为5的索引找不到，这里同样利用二分法查找相对offset小于或者等于指定的相对offset的索引条目中最大的那个相对offset，所以找到的是相对offset为4的这个索引。<br>3、<br>根据找到的相对offset为4的索引确定message存储的物理偏移位置为256。打开数据文件，从位置为256的那个地方开始顺序扫描直到找到offset为368801的那条Message。</p>
<p>这套机制是建立在offset为有序的基础上，利用 <strong>segment</strong> + <strong>有序offset</strong> + <strong>稀疏索引</strong> + <strong>二分查找</strong> +<br><strong>顺序查找</strong><br>等多种手段来高效的查找数据！至此，消费者就能拿到需要处理的数据进行处理了。那每个消费者又是怎么记录自己消费的位置呢？在早期的版本中，消费者将消费到的offset维护zookeeper中，consumer每间隔一段时间上报一次，这里容易导致重复消费，且性能不好！在新的版本中消费者消费到的offset已经直接维护在kafka集群的__consumer_offsets这个topic中！</p>
<h2 id="Kafka-Broker"><a href="#Kafka-Broker" class="headerlink" title="Kafka Broker"></a>Kafka Broker</h2><h3 id="Kafka-Broker工作流程"><a href="#Kafka-Broker工作流程" class="headerlink" title="Kafka Broker工作流程"></a>Kafka Broker工作流程</h3><h4 id="Zookeeper存储的Kafka信息"><a href="#Zookeeper存储的Kafka信息" class="headerlink" title="Zookeeper存储的Kafka信息"></a>Zookeeper存储的Kafka信息</h4><p><img src="/images/Zookeeper%E5%AD%98%E5%82%A8%E7%9A%84Kafka%E4%BF%A1%E6%81%AF.png" alt="Zookeeper存储的Kafka信息"></p>
<ol>
<li><strong>&#x2F;kafka&#x2F;brokers&#x2F;ids：[0,1,2]，记录有哪些服务器。</strong></li>
<li><strong>&#x2F;kafka&#x2F;brokers&#x2F;topics&#x2F;first&#x2F;partitions&#x2F;0&#x2F;state：{“leader”:1,”isr”:[1,0,2] } 记录谁是Leader，有哪些服务器可用。</strong></li>
<li><strong>&#x2F;kafka&#x2F;controller：{“brokerid”:0} 辅助选举Leader</strong></li>
</ol>
<h4 id="Kafka-Broker工作流程-1"><a href="#Kafka-Broker工作流程-1" class="headerlink" title="Kafka Broker工作流程"></a>Kafka Broker工作流程</h4><p><img src="/images/Broker%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png" alt="Broker工作流程"></p>
<ol>
<li>broker启动后在zk中注册</li>
<li>controller谁先注册，谁说了算</li>
<li>由选举出来的controller监听brokers节点变化</li>
<li>controller决定Leader选举</li>
<li>controller将节点信息上传到zk中</li>
<li>其他controller从zk同步相关信息</li>
<li>假设broker1中Leader挂了</li>
<li>controller监听到节点发生变化</li>
<li>获取ISR</li>
<li>选举新的Leader（在isr中存活为前提，按照AR中排在前面的优先，例如：ar[1,0,2]，那么leader就会按照1,0,2的顺序轮询）</li>
<li>更新Leader及ISR</li>
</ol>
<h2 id="Kafka核心特性"><a href="#Kafka核心特性" class="headerlink" title="Kafka核心特性"></a>Kafka核心特性</h2><h3 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h3><p>我们上面已经知道了Kafka支持以集合（batch）为单位发送消息，在此基础上，Kafka还支持对消息集合进行压缩，Producer端可以通过GZIP或Snappy格式对消息集合进行压缩。Producer端进行压缩之后，在Consumer端需进行解压。压缩的好处就是减少传输的数据量，减轻对网络传输的压力，在对大数据处理上，瓶颈往往体现在网络上而不是CPU（压缩和解压会耗掉部分CPU资源）。<br>那么如何区分消息是压缩的还是未压缩的呢，Kafka在消息头部添加了一个描述压缩属性字节，这个字节的后两位表示消息的压缩采用的编码，如果后两位为0，则表示消息未被压缩。</p>
<h3 id="消息可靠性"><a href="#消息可靠性" class="headerlink" title="消息可靠性"></a>消息可靠性</h3><p>在消息系统中，保证消息在生产和消费过程中的可靠性是十分重要的，在实际消息传递过程中，可能会出现如下三中情况：</p>
<ul>
<li>一个消息发送失败</li>
<li>一个消息被发送多次</li>
<li>最理想的情况：exactly-once ,一个消息发送成功且仅发送了一次</li>
</ul>
<p>有许多系统声称它们实现了exactly-<br>once，但是它们其实忽略了生产者或消费者在生产和消费过程中有可能失败的情况。比如虽然一个Producer成功发送一个消息，但是消息在发送途中丢失，或者成功发送到broker，也被consumer成功取走，但是这个consumer在处理取过来的消息时失败了。<br>从Producer端看：Kafka是这么处理的，当一个消息被发送后，Producer会等待broker成功接收到消息的反馈（可通过参数控制等待时间），如果消息在途中丢失或是其中一个broker挂掉，Producer会重新发送（我们知道Kafka有备份机制，可以通过参数控制是否等待所有备份节点都收到消息）。<br>从Consumer端看：前面讲到过partition，broker端记录了partition中的一个offset值，这个值指向Consumer下一个即将消费message。当Consumer收到了消息，但却在处理过程中挂掉，此时Consumer可以通过这个offset值重新找到上一个消息再进行处理。Consumer还有权限控制这个offset值，对持久化到broker端的消息做任意处理。</p>
<h3 id="备份机制"><a href="#备份机制" class="headerlink" title="备份机制"></a>备份机制</h3><p>备份机制是Kafka0.8版本的新特性，备份机制的出现大大提高了Kafka集群的可靠性、稳定性。有了备份机制后，Kafka允许集群中的节点挂掉后而不影响整个集群工作。一个备份数量为n的集群允许n-1个节点失败。在所有备份节点中，有一个节点作为lead节点，这个节点保存了其它备份节点列表，并维持各个备份间的状体同步。下面这幅图解释了Kafka的备份机制:</p>
<p><img src="/images/Kafka%E5%A4%87%E4%BB%BD%E6%9C%BA%E5%88%B6.png" alt="Kafka备份机制"></p>
<h3 id="Kafka高效性相关设计"><a href="#Kafka高效性相关设计" class="headerlink" title="Kafka高效性相关设计"></a>Kafka高效性相关设计</h3><h2 id="高效读写数据"><a href="#高效读写数据" class="headerlink" title="高效读写数据"></a>高效读写数据</h2><ol>
<li>Kafka是分布式集群，可以采用分区技术，并行度高。</li>
<li>读数据采用稀疏索引，可以快速定位到要消费的数据。</li>
<li>顺序写磁盘。</li>
</ol>
<p>Kafka的producer生产数据，要 <strong>写入到log文件中，写的过程是一直追加到文件末端，为顺序写</strong> 。<br><strong>官网有数据表明，同样的磁盘，顺序写能到600M&#x2F;s，而随机写只有100K&#x2F;s</strong><br>。这与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。</p>
<p><strong>页缓存 + 零拷贝技术</strong></p>
<p><strong>零拷贝：</strong> Kafka的数据加工处理操作交由Kafka生产者和Kafka消费者处理。Kafka<br>Broker应用层不关心存储的数据，所以就不用走应用层，传输效率高。</p>
<p><strong>PageCache页缓存</strong><br>：Kafka重度依赖底层操作系统提供的PageCache功能。当上层有写操作时，操作系统只是将数据写入PageCache。当读操作发生时，先从PageCache中查找，如果找不到，再去磁盘中读取。<br><strong>实际上PageCache是把尽可能多的空闲内存都当做了磁盘缓存来使用。</strong></p>
<p><img src="/images/%E6%98%AF%E5%90%A6%E9%9B%B6%E6%8B%B7%E8%B4%9D%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%E5%AF%B9%E6%AF%94.png" alt="是否零拷贝工作流程对比"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2020 – 
    <span itemprop="copyrightYear">2023</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">merric</span>
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/next-boot.js"></script>

  






  





</body>
</html>
